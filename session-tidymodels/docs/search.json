[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tidymodels",
    "section": "",
    "text": "Preface\nAims\n\nto introduce tidymodels framework for predictive modelling studies\nand show how to put all the common steps for building predictive model\n\nLearning outcomes\n\nto be able to use tidymodels framework for a complete workflow of supervised learning\n\nDo you see a mistake or a typo? We would be grateful if you let us know via edu.ml-biostats@nbis.se\nThis repository contains teaching and learning materials prepared for and used during “Introduction to biostatistics and Machine Learning” course, organized by NBIS, National Bioinformatics Infrastructure Sweden. The course is open for PhD students, postdoctoral researcher and other employees within Swedish universities. The materials are geared towards life scientists wanting to be able to understand and use the basic statistical and machine learning methods. More about the course https://nbisweden.github.io/workshop-mlbiostatistics/"
  },
  {
    "objectID": "intro.html#references",
    "href": "intro.html#references",
    "title": "1  Introduction to Tidymodels",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "case-study.html#data-import-eda",
    "href": "case-study.html#data-import-eda",
    "title": "2  Demo: a predictive modelling case study",
    "section": "2.1 Data import & EDA",
    "text": "2.1 Data import & EDA\n\n# load libraries\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(ggcorrplot)\nlibrary(reshape2)\nlibrary(vip)\n\n# import raw data\ninput_diabetes &lt;- read_csv(\"data/data-diabetes.csv\")\n\n# create BMI variable\nconv_factor &lt;- 703 # conversion factor to calculate BMI from inches and pounds BMI = weight (lb) / [height (in)]2 x 703\ndata_diabetes &lt;- input_diabetes %&gt;%\n  mutate(BMI = weight / height^2 * 703, BMI = round(BMI, 2)) %&gt;%\n  relocate(BMI, .after = id)\n\n# preview data\nglimpse(data_diabetes)\n## Rows: 403\n## Columns: 20\n## $ id       &lt;dbl&gt; 1000, 1001, 1002, 1003, 1005, 1008, 1011, 1015, 1016, 1022, 1…\n## $ BMI      &lt;dbl&gt; 22.13, 37.42, 48.37, 18.64, 27.82, 26.50, 28.20, 34.33, 24.51…\n## $ chol     &lt;dbl&gt; 203, 165, 228, 78, 249, 248, 195, 227, 177, 263, 242, 215, 23…\n## $ stab.glu &lt;dbl&gt; 82, 97, 92, 93, 90, 94, 92, 75, 87, 89, 82, 128, 75, 79, 76, …\n## $ hdl      &lt;dbl&gt; 56, 24, 37, 12, 28, 69, 41, 44, 49, 40, 54, 34, 36, 46, 30, 4…\n## $ ratio    &lt;dbl&gt; 3.6, 6.9, 6.2, 6.5, 8.9, 3.6, 4.8, 5.2, 3.6, 6.6, 4.5, 6.3, 6…\n## $ glyhb    &lt;dbl&gt; 4.31, 4.44, 4.64, 4.63, 7.72, 4.81, 4.84, 3.94, 4.84, 5.78, 4…\n## $ location &lt;chr&gt; \"Buckingham\", \"Buckingham\", \"Buckingham\", \"Buckingham\", \"Buck…\n## $ age      &lt;dbl&gt; 46, 29, 58, 67, 64, 34, 30, 37, 45, 55, 60, 38, 27, 40, 36, 3…\n## $ gender   &lt;chr&gt; \"female\", \"female\", \"female\", \"male\", \"male\", \"male\", \"male\",…\n## $ height   &lt;dbl&gt; 62, 64, 61, 67, 68, 71, 69, 59, 69, 63, 65, 58, 60, 59, 69, 6…\n## $ weight   &lt;dbl&gt; 121, 218, 256, 119, 183, 190, 191, 170, 166, 202, 156, 195, 1…\n## $ frame    &lt;chr&gt; \"medium\", \"large\", \"large\", \"large\", \"medium\", \"large\", \"medi…\n## $ bp.1s    &lt;dbl&gt; 118, 112, 190, 110, 138, 132, 161, NA, 160, 108, 130, 102, 13…\n## $ bp.1d    &lt;dbl&gt; 59, 68, 92, 50, 80, 86, 112, NA, 80, 72, 90, 68, 80, NA, 66, …\n## $ bp.2s    &lt;dbl&gt; NA, NA, 185, NA, NA, NA, 161, NA, 128, NA, 130, NA, NA, NA, N…\n## $ bp.2d    &lt;dbl&gt; NA, NA, 92, NA, NA, NA, 112, NA, 86, NA, 90, NA, NA, NA, NA, …\n## $ waist    &lt;dbl&gt; 29, 46, 49, 33, 44, 36, 46, 34, 34, 45, 39, 42, 35, 37, 36, 3…\n## $ hip      &lt;dbl&gt; 38, 48, 57, 38, 41, 42, 49, 39, 40, 50, 45, 50, 41, 43, 40, 4…\n## $ time.ppn &lt;dbl&gt; 720, 360, 180, 480, 300, 195, 720, 1020, 300, 240, 300, 90, 7…\n\n# run basic EDA\n# note: we have seen descriptive statistics and plots during EDA session \n# note: so here we only look at missing data and correlation\n\n# calculate number of missing data per variable\ndata_na &lt;- data_diabetes %&gt;% \n  summarise(across(everything(), ~ sum(is.na(.)))) \n\n# make a table with counts sorted from highest to lowest\ndata_na_long &lt;- data_na %&gt;%\n  pivot_longer(-id, names_to = \"variable\", values_to = \"count\") %&gt;%\n  arrange(desc(count)) \n\n# make a column plot to visualize the counts\ndata_na_long %&gt;%\n  ggplot(aes(x = variable, y = count)) + \n  geom_col(fill = \"blue4\") + \n  xlab(\"\") + \n  theme_bw() +\n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))\n\n# calculate correlation between numeric variables\ndata_cor &lt;- data_diabetes %&gt;% \n  dplyr::select(-id) %&gt;% \n  dplyr::select(where(is.numeric)) %&gt;%\n  cor(use = \"pairwise.complete.obs\")\n\n# visualize correlation via heatmap\nggcorrplot(data_cor, hc.order = TRUE, lab = FALSE)\n\n# based on the number of missing data, let's delete bp.2s, bp.2d\n# and use complete-cases analysis \ndata_diabetes_narm &lt;- data_diabetes %&gt;%\n  dplyr::select(-bp.2s, -bp.2d) %&gt;%\n  na.omit()\n\n\n\n\nNumber of missing data per variable, shows that bp.2d and bp.2s have more than 50% missing entries\n\n\n\n\n\n\n\nHeatmap visualizing Pearson correlation coefficient between numerical variables"
  },
  {
    "objectID": "case-study.html#data-splitting",
    "href": "case-study.html#data-splitting",
    "title": "2  Demo: a predictive modelling case study",
    "section": "2.2 Data splitting",
    "text": "2.2 Data splitting\n\n# use tidymodels framework to fit Lasso regression model for predicting BMI\n# using repeated cross-validation to tune lambda value in L1 penalty term\n\n# select random seed value\nmyseed &lt;- 123\n\n# split data into non-test (other) and test (80% s)\nset.seed(myseed)\ndata_split &lt;- initial_split(data_diabetes_narm, strata = BMI, prop = 0.8) # holds splitting info\ndata_other &lt;- data_split %&gt;% training() # creates non-test set (function is called training but it refers to non-test part)\ndata_test &lt;- data_split %&gt;% testing() # creates test set\n\n# prepare repeated cross-validation splits with 5 folds repeated 3 times\nset.seed(myseed)\ndata_folds &lt;- vfold_cv(data_other,\n                       v = 5, \n                       repeats = 3,\n                       strata = BMI)\n\n# check the split\ndim(data_diabetes)\n## [1] 403  20\ndim(data_other)\n## [1] 291  18\ndim(data_test)\n## [1] 75 18\n\n# check BMI distributions in data splits\npar(mfrow=c(3,1))\nhist(data_diabetes$BMI, xlab = \"\", main = \"BMI: all\", 50)\nhist(data_other$BMI, xlab = \"\", main = \"BMI: non-test\", 50)\nhist(data_test$BMI, xlab = \"\", main = \"BMI: test\", 50)\n\n\n\n\nDistribution of BMI values given all data and spits into non-test and test"
  },
  {
    "objectID": "case-study.html#feature-engineering",
    "href": "case-study.html#feature-engineering",
    "title": "2  Demo: a predictive modelling case study",
    "section": "2.3 Feature engineering",
    "text": "2.3 Feature engineering\n\n# create data recipe (feature engineering)\n\ninch2m &lt;- 2.54/100\npound2kg &lt;- 0.45\n\ndata_recipe &lt;- recipe(BMI ~ ., data = data_other) %&gt;%\n  update_role(id, new_role = \"sampleID\") %&gt;%\n  step_mutate(height = height * inch2m, height = round(height, 2)) %&gt;% # convert height to meters\n  step_mutate(weight = weight * pound2kg, weight = round(weight, 2)) %&gt;% # convert weight to kg\n  step_rename(glu = stab.glu) %&gt;% # rename stab.glu to glu\n  step_log(glu) %&gt;%  #ln transform glucose\n  step_zv(all_numeric()) %&gt;% # removes variables that are highly sparse and unbalanced (if found)\n  step_corr(all_numeric(), -all_outcomes(), -has_role(\"sampleID\"), threshold = 0.8) %&gt;% # removes variables with large absolute correlations with other variables (if found)\n  step_dummy(location, gender, frame) %&gt;% # convert categorical variables to dummy variables\n  step_normalize(all_numeric(), -all_outcomes(), -has_role(\"sampleID\"), skip = FALSE) \n  \n  # you can implement more steps: see https://recipes.tidymodels.org/reference/index.html\n\n# print recipe\ndata_recipe\n\n# check if recipe is doing what it is supposed to do\n# i.e. bake the data\ndata_other_prep &lt;- data_recipe %&gt;%\n  prep() %&gt;%\n  bake(new_data = NULL)\n\n## bake test data\ndata_test_prep &lt;- data_recipe %&gt;%\n  prep() %&gt;%\n  bake(new_data = data_test)\n\n# preview baked data\nprint(head(data_other_prep))\n## # A tibble: 6 × 17\n##      id   chol    glu    hdl  ratio  glyhb    age  height  bp.1s  bp.1d    hip\n##   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n## 1  1045 -0.319 -0.539 -0.830  0.486 -0.172 -0.645 -0.474  -1.16  -0.552 -1.66 \n## 2  1271  0.449 -1.09  -0.324  0.320 -0.458 -1.39  -1.29   -1.59  -1.00  -0.914\n## 3  1277 -0.657 -0.572  2.32  -1.45  -0.642 -0.337  1.56    0.286  2.15  -1.29 \n## 4  1303 -0.590 -0.410 -0.436 -0.178 -0.518  0.341  0.545  -0.309  0.500 -1.47 \n## 5  1309 -0.206 -0.347  0.687 -0.730 -0.860 -1.32   0.0357 -0.735 -0.402 -1.66 \n## 6  1315 -0.793 -0.572  0.350 -0.841  0.225  0.649  1.26   -0.565 -1.45  -1.29 \n## # ℹ 6 more variables: time.ppn &lt;dbl&gt;, BMI &lt;dbl&gt;, location_Louisa &lt;dbl&gt;,\n## #   gender_male &lt;dbl&gt;, frame_medium &lt;dbl&gt;, frame_small &lt;dbl&gt;"
  },
  {
    "objectID": "case-study.html#lasso-regression",
    "href": "case-study.html#lasso-regression",
    "title": "2  Demo: a predictive modelling case study",
    "section": "2.4 Lasso regression",
    "text": "2.4 Lasso regression\n\n# define model\nmodel &lt;- linear_reg(penalty = tune(), mixture = 1) %&gt;%\n  set_engine(\"glmnet\") %&gt;%\n  set_mode(\"regression\")\n\n# create workflow with data recipe and model \nwf &lt;- workflow() %&gt;%\n  add_model(model) %&gt;%\n  add_recipe(data_recipe)\n\n# define parameters range for tuning\ngrid_lambda &lt;- grid_regular(penalty(), levels = 25)\n\n# tune lambda\nmodel_tune &lt;- wf %&gt;%\n  tune_grid(resamples = data_folds, \n            grid = grid_lambda)\n\n# show metrics average across folds\nmodel_tune  %&gt;%\n  collect_metrics(summarize = TRUE)\n## # A tibble: 50 × 7\n##     penalty .metric .estimator  mean     n std_err .config              \n##       &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n##  1 1   e-10 rmse    standard   2.48     15  0.142  Preprocessor1_Model01\n##  2 1   e-10 rsq     standard   0.851    15  0.0143 Preprocessor1_Model01\n##  3 2.61e-10 rmse    standard   2.48     15  0.142  Preprocessor1_Model02\n##  4 2.61e-10 rsq     standard   0.851    15  0.0143 Preprocessor1_Model02\n##  5 6.81e-10 rmse    standard   2.48     15  0.142  Preprocessor1_Model03\n##  6 6.81e-10 rsq     standard   0.851    15  0.0143 Preprocessor1_Model03\n##  7 1.78e- 9 rmse    standard   2.48     15  0.142  Preprocessor1_Model04\n##  8 1.78e- 9 rsq     standard   0.851    15  0.0143 Preprocessor1_Model04\n##  9 4.64e- 9 rmse    standard   2.48     15  0.142  Preprocessor1_Model05\n## 10 4.64e- 9 rsq     standard   0.851    15  0.0143 Preprocessor1_Model05\n## # ℹ 40 more rows\n\n# plot k-folds results across lambda range\nmodel_tune %&gt;%\n  collect_metrics() %&gt;% \n  dplyr::filter(.metric == \"rmse\") %&gt;% \n  ggplot(aes(penalty, mean, color = .metric)) +\n  geom_errorbar(aes( ymin = mean - std_err, ymax = mean + std_err), alpha = 0.5) +\n  scale_x_log10() + \n  geom_line(linewidth = 1.5) +\n  theme_bw() +\n  theme(legend.position = \"none\") +\n  scale_color_brewer(palette = \"Set1\")\n  \n# best lambda value (min. RMSE)\nmodel_best &lt;- model_tune %&gt;%\n  select_best(metric = \"rmse\")\n\nprint(model_best)\n## # A tibble: 1 × 2\n##   penalty .config              \n##     &lt;dbl&gt; &lt;chr&gt;                \n## 1  0.0562 Preprocessor1_Model22\n\n# finalize workflow with tuned model\nwf_final &lt;- wf %&gt;%\n  finalize_workflow(model_best)\n\n# last fit \nfit_final &lt;- wf_final %&gt;%\n  last_fit(split = data_split)\n\n# final predictions\ny_test_pred &lt;- fit_final %&gt;% collect_predictions() # predicted BMI\n\n# final predictions: performance on test (unseen data)\nfit_final %&gt;% collect_metrics() \n## # A tibble: 2 × 4\n##   .metric .estimator .estimate .config             \n##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n## 1 rmse    standard       2.79  Preprocessor1_Model1\n## 2 rsq     standard       0.857 Preprocessor1_Model1\n\n# plot predictions vs. actual for test data\nplot(data_test$BMI, y_test_pred$.pred, xlab=\"BMI (actual)\", ylab = \"BMI (predicted)\", las = 1, pch = 19)\n\n# correlation between predicted and actual BMI values for test data\ncor(data_test$BMI, y_test_pred$.pred)\n## [1] 0.9256857\n\n# re-fit model on all non-test data\nmodel_final &lt;- wf_final %&gt;%\n  fit(data_other) \n\n# show final model\ntidy(model_final)\n## # A tibble: 16 × 3\n##    term            estimate penalty\n##    &lt;chr&gt;              &lt;dbl&gt;   &lt;dbl&gt;\n##  1 (Intercept)      28.7     0.0562\n##  2 chol              0       0.0562\n##  3 glu               0.0229  0.0562\n##  4 hdl               0       0.0562\n##  5 ratio             0.335   0.0562\n##  6 glyhb            -0.0512  0.0562\n##  7 age              -0.257   0.0562\n##  8 height           -1.86    0.0562\n##  9 bp.1s            -0.294   0.0562\n## 10 bp.1d             0.203   0.0562\n## 11 hip               5.60    0.0562\n## 12 time.ppn          0       0.0562\n## 13 location_Louisa  -0.160   0.0562\n## 14 gender_male       1.07    0.0562\n## 15 frame_medium     -0.320   0.0562\n## 16 frame_small      -0.530   0.0562\n\n# plot variables ordered by importance (highest abs(coeff))\nmodel_final %&gt;%\n  extract_fit_parsnip() %&gt;%\n  vip(geom = \"point\") + \n  theme_bw()\n\n\n\n\nMean RMSE plus/minus standard error across repeated cross-validation folds as a function of lambda values\n\n\n\n\n\n\n\nPredicted BMI values against actual BMI values using final model for predicting test (unseen) data\n\n\n\n\n\n\n\nTop feature of importance, here measured as the features with highest absolute value of the Lasso regression coefficients from the final tuned model"
  }
]