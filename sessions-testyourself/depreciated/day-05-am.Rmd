---
title: "Friday morning session"
output:
  html_document: default
  pdf_document: default
  word_document: default
editor_options:
  chunk_output_type: console
---


## Welcome to Friday! Almost there...

In your group discuss:

- yesterday's questions (below); can you agree on the answers?
- anything that you've found confusing or useful yesterday
- and post your answers and comments on our [whiteboard](https://jamboard.google.com/d/15oxwIUbheZfNQMc82B4phuRVr3R4GeOvsxyKrvZ4sR0/edit?usp=sharing)


-----

**Thursday's questions**

1. Total variance is 9. The variance across all components but one is 8. What is the variance explained by the first component?
a) 1
b) 8
c) 8/9
d) 1/9

2. What is the difference between loadings and eigenvectors?
A) They are the same thing
B) Eigenvectors show standard deviation but loadings are the direction in space
C) Eigenvectors are the direction of the largest spread of data and loadings are eigenvectors but scaled with the standard deviation of PCs
D) A, B, and C are incorrect

3. Why should we center the data?
A) Because if we do PCA on noncentered data, the result is not a PCA!
B) Because centering forces the data to have the same scale across the variables
C) Because centering some PCA packages use t(A)%*%(A) to do PCA
D) A and C

4. What is the closest to the definition of clustering?
a) clustering is about finding the objects similarities expressed in (dis)similarities matrix 
b) clustering is about grouping objects together according to similarity
c) clustering is about finding substructures in a data set
d) none of the above

5. Which is not part of the k-means algorithm
a) selecting $k$ initial centroids
b) randomly assigning each data point to one of $K$ clusters to compute the centroids for the initial clusters
c) updating the centroids for each of the $k$ clusters by computing the centroids for all the objects in each of the clusters
d) repeating the above steps until no centroids are left (convergence)

6. What is true about data splitting into train, validation and test in machine learning?
a) we train ML methods such as classification on train data and check models on validation and test data to assess the prediction power on the unknown data sets
b) we use validation data to check if our implementation of ML is working correctly
c) we split data to have multiple dataset to assess ML performance on
d) we use train data to build ML methods, validate data to tune model parameters and test data to assess model predictive performance for the unknown observations

7. Given data below and assuming $k=1$ would a new observation (1,2) be classified as A or B?
```{r, echo=F}
x <- c(1, 1, 2, 4, 4, 2)
y <- c(1, 2, 2, 1, 2, 1)
label <- c("A", "A", "A", "B", "B", "?")

data <- data.frame(x = x,  y=y, label = label)
#print(data)
```

| x 	| y 	| label 	|
|:-:	|:-:	|:-:	|
| 1 	| 1 	| A 	|
| 1 	| 2 	| A 	|
| 2 	| 2 	| A 	|
| 4 	| 1 	| B 	|
| 4 	| 2 	| B 	|
| 2 	| 1 	| ? 	|

8. Which of the below are not part of fitting a decision tree?
a) selecting a variable that gives the best split
b) selecting a variable that has a highest variance
c) partitioning the data based on the variable
d) stop splitting when data is split as much as possible  

