---
title: "Test yourself 04"
output:
  html_document: default
  pdf_document: default
  word_document: default
editor_options:
  chunk_output_type: console
---

Rate your confidence of being able to answer the below questions saying A, B or C, where:

- A. I am confident that I know the answer to this question
- B. I know at least 50% of the answer to this question, within 20 minutes I could find the required resources to enable a complete answer
- C. I am not confident that I can answer the question at this time.

### Part I

1. Could you explain what information PC components capture?

2. Could you explain the difference between loadings and eigenvectors?

3. Could you explain why should we center data in the context of PCA?

4. Could you explain what clustering is? 

5. Could you explain how k-means works?

6. Could you explain why we are using data splitting into train, validation and test in machine learning?

7. Could you explain how knn classification work using example data and Euclidean distance?

8. Could you explain how a decision tree model is generated (fitted)?

### Part II

1. Total variance is 9. The variance across all components but one is 8. What is the variance explained by the first component?
a) 1
b) 8
c) 8/9
d) 1/9

2. What is the difference between loadings and eigenvectors?
A) They are the same thing
B) Eigenvectors show standard deviation but loadings are the direction in space
C) Eigenvectors are the direction of the largest spread of data and loadings are eigenvectors but scaled with the standard deviation of PCs
D) A, B, and C are incorrect

3. Why should we center the data?
A) Because if we do PCA on noncentered data, the result is not a PCA!
B) Because centering forces the data to have the same scale across the variables
C) Because centering some PCA packages use t(A)%*%(A) to do PCA
D) A and C

4. What is the closest to the definition of clustering?
a) clustering is about finding the objects similarities expressed in (dis)similarities matrix 
b) clustering is about grouping objects together according to similarity
c) clustering is about finding substructures in a data set
d) none of the above

5. Which is not part of the k-means algorithm
a) selecting $k$ initial centroids
b) randomly assigning each data point to one of $K$ clusters to compute the centroids for the initial clusters
c) updating the centroids for each of the $k$ clusters by computing the centroids for all the objects in each of the clusters
d) repeating the above steps until no centroids are left (convergence)

6. What is true about data splitting into train, validation and test in machine learning?
a) we train ML methods such as classification on train data and check models on validation and test data to assess the prediction power on the unknown data sets
b) we use validation data to check if our implementation of ML is working correctly
c) we split data to have multiple dataset to assess ML performance on
d) we use train data to build ML methods, validate data to tune model parameters and test data to assess model predictive performance for the unknown observations

7. Given data below and assuming $k=1$ would a new observation (1,2) be classified as A or B?
```{r, echo=F}
x <- c(1, 1, 2, 4, 4, 2)
y <- c(1, 2, 2, 1, 2, 1)
label <- c("A", "A", "A", "B", "B", "?")

data <- data.frame(x = x,  y=y, label = label)
#print(data)
```

| x 	| y 	| label 	|
|:-:	|:-:	|:-:	|
| 1 	| 1 	| A 	|
| 1 	| 2 	| A 	|
| 2 	| 2 	| A 	|
| 4 	| 1 	| B 	|
| 4 	| 2 	| B 	|
| 2 	| 1 	| ? 	|

8. Which of the below are not part of fitting a decision tree?
a) selecting a variable that gives the best split
b) selecting a variable that has a highest variance
c) partitioning the data based on the variable
d) stop splitting when data is split as much as possible  


