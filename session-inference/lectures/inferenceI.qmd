---
title: "Statistical inference, part I"
author: "Eva Freyhult"
date: "2022-09-13"
institute: NBIS, SciLifeLab
format: 
  revealjs:
    slide-number: true
    self-contained: true
    theme: [default, custom.scss]
---

```{r, include=FALSE}
require(tidyverse)
require(ggplot2)
require(reshape2)
require(knitr)
require(kableExtra)
require(latex2exp)
knitr::opts_chunk$set(fig.width=3.5, fig.height=3.5, echo = FALSE, cache=TRUE, error=FALSE, warnings=FALSE, dpi=600)
options(digits=4)
```

# Statistical inference

Statistical inference is to draw conclusions regarding properties of a population based on observations of a random sample from the population.

## Hypothesis test

To perform a hypothesis test is to evaluate a hypothesis based on a random sample.

Typically, the hypotheses that are tested are assumptions about properties of a population, such as proportion, mean, mean difference, variance etc.

## The null and alternative hypothesis

There are two hypotheses involved in a hypothesis test, the **null hypothesis**, $H_0$, and the **alternative hypothesis**, $H_1$.

$H_0$, the **null hypothesis** is in general neutral, "no change", "no difference between groups", "no association".

In general we want to show that $H_0$ is false.

$H_1$, The **alternative hypothesis** expresses what the researcher is interested in "the treatment has an effect", "there is a difference between groups", "there is an association".

The alternative hypothesis can also be directional "the treatment has a positive effect".

## Error types

```{r}
kable(matrix(c("", "H0 is true", "H0 is false", "Accept H0", "", "Type II error, miss", "Reject H0", "Type I error, false alarm", ""), byrow=3, ncol=3))
```

**Type I error** is a false positive, a false alarm that occurs when $H_0$ is rejected when it is actually true. Examples: *"The test says that you are covid-19 positive, when you actually are not", "The test says that the drug has a positive effect on patient symptoms, but it actually has not"*.

**Type II error** is a false negative, a miss that occurs when $H_0$ is accepted, when it is actually false. Examples: *The test says that you are covid-19 negative, when you actually have covid-19", "The test says that the drug has no effect on patient symptoms, when it actually has"*.

## Significance level

```{r}
kable(matrix(c("", "H0 is true", "H0 is false", "Accept H0", "", "Type II error, miss", "Reject H0", "Type I error, false alarm", ""), byrow=3, ncol=3))
```

The significance level, $\alpha$ = P(false alarm) = P(Reject $H_0$\| $H_0$ is true).

<!-- The significance level is the risk to of false alarm, i.e. to say "I have a hit", "I found a difference", when the the null hypothesis ("there is no difference") is true. The risk of false alarm is controll by setting the significance level to a disired value. We do want to keep the risk of false alarm (type I error) low, but at the same time we don't want to many missed hits (type II error). -->

The significance level should be set before the hypothesis test is performed!

Common values of $\alpha$ are 0.05 or 0.01.

## Statistical power

```{r}
kable(matrix(c("", "H0 is true", "H0 is false", "Accept H0", "", "Type II error, miss", "Reject H0", "Type I error, false alarm", ""), byrow=3, ncol=3))
```

Another property of a statistical test is the **statistical power**

power = P(Reject H0|H0 is false).



## To perform a hypothesis test

::: {.smaller style="font-size: 35px"}
1.  Define $H_0$ and $H_1$
. . .
2.  Select appropriate test statistic, $T$, and compute the observed value, $t_{obs}$
. . .
3.  Assume that the $H_0$ is true and compute the sampling distribution of $T$.
. . .
4.  Select an appropriate significance level, $\alpha$
. . .
5.  Compare the observed value, $t_{obs}$, with the computed sampling distribution under $H_0$ and compute a p-value. The p-value is the probability of observing a value at least as extreme as the observed value, if $H_0$ is true.
. . .
6.  Based on the p-value either accept or reject $H_0$.
:::



## Null distribution

A **sampling distribution** is the distribution of a sample statistic. The sampling distribution can be obtained by drawing a large number of samples from a specific population.

The **null distribution** is a sampling distribution when the null hypothesis is true.

```{r examplenull, out.width="70%", fig.show="hold", fig.width=5, fig.align="center", fig.cap="A null distribution"}
x<-seq(-3,3,0.01)
df <- data.frame(x=x, f=dnorm(x, 0, 1))
plot(ggplot(df, aes(x=x, y=f)) + geom_line() + theme_bw() + xlab("x") + ylab("f(x)"))
```

## p-value

The p-value is the probability of the observed value, or something more extreme, if the null hypothesis is true.

```{r examplepval, out.width="70%", fig.align="center", fig.show="hold", fig.width=5, warning=FALSE}
pl <- ggplot(df, aes(x=x, y=f)) + geom_line() + theme_bw() + xlab("x") + ylab("f(x)") + geom_area(data=df %>% filter(x>1.5)) + annotate("label",label=TeX("P( X$\\geq$xobs )"), x=1.8, y=0.11, hjust=0)
plot(pl + scale_x_continuous(breaks=c(-2,0,1.5,2), labels=c("-2","0","xobs", "2")) + theme(panel.grid.minor = element_blank(), panel.grid.major.x = element_line(color = c("grey92", "grey92", NA, "grey92"))))
```

## p-value

The p-value is the probability of the observed value, or something more extreme, if the null hypothesis is true.

```{r examplepval2, out.width="70%", fig.align="center", fig.show="hold", fig.width=5, warning=FALSE}
pl <- pl + geom_area(data=df %>% filter(x<(-1.5))) + annotate("label",label=TeX("P(X$\\leq$-xobs)"), x=-1.8, y=0.11, hjust=1)
plot(pl + scale_x_continuous(breaks=c(-2,-1.5,0,1.5,2), labels=c("-2", "-xobs","0","xobs", "2")) +
     theme(panel.grid.minor = element_blank(),
              panel.grid.major.x = element_line(color = c("grey92", NA, "grey92", NA, "grey92"))))
```

## p-value

If the p-value is above the significance level, $H_0$ is accepted.

If the p-value is below the significance level, $H_0$ is rejected.

## Simulation example

**Do high fat diet lead to increased body weight?**

Study setup:

1.  Order 24 female mice from a lab.
2.  Randomly assign 12 of the 24 mice to receive high-fat diet, the remaining 12 are controls (ordinary diet).
3.  Measure body weight after one week.

The observed values, mouse weights in grams, are summarized below;

```{r miceobs, echo=FALSE}
## 12 HF mice
xHF <- c(25, 30, 23, 18, 31, 24, 39, 26, 36, 29, 23, 32)
## 12 control mice
xN <- c(27, 25, 22, 23, 25, 37, 24, 26, 21, 26, 30, 24)
```

```{r}
kable(rbind("high-fat"=xHF, "ordinary"=xN), digits=1) %>% kable_styling()
```

## Simulation example

**1. Null and alternative hypotheses**

$$
\begin{aligned}
H_0: \mu_2 = \mu_1 \iff \mu_2 - \mu_1 = 0\\
H_1: \mu_2>\mu_1 \iff \mu_2-\mu_1 > 0
\end{aligned}
$$

where $\mu_2$ is the (unknown) mean body weight of the high-fat mouse population and $\mu_1$ is the mean body-weight of the control mouse population.

Studied population: Female mice that can be ordered from a lab.

## Simulation example

**2. Select appropriate significance level** $\alpha$

$$\alpha = 0.05$$

## Simulation example

**3. Test statistic**

Of interest; the mean difference between high-fat and control mice 

$$D = \bar X_2 - \bar X_1$$

Mean weight of 12 (randomly selected) mice on ordinary diet, $\bar X_1$. $E[\bar X_1] = E[X_1] = \mu_1$

Mean weight of 12 (randomly selected) mice on high-fat diet, $\bar X_2$. $E[\bar X_2] = E[X_2] = \mu_2$

Observed values;

```{r, echo=FALSE}
## 12 HF mice
xHF <- c(25, 30, 23, 18, 31, 24, 39, 26, 36, 29, 23, 32)
## 12 control mice
xN <- c(27, 25, 22, 23, 25, 37, 24, 26, 21, 26, 30, 24)

##Compute mean body weights of the two samples
mHF <- mean(xHF)
mN <- mean(xN) 
## Compute mean difference
dobs <- mHF - mN
```

$\bar x_1 = `r sprintf("%.2f", mN)`$, mean weight of control mice (ordinary diet)

$\bar x_2 = `r sprintf("%.2f", mHF)`$, mean weight of mice on high-fat diet

$d_{obs} = \bar x_2 - \bar x_1 = `r dobs`$, difference in mean weights 

## Simulation example

**4. Null distribution**

If high-fat diet has no effect, i.e. if $H_0$ was true, the result would be as if all mice were given the same diet.

The 24 mice were initially from the same population, depending on how the mice are randomly assigned to high-fat and normal group, the mean weights would differ, even if the two groups were treated the same.

Random reassignment to two groups can be accomplished using permutation.

Assume $H_0$ is true, i.e. assume all mice are equivalent and

1.  Randomly reassign 12 of the 24 mice to 'high-fat' and the remaining 12 to 'control'.
2.  Compute difference in mean weights

If we repeat 1-2 many times we get the sampling distribution when $H_0$ is true, the so called null distribution, of difference in mean weights.

## Simulation example

**4. Null distribution**

```{r permtest, echo=FALSE, out.width="50%"}
## All 24 body weights in a vector
x <- c(xHF, xN)
## Mean difference
dobs <- mean(x[1:12]) - mean(x[13:24])

## Permute once
y <- sample(x)
##Compute mean difference
#mean(y[1:12]) - mean(y[13:24])
dnull.perm <- replicate(n = 100000, {
  y <- sample(x)
  ##Mean difference
  mean(y[1:12]) - mean(y[13:24])
})
ggplot(data.frame(d=dnull.perm), aes(x=d)) + geom_histogram(bins=25, color="white") + theme_bw() + geom_vline(xintercept=dobs, color="red")
##Alternatively plot using hist
## hist(dnull.perm)
```

## Simulation example

**5. Compute p-value**

What is the probability to get an at least as extreme mean difference as our observed value, $d_{obs}$, if $H_0$ was true?

```{r micepval, echo=FALSE, eval=FALSE}
## Compute the p-value
sum(dnull.perm>dobs)/length(dnull.perm)
mean(dnull.perm>dobs)
```

$P(\bar X_2 - \bar X_2 \geq d_{obs} | H_0) =$ `r sprintf("%.3g",mean(dnull.perm>=dobs))`

## Simulation example

**6. Conclusion?**




## Multiple testing
### Error types

:::: {.columns}
:::{.column width="50%"}
```{r}
kable(matrix(c("", "H0 is true", "H0 is false", "Accept H0", "", "Type II error, miss", "Reject H0", "Type I error, false alarm", ""), byrow=F, ncol=3)) %>% kable_styling()
```
:::
::: {.column width="50%}
:::
::::

## Multiple testing
### Error types

:::: {.columns}
:::{.column width="50%"}
```{r}
kable(matrix(c("", "H0 is true", "H0 is false", "Accept H0", "", "Type II error, miss", "Reject H0", "Type I error, false alarm", ""), byrow=F, ncol=3)) %>% kable_styling()
```
:::

::: {.column width="50%}

```{r}
kable(matrix(c("", "H0 is true", "H0 is false", "Accept H0", "TN", "FN", "Reject H0", "FP", "TP"), byrow=F, ncol=3)) %>% kable_styling()
```

:::

::::


## Multiple testing
### Error types

:::: {.columns}
:::{.column width="50%"}
```{r}
kable(matrix(c("", "H0 is true", "H0 is false", "Accept H0", "", "Type II error, miss", "Reject H0", "Type I error, false alarm", ""), byrow=F, ncol=3)) %>% kable_styling()
```
:::

::: {.column width="50%}

```{r}
kable(matrix(c("", "H0 is true", "H0 is false", "Accept H0", "TN", "FN", "Reject H0", "FP", "TP"), byrow=F, ncol=3)) %>% kable_styling()
```

:::

::::

**Significance level**

$$P(\mbox{reject }\,H_0 | H_0 \,\mbox{is true}) = P(\mbox{type I error}) = \alpha$$
  
**Statistical power**

$$P(\mbox{reject } H_0 | H_1 \mbox{ is true}) = P(\mbox{reject } H_0 | H_0 \mbox{ is false}) = 1 - P(\mbox{type II error})$$

## Multiple tests

:::: {.columns}
::: {.column width="50%"}

### Perform one test:
  
  - P(One type I error) = $\alpha$
  - P(No type I error) = $1 - \alpha$
  
### Perform $m$ independent tests:
  
  - P(No type I errors in $m$ tests) = $(1 - \alpha)^m$
  - P(At least one type I error in $m$ tests) = $1 - (1 - \alpha)^m$
  
:::

::: {.column width="50%"}

```{r multiple, echo=FALSE, out.width="100%", fig.align="center", fig.width=4, fig.height=4}
a=0.05
k <- 1:100
ggplot(data.frame(k=k, p = 1-(1-a)^k), aes(x=k, y=p)) + geom_line() + xlab("Number of tests") + ylab("P(At least one type I error)") + theme_bw() + annotate("label", x=75, y=0.2, label="alpha == 0.05", parse=TRUE)
```

:::

::::

## Multiple test correction

- FWER: family-wise error rate, control the probability of one or more false positive, e.g. Bonferroni, Holm
- FDR: false discovery rate, control the proportion of false positives among the hits, e.g. Benjamini-Hochberg, Storey

## Bonferroni correction

To achieve a family-wise error rate of $\leq \alpha$ when performing $m$ tests, declare significance and reject the null hypothesis for any test with $p \leq \alpha/m$.

Objections: too conservative

## Benjamini-Hochbergs FDR

```{r}
kable(matrix(c("", "H0 is true", "H0 is false", "Accept H0", "TN", "FN", "Reject H0", "FP", "TP"), byrow=3, ncol=3)) %>% kable_styling()
```

The false discovery rate is the proportion of false positives among 'hits', i.e. $\frac{FP}{TP+FP}$.


Benjamini-Hochberg's method control the FDR level, $\gamma$, when performing $m$ *independent* tests, as follows:
  
1. Sort the p-values $p_1 \leq p_2 \leq \dots \leq p_m$.
2. Find the maximum $j$ such that $p_j \leq \gamma \frac{j}{m}$.
3. Declare significance for all tests $1, 2, \dots, j$.

## 'Adjusted' p-values
  
Sometimes an adjusted significance threshold is not reported, but instead 'adjusted' p-values are reported.
  
- Using Bonferroni's method the 'adjusted' p-values are:
  
  $\tilde p_i = \min(m p_i, 1)$.

A feature's adjusted p-value represents the smallest FWER at which the null hypothesis will be rejected, i.e. the feature will be deemed significant.
  
- Benjamini-Hochberg's 'adjusted' p-values are called $q$-values:
  
  $q_i = \min(\frac{m}{i} p_i, 1)$
  
  A feature's $q$-value can be interpreted as the lowest FDR at which the corresponding null hypothesis will be rejected, i.e. the feature will be deemed significant.

<!-- --- -->

## Example, 10000 independent tests (e.g. genes) {-}

```{r padjust, results="asis"}
p <- sort(c(1.7e-8, 5.8e-8, 3.4e-7, 9.1e-7, 1.0e-6, 2.4e-6, 3.6e-5, 2.3e-5, 2.3e-4, 2.2e-4, 8.9e-3,7.3e-4, 0.0045, 0.0032, 0.0087, 0.012, 0.014, 0.045, 0.08, 0.23))
kable(data.frame(`p-value`=sprintf("%.3g", p), `adj p (Bonferroni)` = p.adjust(p, "bonferroni", 10000), `q-value (B-H)`=p.adjust(p, "BH", 10000), check.names=FALSE))
```

