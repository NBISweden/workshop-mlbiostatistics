---
editor: source
title: "Statistical inference, part III"
subtitle: "Point and interval estimates"
author: "Eva Freyhult"
date: "2024-04-23"
date-format: long
institute: NBIS, SciLifeLab
format: 
  revealjs:
    slide-number: true
    self-contained: true
    auto-stretch: false
    theme: [default, custom.scss]
---

```{r, include=FALSE}
require(tidyverse)
require(ggplot2)
require(reshape2)
require(knitr)
require(kableExtra)
require(latex2exp)
library(ggforce)
knitr::opts_chunk$set(fig.width=3.5, fig.height=3.5, echo = FALSE, cache=TRUE, error=FALSE, warnings=FALSE, dpi=600)
options(digits=4)
```

## Point estimate

Unknown population parameters can be inferred from estimates from random samples from the population of interest. The sample estimate will be our best guess, a **point estimate**, of the population parameter.

The sample proportion and sample mean are **unbiased** estimates of the population proportion and population mean.

The expected value of an **unbiased** point estimate is the the population parameter that it estimates.

The sample estimate is our best guess, but it will not be without error.


## Bias and precision

```{r}
#| label: fig-biasprecision
#| fig-cap: "Bias and precision."
#| message: false
#| warning: false
#| echo: false
#| out-width: "70%"
bias <- c(Biased=1.5, Unbiased=0)
precision= c(Precise=0.5, Unprecise=2)
df <- data.frame(B=rep(names(bias), each=2), P=rep(names(precision),2)) |> mutate(m=bias[B], s=precision[P]) |> group_by(B, P) |> reframe(x=rnorm(10, mean=m, sd=s), y=rnorm(10, mean=m, sd=s)) 

ggplot() + geom_point(data=df, aes(x=x, y=y, color=B, shape=P)) + facet_grid(B~P) + geom_circle(data=data.frame(x0=0, y0=0,r=1:6), aes(x0=x0,y0=y0,r=r)) + theme_classic() + theme(panel.grid=element_blank(), axis.ticks  = element_blank(), axis.text=element_blank(), legend.position = "none") + xlab("") + ylab("")
```

:::{.notes}
The expected value of an **unbiased** point estimate is the the population parameter that it estimates. This means that if you would repeat the sampling many times and compute the point estimate of interest, e.g. sample mean, the average of the sample means would be the population mean.
:::

## Interval estimates

To show the uncertainty an **interval estimate** for a population parameter can be computed based on sample data, instead of just a point estimate.

An interval estimate is an interval of possible values that with high probability contains the true population parameter.

The width of the interval estimate can be determined from the sampling distribution.

## Bootstrap interval

If the sampling distribution of the sample statistic of interest is unknown, a bootstrap interval can be computed instead.

Bootstrap is to use the data we have (our sample) and sample repeatedly with replacement from this sample.

Put the entire sample in an urn and resample!

## Bootstrap interval

**Pollen example**

If we are interested in how large proportion of the Uppsala population is allergic to pollen, we can investigate this by studying a random sample. We randomly select 100 persons in Uppsala and observe that 42 have a pollen allergy.

Based on this observation our point estimate of the Uppsala popultation proportion $\pi$ is $\pi \approx p = 0.42$.

```{r pollenurn42, echo=FALSE, out.width = "20%", fig.align="center"}
knitr::include_graphics("figures/pollenurn42.png")
```

Sample from the urn with replacement to compute the bootstrap distribution.

## Bootstrap interval

**Pollen example**

:::: {.columns}
::: {.column width="50%"}

Sample an object with replacement 100 times and note the proportion allergic (black balls).

Repeat this many times to get a bootstrap distribution

Using the bootstrap distribution the uncertainty of our estimate of $\pi$ can be estimated.

```{r}
x <- rep(0:1, c(58, 42))
pboot <- replicate(100000, mean(sample(x, replace=TRUE)))
ciboot <- quantile(pboot, c(0.025, 0.975))
```

The 95% bootstrap interval is [`r ciboot`].

The bootstrap is very useful if you do not know the distribution of our sampled propery. But in our example we actually do.
:::
::: {.column width="50%"}
```{r CIboot, out.width="95%", fig.align="center"}
ggplot(data.frame(x=pboot), aes(x=x, fill=x>ciboot[1] & x<ciboot[2])) + geom_histogram(color="white", binwidth=0.02) + theme_bw() + theme(legend.position="none") + xlab("p") + geom_line(data=data.frame(x=ciboot, y=5000), aes(x=x, y=y), arrow=arrow(ends="both")) + annotate("label", x=mean(ciboot), y=5000, label="95%")
```   
:::
::::


## Confidence interval

A confidence interval is a type of interval estimate associated with a confidence level. 

> An interval that with probability $1 - \alpha$ cover the population parameter $\theta$ is called a confidence interval for $\theta$ with confidence level $1 - \alpha$.

## Sampling distribution of mean

$$\bar X \sim N(\mu, \frac{\sigma}{\sqrt{n}})$$

```{r meanX, out.width="100%", fig.align="center", fig.width=7}
x<-seq(-3.5,3.5,.01)
df.nwt <- data.frame(x=x, f=dnorm(x))
lbl <- sprintf("%iSE", -3:3)
lbl[4]=expression(mu)
pl <- ggplot(df.nwt, aes(x=x, y=f)) + geom_line() + theme_bw() + theme_bw() + scale_x_continuous(breaks=-3:3, labels=lbl) + xlab("")
pl
```

## Sampling distribution of mean

$$\bar X \sim N(\mu, \frac{\sigma}{\sqrt{n}})$$

```{r meanX1, out.width="100%", fig.align="center", fig.width=7}
pl <- pl + geom_vline(xintercept=-1.96) + geom_vline(xintercept=1.96)  + geom_line(data=data.frame(x=c(-1.96, 1.96), y=0.18), aes(x=x, y=y), arrow=arrow(ends="both")) + annotate("label", x=0, y=0.18, label="95%")
pl
```


## Sampling distribution of mean

$$\bar X \sim N(\mu, \frac{\sigma}{\sqrt{n}})$$

```{r meanX2, out.width="100%", fig.align="center", fig.width=7}
set.seed(1111)
samples <- data.frame(x=rnorm(40), y=-Inf) |> mutate(col=x>1.96|x<(-1.96))
pl + geom_point(data=samples[1,,drop=FALSE], aes(x=x, y=y, color=col), shape="|", stroke=10) + theme(legend.position = "none") + scale_color_manual(values=c("black", "red"))
```


## Sampling distribution of mean

$$\bar X \sim N(\mu, \frac{\sigma}{\sqrt{n}})$$

```{r meanX3, out.width="100%", fig.align="center", fig.width=7}
set.seed(1111)
samples <- data.frame(x=rnorm(40), y=-Inf) |> mutate(col=x>1.96|x<(-1.96))
pl + geom_point(data=samples, aes(x=x, y=y, color=col), shape="|", stroke=10) + theme(legend.position = "none") + scale_color_manual(values=c("black", "red"))
```

## Confidence interval of mean

If $\sigma$ is known

$$Z = \frac{\bar X - \mu}{SEM} = \frac{\bar X - \mu}{\frac{\sigma}{\sqrt{n}}} \sim N(0, 1)$$

## Standard normal distribution

$$P\left(-z_{\alpha/2} < Z <z_{\alpha/2}\right) = 1-\alpha$$

```{r ZCI95, out.width="60%", fig.show="hold", fig.width=5, fig.height=3.5, fig.align="center", warning=FALSE}
x<-seq(-3,3,0.01)
df <- data.frame(x=x, f=dnorm(x, 0, 1))
pl <- ggplot(df, aes(x=x, y=f)) + geom_line() + theme_bw() + xlab("z") + ylab("f(z)") + scale_x_continuous(breaks=c(-1.5,0,1.5), labels=c("-z","0","z")) +
     theme(panel.grid.minor = element_blank(),
              panel.grid.major.x = element_line(color = c("grey92", NA, "grey92", NA, "grey92")))
pl  + geom_area(data=df %>% filter(x>(-1.5) & x<1.5)) + annotate("label",label=TeX("$P(-z_{\\alpha/2} \\leq Z \\leq z_{\\alpha/2}) = 1 - \\alpha$"), x=0, y=0.11, hjust=0.5)
```


## Standard normal distribution

$$P\left(-z_{\alpha/2} < Z <z_{\alpha/2}\right) = 1-\alpha$$

```{r ZCI95a, out.width="60%", fig.show="hold", fig.width=5, fig.height=3.5, fig.align="center", warning=FALSE}
pl <- pl + geom_area(data=df %>% filter(x<(-1.5))) + annotate("label",label=TeX("$P(Z \\leq -z)=\\alpha/2$"), x=-1.6, y=0.07, hjust=1, size=3) + geom_area(data=df %>% filter(x>1.5)) + annotate("label",label=TeX("$P(Z \\geq z) = \\alpha/2$"), x=1.6, y=0.07, hjust=0, size=3)
plot(pl)
```

$z_{\alpha/2}$ is the value such that $P(Z \geq z_{\alpha/2}) = \frac{\alpha}{2} \iff P(Z \leq z_{\alpha/2}) = 1 - \frac{\alpha}{2}$.

For a 95% confidence, $\alpha = 0.05$, and $z_{\alpha/2} = 1.96$. For 90% or 99% confidence $z_{0.05} = 1.64$ and $z_{0.005}=2.58$. 


## Confidence interval of mean

If $\sigma$ is known

$$Z = \frac{\bar X - \mu}{SEM} = \frac{\bar X - \mu}{\frac{\sigma}{\sqrt{n}}} \sim N(0, 1)$$
From the standard normal distribution we know;

$$P(z_{\alpha/2}<Z<z_{\alpha/2}) = 1-\alpha$$

. . .

$$P(z_{\alpha/2}<\frac{\bar X-\mu}{SEM}<z_{\alpha/2}) = 1-\alpha$$

. . .

$$P(\mu-z_{\alpha/2}SEM<\bar X<\mu+z_{\alpha/2}SEM) = 1-\alpha$$

. . .

$$P(\bar X-z_{\alpha/2}SE<\mu<\bar X+z_{\alpha/2}SE) = 1-\alpha$$



:::{.notes}
On board show what this means, i.e. an observed samples mean and the CI around it
:::

## Confidence interval of mean

If $\sigma$ is known

$$Z = \frac{\bar X - \mu}{SEM} = \frac{\bar X - \mu}{\frac{\sigma}{\sqrt{n}}} \sim N(0, 1)$$

The confidence interval with confidence level $1-\alpha$;

$$[\bar x_{obs} - z_{\alpha/2}SEM, \bar x_{obs} + z_{\alpha/2}SEM]$$

or 

$$\mu = \bar x_{obs} \pm z_{\alpha/2}SEM$$
where $SEM = \frac{\sigma}{\sqrt{n}}$.

## Confidence interval of mean

The mean of a sample of $n$ independent and identically normal distributed observations $X_i$ is normally distributed;

$$\bar X \sim N(\mu, \frac{\sigma}{\sqrt{n}})$$
  
If $\sigma$ is unknown  and $n$ is small?

. . .


Use the statistic $t=\frac{\bar X - \mu}{SEM} = \frac{\bar X - \mu}{\frac{s}{\sqrt{n}}} \sim t(n-1)$, t-distributed with $n-1$ degrees of freedom.

. . .

::::{.columns}
:::{.column width="50%"}
It follows that 

$$
\begin{aligned}
P\left(-t < \frac{\bar X - \mu}{\frac{s}{\sqrt{n}}} < t\right) = 1 - \alpha \iff \\
P\left(\bar X - t \frac{s}{\sqrt{n}} < \mu < \bar X + t \frac{}{\sqrt{n}}\right) = 1 - \alpha
\end{aligned}
$$
:::

:::{.column width="50%" .fragment .fade-in}

The confidence interval;

$$[\bar x_{obs} - t \frac{s}{\sqrt{n}}, \bar x_{obs} + t \frac{s}{\sqrt{n}}]$$

or 

$$\mu = \bar x_{obs} \pm t \frac{s}{\sqrt{n}}$$
:::
::::


## Confidence interval of mean

The confidence interval with confidence level $1-\alpha$ is thus;

$$\mu = \bar x_{obs} \pm t \frac{s}{\sqrt{n}}$$
  
For a 95% confidence interval and $n=5$, $t=$ `r qt(.975, df=4)`.

The $t$ values for different values of $\alpha$ and degrees of freedom are tabulated and can be computed in R using the function `qt`.

```{r, echo=TRUE}
n=5
alpha = 0.05
## t value
qt(1-alpha/2, df=n-1)
```

## Example

You study the BMI of male diabetic patients. In a sample of size 6 you observe; $27, 25, 31, 29, 30, 22$. Assume that the BMI is normally distributed and calculate a 95% confidence interval for the mean BMI in male diabetic patients.


## Confidence interval of proportions

Remember that we can use the central limit theorem to show that 

$$P \sim N\left(\pi, SE\right) \iff P \sim \left(\pi, \sqrt{\frac{\pi(1-\pi)}{n}}\right)$$

. . .
  
It follows that 

$$Z = \frac{P - \pi}{SE} \sim N(0,1)$$
Based on what we know of the standard normal distribution, we can compute an interval around the population property $\pi$ such that the probability that a sample property $p$ falls within this interval is $1-\alpha$.


## Confidence interval of proportion

$$P\left(-z_{\alpha/2} < Z <z_{\alpha/2}\right) = 1-\alpha\\
P(-z_{\alpha/2} < \frac{P - \pi}{SE} < z_{\alpha/2}) = 1 - \alpha$$

We can rewrite this to

$$P\left(\pi-z_{\alpha/2} SE < P < \pi + z_{\alpha/2} SE\right) = 1-\alpha$$
In words, a sample fraction $p$ will fall between $\pi \pm z_{\alpha/2} SE$ with probability $1- \alpha$.

The equation can also be rewritten to 

$$P\left(P-z SE < \pi < P + z SE\right) = 1 - \alpha$$

## Confidence interval of proportion

The observed confidence interval is what we get when we replace the random variable $P$ with our observed fraction,

$$p-z SE < \pi < p + z SE$$
$$\pi = p \pm z SE = p \pm z \sqrt{\frac{p(1-p)}{n}}$$

## Confidence interval of proportion

The 95% confidence interval $$\pi = p \pm 1.96 \sqrt{\frac{p(1-p)}{n}}$$

## Confidence interval of proportion

A 95% confidence interval will have 95% chance to cover the true value.

```{r CIallergy, fig.width=7, fig.height=3}
set.seed(13)
p <- replicate(100, mean(sample(0:1, 100, p=c(.7,.3), replace=TRUE)))
ggplot(data.frame(x=1:40, p=p[61:100]) %>% mutate(ymin=p-1.96*sqrt((p*(1-p))/100), ymax=p+1.96*sqrt((p*(1-p))/100)), aes(x=x, ymin=ymin, ymax=ymax, color=0.3>ymin & 0.3<ymax)) + geom_errorbar() + geom_hline(yintercept=0.3) + xlab("") + ylab("p") + theme_bw() + theme(legend.position="none")
```

## Confidence interval of proportion

Back to our example of proportion pollen allergic in Uppsala. $p=0.42$ and $SE=\sqrt{\frac{p(1-p)}{n}} = `r sqrt(0.42*(1-0.42)/100)`$.

Hence, the 95% confidence interval is 
$$\pi = 0.42 \pm 1.96 * 0.05 = 0.42 \pm 0.092$$
  or
$$(0.42-0.092, 0.42+0.092) = (0.32, 0.52)$$

