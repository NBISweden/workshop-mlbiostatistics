[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Survival Analysis",
    "section": "",
    "text": "Preface\nAims\n\nto introduce survival analysis\n\nLearning outcomes\n\nTBD\n\nDo you see a mistake or a typo? We would be grateful if you let us know via edu.ml-biostats@nbis.se\nThis repository contains teaching and learning materials prepared for and used during “Introduction to biostatistics and Machine Learning” and “Biostatistics and Machine Learning II” courses, organized by NBIS, National Bioinformatics Infrastructure Sweden. The courses are open for PhD students, postdoctoral researcher and other employees within Swedish universities. The materials are geared towards life scientists wanting to be able to understand and use the basic statistical and machine learning methods. More about the course https://nbisweden.github.io/workshop-mlbiostatistics/",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Why survival analysis?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#why-survival-analysis",
    "href": "intro.html#why-survival-analysis",
    "title": "1  Introduction",
    "section": "",
    "text": "The term survival analysis refers to statistical methods developed to study time-to-event data, originally applied to time until death in 17th-century mortality studies, which is where the term “survival” originates.\nOver the decades its scope has broadened to include a wide range of applications in both medical studies and beyond, in fields such as marketing, engineering or criminology and many more.\nThe common factor in survival analysis is the study of censored data that arise when studying a unique kind of outcome variable: time until an event occurs.\nThis event, can be death, as previously mentioned, but also disease onset or relapse in medical studies. In other fields, we can study time until next purchase (marketing), time until machine failure (engineering), time until a released prisoner commits another crime (criminology), and many more.\nIn fact, survival analysis is applicable whenever censored data occurs, and these cases are not limited to studying time-based events. We can use survival analysis methods to study the number of treatment sessions until a patient recovers or the number of attempts until a student passes an exam.\nCensoring occurs when the event of interest has not yet been observed by the end of the study. This makes survival analysis especially useful for incomplete data sets, where we can still make use of the available information to estimate the time to event.\nWith survival analysis, we can compare groups (e.g., treatment vs. control) and determine which factors increase or decrease the hazard (risk) of the event occurring over time, even when adjusting for other variables.\nWe can incorporate time-dependent variables, allowing the analysis to account for changing risk factors, such as fluctuating health conditions or environmental factors, and include multiple states and/or events. For example, a patient may progress through different stages of a disease (multiple states), or a patient dying from different causes may prevent the occurrence of the primary event being studied (multiple events, competing risks).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#survival-and-censoring-times",
    "href": "intro.html#survival-and-censoring-times",
    "title": "1  Introduction",
    "section": "1.2 Survival and censoring times",
    "text": "1.2 Survival and censoring times\nLet’s imagine a mortality study of terminally ill patients receiving a certain medical treatment. We follow a group of patients over 24 months follow-up period and record the time until death or until the end of the study. For each patient, we suppose there is:\n\na true survival time \\(T\\) and\na censoring time \\(C\\).\n\nThe survival time represents the time at which the event of interest occurs, here death. The censoring time represents the time at which the patient is lost to follow-up (e.g. withdraws from the study) or the study ends.\nWe observe the random variable \\[Y = min (T, C)\\]\nIf the event occurs before censoring (i.e. \\(T &lt; C\\)) then we observe the true survival time \\(T\\). Otherwise, if censoring occurs before the event (i.e. \\(T &gt; C\\)), we observe the censoring time \\(C\\).\nWe also observe a status indicator\n\\[\\begin{equation}\n    \\sigma =\n    \\left\\{\n        \\begin{array}{cc}\n                1 & \\mathrm{if\\ } T \\le C \\\\\n                0 & \\mathrm{if\\ } T&gt;C \\\\\n        \\end{array}\n    \\right.\n\\end{equation}\\]\nA figure below illustrates the data for 10 patients in this ficitious study.\n\n\nCode\n# Example data for 10 patients\ndata &lt;- data.frame(\n  patient = factor(1:10),     # Patient IDs\n  time = c(23, 24, 9, 7, 14, 16, 19, 20, 24, 24),  # Time to event or censoring\n  status = c(1, 0, 1, 0, 1, 1, 0, 1, 0, 1)       # Event status (1 = event, 0 = censored)\n)\n\n# Plot the data with horizontal lines\nggplot(data, aes(x = time, y = patient)) +\n  geom_segment(aes(x = 0, xend = time, y = patient, yend = patient), color = mycols[2]) +  #\n  geom_point(aes(shape = factor(status)), size = 3) +  \n  geom_vline(xintercept = 24, linetype = \"dashed\") +\n  scale_shape_manual(values = c(1, 16),               \n                     labels = c(\"Censored\", \"Event\")) +\n  labs(x = \"Time (months)\", y = \"Patient\", shape = \"Status\") +  \n  theme_minimal() +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\nFigure 1.1: Example of right-censored data in a mortatily study lasting 24 months. The horizontal lines represent the time to event or censoring for each patient. The points indicate whether the event occurred (event) or not (censored).\n\n\n\n\n\nWe we observe 10 \\((Y, \\sigma)\\) pairs, which we denote as \\((y_1, \\sigma_1, \\dots, (y_n, \\sigma_n))\\), where \\(n = 10\\). From Figure 1.1, we can see that:\n\nfor patient #1 we get \\((y_1= t_1, \\space \\sigma_1 = 1)\\) since we observe event (death) as ca. 23 months, before the end of the follow-up at 24 months.\nfor patient #2 we get \\((y_2= c_1, \\space \\sigma_1 = 0)\\) since the patient is still alive at the end of the study at 24 moths, meaning that the patient has survied at least 24 months (censored)\nfor patient #3 we get \\((y_3= t_3, \\space \\sigma_3 = 1)\\) since we observe event (death) at 9 months\nfor patients #4, we get \\((y_4= c_4, \\space \\sigma_4 = 0)\\), anther censored data point. The study is not over yet, the patient has not diet but is lost to follow-up, e.g. due to withdrawing from the study\nanalogously, for patients #5, #6, #8 and #10 we observe survival times, and for patients #7 and #9 we observe censoring times.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#independent-censoring",
    "href": "intro.html#independent-censoring",
    "title": "1  Introduction",
    "section": "1.3 Independent censoring",
    "text": "1.3 Independent censoring\nIn order to analyze survival data, we need to make some assumptions about the censoring process. One of the key assumptions in survival analysis is independent censoring. This assumption states that the reason for censoring is unrelated to the likelihood of the event occurring. In other words, censored individuals should have the same probability of experiencing the event as those who remain in the study.\nFor example, in a cancer study, if a number of patients leave the study for reasons unrelated to their health status, their data can be treated as censored without biasing the results, since censoring does not provide any information about the outcome. However, if a number of patients drop out early because they are very sick, this would violate the assumption of the independent censoring.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#left-and-interval-censoring",
    "href": "intro.html#left-and-interval-censoring",
    "title": "1  Introduction",
    "section": "1.4 Left and interval censoring",
    "text": "1.4 Left and interval censoring\nIn addition to right-censored data, we may encounter left and/or interval-censored data. Left censoring occurs when the event happened before the observation period started, whereas interval censoring occurs when the event is known to have happened between two specific time points within the study.\nImagine an age study in which left censoring occurs when a patient was diagnosed with a disease before the study began, but the exact age of diagnosis is unknown. For example, if a patient is known to have been diagnosed before age 25, but the exact age is not recorded, they are left-censored. Interval censoring occurs when a patient’s diagnosis happens between two observed ages, but the exact age of diagnosis is unknown. For instance, if a patient was healthy at age 45 and diagnosed by age 55, but the precise age of diagnosis isn’t known, their data is interval-censored.\n\n\nCode\n# Create a data frame for 8 patients\n# Left-censored patients were diagnosed before the study, and interval-censored patients were diagnosed between visits\ndata &lt;- data.frame(\n  patient_id = 1:8,\n  start_age = c(NA, 30, 40, 35, NA, 25, 45, 50),   # Start of observation or known age for interval censoring (NA for left-censored)\n  end_age = c(25, 35, 45, 50, 20, 40, 55, 60),     # Age of diagnosis or end of observation\n  type = c(\"Left Censored\", \"Fully Observed\", \"Fully Observed\", \"Fully Observed\", \n                     \"Left Censored\", \"Interval Censored\", \"Interval Censored\", \"Fully Observed\")\n)\n\n# Plot the data\nggplot(data, aes(x = end_age, y = factor(patient_id), color = type)) +\n  # Add points for observed ages (diagnosis age or censoring)\n  geom_point(size = 4) +\n  \n  # For interval-censored patients, add a horizontal line to show the interval\n  geom_segment(data = subset(data, type == \"Interval Censored\"), aes(x = start_age, xend = end_age, y = factor(patient_id), yend = factor(patient_id)),\n               color = mycols[2], linetype = \"dashed\") +\n  \n  # For left-censored patients, add an arrow showing the uncertainty before diagnosis\n  geom_segment(data = subset(data, type == \"Left Censored\"), aes(x = 0, xend = end_age, y = factor(patient_id), yend = factor(patient_id)),\n               color = mycols[1], linetype = \"dotted\", arrow = arrow(length = unit(0.2, \"cm\"))) +\n  \n  # Customize the plot labels and appearance\n  labs(x = \"Age\", y = \"Patient ID\") +\n  scale_color_manual(values = c(\"Left Censored\" = mycols[1], \"Fully Observed\" = \"black\", \"Interval Censored\" = mycols[2])) +\n  theme_minimal() + \n  theme(legend.position = \"top\", legend.title = element_blank())\n\n\n\n\n\n\n\n\nFigure 1.2: Example of left and interval censoring in an age study. Left-censored patients were diagnosed before the study, and interval-censored patients were diagnosed between visits.\n\n\n\n\n\nIn this session, we will focus on right censored data.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#kaplan-meier-estimator",
    "href": "intro.html#kaplan-meier-estimator",
    "title": "1  Introduction",
    "section": "1.5 Kaplan-Meier estimator",
    "text": "1.5 Kaplan-Meier estimator\nThe survival curve, or survival function, is a decreasing function that quantifies the probability of surviving past time \\(t\\) and is defined as \\[S(t) = Pr(T &gt; t) \\tag{1.1}\\]\nThe Kaplan-Meier (KM) estimator is a non-parametric statistic used to estimate the survival function from lifetime data and is given by: \\[\\hat{S}(t) = \\prod_{j=1}^{t} \\left( 1 - \\frac{d_j}{n_j} \\right) \\tag{1.2}\\]\nwhere:\n\n\\(d_j\\): number of failures at time \\(t_j\\)\n\\(n_j\\): number of patients at risk just before time \\(t_ij\\)\nand the product is taken over all time intervals in which a death occurred, up to and including \\(t\\)\n\nKapalan-Meier estimator is also known as product-limit estimator.\n\n1.5.1 Tooth filling example\n\n1.5.1.1 Complete follow-up data\nSuppose we have 10 patients who receive a tooth filling, and we want to track how long these fillings last before they fail (fall out or need replacement). The failure times (in months) for each patient are recorded:\n\n\nCode\ndata_tooth &lt;- data.frame(\n  patientID = 1:10,\n  time = c(10, 8, 11,  5, 4,  3,  7,  6, 12,  8), \n  surv = 1\n)\n\nstr(data_tooth)\n\n\n'data.frame':   10 obs. of  3 variables:\n $ patientID: int  1 2 3 4 5 6 7 8 9 10\n $ time     : num  10 8 11 5 4 3 7 6 12 8\n $ surv     : num  1 1 1 1 1 1 1 1 1 1\n\n\nNote that the surv column is a binary indicator of survival status (1 = event, 0 = censored). In this example, we assume all patients have experienced the event (failure) and have complete follow-up data.\nTo calculate the Kaplan-Meier Curve:\n\nWe sort the data by time to failure.2.\nFor each time, we calculate the survival probabilities, i.e. the probability the filling lasting beyond that time.\nWe apply the Kaplan-Meier formula (Equation 1.2) to calculate the probability of surviving up to time \\(t\\), as the product of all individual survival probabilities at each time up to \\(t\\):\n\nIn our example:\n\n\n\n\n\n\n\n\n\n\nTime  (months)\nPatients at Risk  \\(n_i\\)\nFailures  \\(d_i\\)\nSurvival Probability  at \\(t_i\\)\nCumulative Survival  \\(S(t)\\)\n\n\n\n\n3\n10\n1\n1 - \\(\\frac{1}{10}\\) = 0.9\n0.9\n\n\n4\n9\n1\n1 - \\(\\frac{1}{9}\\) = 0.888\n0.9 \\(\\times\\) 0.888 = 0.8\n\n\n5\n8\n1\n1 - \\(\\frac{1}{8}\\) = 0.875\n0.8 \\(\\times\\) 0.875 = 0.7\n\n\n6\n7\n1\n1 - \\(\\frac{1}{7}\\) = 0.857\n0.7 \\(\\times\\) 0.857 = 0.6\n\n\n7\n6\n1\n1 - \\(\\frac{1}{6}\\) = 0.833\n0.6 \\(\\times\\) 0.833 = 0.5\n\n\n8\n5\n2\n1 - \\(\\frac{2}{5}\\) = 0.6\n0.5 \\(\\times\\) 0.6 = 0.3\n\n\n10\n3\n1\n1 - \\(\\frac{1}{3}\\) = 0.667\n0.3 \\(\\times\\) 0.667 = 0.2\n\n\n11\n2\n1\n1 - \\(\\frac{1}{2}\\) = 0.5\n0.2 \\(\\times\\) 0.5 = 0.1\n\n\n12\n1\n1\n1 - \\(\\frac{1}{1}\\) = 0\n0.1 \\(\\times\\) 0 = 0\n\n\n\nWe can see that:\n\nAt 3 months: 10 patients are at risk, and 1 failure occurs, so the survival probability for this period is 0.9.\nFor 4 months: 9 patients are at risk (since one patient failed at 3 months), and the survival probability is now cumulative (0.9 from the first interval multiplied by 0.888 from this interval).\nAt time 8 months: two failures occur and the survival probability drops more sharply.\nAt time 12 months: the survival probability reaches 0, indicating that all patients experienced the event (tooth filling failure) by the end of the study.\n\nWe can visualize the Kaplan-Meier curve for this data:\n\n\nCode\nfit.surv &lt;- survfit(Surv(time, surv) ~ 1, data = data_tooth)\nplot(fit.surv, conf.int=FALSE,  xlab = \"Months\", ylab = \"Estiamted Probabiliy of Survival\")\n\n\n\n\n\n\n\n\nFigure 1.3: Kaplan-Meier survival curve for tooth filling data. The curve shows the estimated probability of survival (filling intact) over time.\n\n\n\n\n\n\n\n1.5.1.2 Including censored data\nIn real life, not all patients may have complete follow-up data. Some patients might drop out of the study (e.g., move away or lose contact). This is called censoring, and these patients are still considered “alive” (their fillings intact) at the time they are censored, but we do not know what happens to them afterward. The filling can also be intact at the end of the study, but we do not know how long it will last.\nLet’s update the data with censoring for two patients:\n\n\n\nPatient\nTime to Failure (months)\nCensored\n\n\n\n\n1\n3\nNo\n\n\n2\n4\nNo\n\n\n3\n5\nYes\n\n\n4\n6\nNo\n\n\n5\n7\nNo\n\n\n6\n8\nNo\n\n\n7\n8\nNo\n\n\n8\n10\nYes\n\n\n9\n11\nNo\n\n\n10\n12\nNo\n\n\n\nNow, we can adjust the KM calculations to account for censored data. For censored patients, we do not count them in the number of events (failures), but they are still included in the “at-risk” population until they are censored.\n\n\n\n\n\n\n\n\n\n\n\nTime(months)\nPatients at Risk\\(n_i\\)\nFailures\\(d_i\\)\nC\nSurvival Probability at \\(t_i\\)\nCumulative Survival\\(S(t)\\)\n\n\n\n\n3\n10\n1\n0\n\\(1 - \\frac{1}{10} = 0.9\\)\n0.9\n\n\n4\n9\n1\n0\n\\(1 - \\frac{1}{9} = 0.888\\)\n0.9 \\(\\times\\) 0.888 = 0.8\n\n\n5\n8\n0\n1\n\n0.8\n\n\n6\n7\n1\n0\n\\(1 - \\frac{1}{7} = 0.857\\)\n0.8 \\(\\times\\) 0.857 = 0.686\n\n\n7\n6\n1\n0\n\\(1 - \\frac{1}{6} = 0.833\\)\n0.686 \\(\\times\\) 0.833 = 0.571\n\n\n8\n5\n2\n0\n\\(1 - \\frac{2}{5} = 0.0.6\\)\n0.571 \\(\\times\\) 0.6 = 0.343\n\n\n10\n3\n0\n1\n\n0.343\n\n\n11\n2\n1\n0\n\\(1 - \\frac{1}{2} = 0.5\\)\n0.343 \\(\\times\\) 0.5 = 0.171\n\n\n12\n1\n1\n0\n\\(1 - \\frac{1}{1} = 0\\)\n0.171 \\(\\times\\) 0 = 0\n\n\n\nCensoring affects the calculations:\n\nAt 5 months, one patient is censored, so we do not record a failure, and the cumulative survival rate remains unchanged.\nAt 10 months, one more patient is censored. Again, there is no effect on the failure probability, but the number of at-risk patients decreases.\nIn other words, if a patient is censored, they contribute to the number of at-risk patients until their censoring time, but they do not contribute to the event (failure) counts.\n\nWe can see how the censoring data affect the KM curve:\n\n\nCode\ndata_tooth[1, \"surv\"] &lt;- 0\ndata_tooth[4, \"surv\"] &lt;- 0\nfit.surv &lt;- survfit(Surv(time, surv) ~ 1, data = data_tooth)\nplot(fit.surv, mark.time=TRUE, conf.int=FALSE,  xlab = \"Months\", ylab = \"Estiamted Probabiliy of Survival\")\n\n\n\n\n\n\n\n\nFigure 1.4: Kaplan-Meier survival curve for tooth filling data. The curve shows the estimated probability of survival (filling intact) over time.\n\n\n\n\n\n\n\n\n1.5.2 Interpretations\nThe Kaplan-Meier curve shows the cumulative survival probabilities. A steeper slope indicates a higher event rate (death rate) and therefore a worse survival prognosis. A flatter slope indicates a lower event rate and therefore a better survival prognosis. The curve may have plateaus or flat areas, indicating periods of relatively stable survival.\nAt specific time points, you can estimate the survival probability by locating the time point on the horizontal axis and dropping a vertical line to the curve. Then, read the corresponding survival probability from the vertical axis.\n\nSo, what is the probability that a tooth filling will last 8 months? We can estimate this by locating 8 months on the x-axis and dropping a vertical line to the curve. The estimated survival probability at 10 months is approximately 0.343, meaning there is a 34.3.7% chance that a tooth filling will last 10 months.\n\n\n\nCode\nplot(fit.surv, conf.int=FALSE,  xlab = \"Months\", ylab = \"Estiamted Probabiliy of Survival\")\nabline(v = 10, h = 0.343, col = \"red\", lty = 2)\n\n\n\n\n\n\n\n\nFigure 1.5: Kaplan-Meier survival curve for tooth filling data. Red lines indicate the estimated survival probability (tooth being intact) at 10 months.\n\n\n\n\n\nIf the interest is the average length of survival, or life expectancy, following the start of treatment, this may be crudely estimated from the survival curve as the time corresponding to a cumulative probability of survival at 0.5. Alternatively, it can be calculated as: \\[\\textrm{Life expectancy} = 0.5 + \\sum(\\textrm{length of interval} \\times \\textrm{cumulative chance of survival})\\]\nIf there are multiple curves representing different groups, you can compare their shapes and patterns. If the curves are parallel, it suggests that the groups have similar survival experiences. If the curves diverge or cross, it indicates differences in survival between the groups.\n\n\nCode\n# Create data frame for survival data\ndata_tooth_ext &lt;- data.frame(\n  time = c(3, 5, 6, 7, 9, 10, 12, 15, 18, 20, \n           4, 6, 7, 9, 11, 13, 14, 16, 18, 22),\n  surv = c(1, 1, 1, 1, 1, 0, 1, 1, 0, 1, \n               1, 1, 0, 1, 1, 1, 1, 0, 1, 1),\n  gender = c(rep(\"M\", 10), rep(\"F\", 10))\n)\n\n# Create a survival object and\nsurv_object &lt;- Surv(time = data_tooth_ext$time, event = data_tooth_ext$surv)\n\n# Fit Kaplan-Meier curves for gender\nfit &lt;- survfit(surv_object ~ gender, data = data_tooth_ext)\n\n# Plot Kaplan-Meier survival curves\nggsurvplot(fit, \n           data = data_tooth_ext,\n           pval = FALSE,             # Show p-value for difference in survival\n           conf.int = FALSE,         # Add confidence interval\n           risk.table = TRUE,       # Show risk table at the bottom\n           ggtheme = theme_minimal(), # Use a minimal theme\n           xlab = \"Time (Months)\",\n           ylab = \"Survival Probability\", \n           palette = mycols[1:2])\n\n\n\n\n\n\n\n\nFigure 1.6: Kaplan-Meier survival curves for a new extended study of tooth filling data, including 20 participants (10 men and 10 women).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#comparisons-of-hazards",
    "href": "intro.html#comparisons-of-hazards",
    "title": "1  Introduction",
    "section": "1.6 Comparisons of hazards",
    "text": "1.6 Comparisons of hazards\nOften, in survival analysis we would like to compare the survival patterns of different groups, e.g. is there a group difference between survival times (tooth filling intact) between men and women in the tooth filling study?\nThe differences between the survival curves are not constant. For example, both groups start at 1 and the survival probability deceases, with lower survival probability for men at 10 months, but then again higher survival probability at 15 months.\nWe solve the problem of allowing for differences in survival time by comparing hazards in the two groups over the duration of the follow-up. We also assume that the ratio of the hazards in the two groups remains constant over time, even if the underlying hazards change. We assume, that at all times \\(t\\): \\[\\frac{h_1(t)}{h_0(t)} = constant\\]\nwhere:\n\n\\(h_1(t)\\) and \\(h_0(t)\\) are the hazards in the exposed and unexposed groups at time \\(t\\) (or in one group and the other).\n\nThis assumption is called the proportional hazards assumption. It is difficult to estimate the hazard directly from the data, since this would give a series of “spikes” when an even occurs, interspersed with zeros when there is no disease event. Instead we use the cumulative hazard function, \\(H(t)\\). This is the total hazard experienced up to time \\(t\\), and is estimated by the sum of the risks at each time \\(t\\) at which an event occurs \\[H(t) = \\sum_{i=1}^{t}\\frac{d_i}{n_i}\\]\nIf the ratio of the hazards in both groups is constant over time, if follows that the ratio of the cumulative hazard functions must also equal this constant \\[\\frac{H_1(t)}{H_0(t)} = \\frac{h_1(t)}{h_0(t)} = constant\\] and applying the rules of logarithms: \\[log(H_1(t) - log(H_0(t)) = log(constant)\\]\nTherefore, if the proportional hazards assumptions is met, then graphs of the log of the cumulative hazard functions should be parallel.\n\n\nCode\n# Plot Kaplan-Meier survival curves\nggsurvplot(fit, \n           data = data_tooth_ext,\n           fun = \"cumhaz\",           # Add cumulative hazard function\n           pval = FALSE,             # Show p-value for difference in survival\n           conf.int = FALSE,         # Add confidence interval\n           risk.table = FALSE,       # Show risk table at the bottom\n           ggtheme = theme_minimal(), # Use a minimal theme\n           xlab = \"Time (Months)\",\n           ylab = \"Cumulative hazard (log)\", \n           palette = mycols[1:2])\n\n\n\n\n\n\n\n\nFigure 1.7: Cumulative hazard functions for the two groups in the extended tooth filling study.\n\n\n\n\n\nNote that it can be shown mathematically that the cumulative hazard is related to the survival function by \\(H(t) = -log(S(t))\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#mantel-cox-log-rank-test",
    "href": "intro.html#mantel-cox-log-rank-test",
    "title": "1  Introduction",
    "section": "1.7 Mantel-Cox (log-rank test)",
    "text": "1.7 Mantel-Cox (log-rank test)\nAssuming the proportional hazards assumption holds, we can test for differences in survival between groups using the Mantel-Cox test, also known as the log-rank test. It tests the null hypothesis of no difference in survival between two or more independent groups. The test compares the entire survival experience between groups and can be thought of as a test of whether the survival curves are identical (overlapping).\nThe log-rank test statistic is constructed by comparing the observed number of events (e.g. deaths, failures) in each group to the expected number of events, assuming that the survival experiences of the groups are the same. The test statistic is based on a chi-square distribution, which tests whether the difference between the observed and expected numbers of events is larger than what we would expect by chance.\nLet’s start with two groups, A and B. If at time \\(t_j\\) there were \\(d_j\\) deaths and there were \\(n'_{jA}\\) and \\(n'_{jB}\\) subjects alive just before \\(t_j\\) in groups A and B respectively, then the data can be arranged in \\(2\\times2\\) table:\n\n\n\n\n\n\n\n\n\n\nDied\nSurvived\nTotal\n\n\n\n\nGroup A\n\\(d_{jA}\\)\n\\(r_{jA} = n'_{_jA} - d_{jA}\\)\n\\(n'_{jA}\\)\n\n\nGroup B\n\\(d_{jB}\\)\n\\(r_{jB} = n_{_jB} - d_{jB}\\)\n\\(n'_{jB}\\)\n\n\nTotal\n\\(d_j = d_{jA} + d_{jB}\\)\n\\(r_j = r_{jA} + r_{jB}\\)\n\\(n'_j = n'_{jA} + n'_{jB}\\)\n\n\n\nwhere:\n\nGroup A and Group B represent the two groups being compared (e.g., two different treatments, genders, etc.).\nDied (\\(d_{jA}\\), \\(d_{jB}\\)): The number of individuals who experienced the event (e.g., death, tooth filling falling out) in each group.\nSurvived (\\(r_{jA}\\), \\(r_{jB}\\)): The number of individuals who did not experience the event (survivors, with tooth filling intact) in each group. This is calculated as the total number in the group minus the number of deaths.\nTotal (\\(n_A\\), \\(n_B\\)): The total number of individuals in each group at risk just before the time of an event\n\nThe log-rank test compares the observed number of events to the expected number of events if the survival curves were the same for all groups. The expected number of events in group A at each event time is denoted by: \\[E(d_{jA}) = \\frac{n'_{jA}d_i}{n'_j}\\] and analogously for group B \\[E(d_{jB}) = \\frac{n'_{jB}d_j}{n'_j}\\]\nThe difference between observed and expected number of events is evidence against the null hypothesis. The Mantel-Cox chi-squared (log-rank) its simple for is the combination of these differences over all the times at which deaths (events) occurred: \\[\\chi^2_{MC} = \\frac{(O_A - E_A)^2}{E_A} + \\frac{(O_B - E_B)^2}{E_B}\\]\nwith 1 \\(df\\).\nThe test can be easily expanded to more than two groups, by covering more groups in the summation and having \\(k-1\\) degrees of freedom, where \\(k\\) is the number of groups.\nIn more advanced version, the log-rank test incorporates variance into the test statistics. This ensures more accurate and reliable comparisons of survival distributions, particularly when groups differ in size, have varying numbers of individuals at risk, or experience uneven censoring: \\[\\chi^2_{MC} = \\frac{(O_A - E_A)^2}{V_A} + \\frac{(O_B - E_B)^2}{V_B}\\] where \\(V\\) stands for total variance across all times at which event occurs, with variance at these points calculated as \\[V(d_{jA}) = \\frac{d_j(n'_j - d_j)n'_{jA}n'_{jB}}{n'^2_j(n'_j -1)}\\] for group A (and analogously for other groups in the study).\nIn our extended tooth filling study, we can compare the survival experiences between men and women:\n\n\nCode\n# Perform the log-rank test\nlog_rank_test &lt;- survdiff(surv_object ~ gender, data = data_tooth_ext)\n\n# Display the result of the log-rank test\nprint(log_rank_test)\n\n\nCall:\nsurvdiff(formula = surv_object ~ gender, data = data_tooth_ext)\n\n          N Observed Expected (O-E)^2/E (O-E)^2/V\ngender=F 10        8     9.05     0.121     0.302\ngender=M 10        8     6.95     0.158     0.302\n\n Chisq= 0.3  on 1 degrees of freedom, p= 0.6 \n\n\nIn this example, the chi-square values is 0.3, with \\(1\\) degrees of freedom. The critical value for \\(\\chi^2\\) at \\(\\alpha = 0.05\\) is approximately \\(3.84\\) and since 0.3 &lt; \\(3.84\\) we would conclude that we cannot reject the null hypothesis of no difference in survival between the groups (indicated also by the obtained p-value 0.58).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "regression.html",
    "href": "regression.html",
    "title": "2  Regression with survival response",
    "section": "",
    "text": "2.1 Cox proportional hazards model\nIf survival time is of interest, such as in mortality studies, a common approach is to postulate a distribution for survival time and estimate the parameters of this distribution from the data. For instance, the exponential distribution can be used if the death rate is independent of time, the Weibull distribution allows for increasing or decreasing hazard rates, and the Gompertz distribution models hazard rates that exponentially increase or decrease over time.\nMore commonly, it is the relationship between survival time and one or more predictor variables (covariates) that is of interest. The Cox proportional hazards model is a widely used semi-parametric model to study this relationship. It is used to estimate the hazard ratio for individuals based on their covariates, without needing to specify the baseline hazard function.\nEstimation of \\(\\boldsymbol{\\beta}\\) and inferences are developed by considering the information supplied at each time that a death (event) occurred.\nConsider:\nThen:\nwhere:\nThe risk of death at time \\(t_j\\) in the risk set does not supply absolute measures of risk, but does supply the relative risks for each subject, since, although \\(h_0(t)\\) is unknown, it is the same for each subject. Thus the probability that the death observed at \\(t_j\\) was of the subject who did die at that time is: \\[p_j = \\frac{\\textrm{exp}(\\boldsymbol{\\beta}^T\\boldsymbol{x_1})}{\\sum \\textrm{exp}(\\beta^T\\boldsymbol{x_i})}\\] where summation is over all remembers of the risk set.\nSimilar terms are derived for each time that a death occurred and are combined to form a likelihood (product of these probabilities over all event times \\(t_j\\)): \\[PL(\\boldsymbol{\\beta}) = \\prod_{j=1}^{k} \\frac{\\exp(\\boldsymbol{\\beta}^T \\boldsymbol{x_1})}{\\sum_{i \\in \\text{risk set at } t_j} \\exp(\\boldsymbol{\\beta}^T \\boldsymbol{x_i})}\\] Technically this is called partial likelihood, since the component terms are derived conditionally on the times that deaths occurred and the composition of the risk set at these times. This partial likelihood is used to estimate the regression coefficients \\(\\boldsymbol{\\beta}\\) in the Cox model. Maximizing this partial likelihood gives the best estimates for \\(\\boldsymbol{\\beta}\\), quantifying the effect of the covariates on the hazard.\nTo estimate \\(\\beta\\), we maximize the partial likelihood function with respect to \\(\\beta\\). No closed-form solution is available, and so iterative algorithms are used.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Regression with survival response</span>"
    ]
  },
  {
    "objectID": "regression.html#cox-proportional-hazards-model",
    "href": "regression.html#cox-proportional-hazards-model",
    "title": "2  Regression with survival response",
    "section": "",
    "text": "a death occurring at time \\(t_j\\), and\nsuppose that there were \\(n_j\\) subjects alive just before \\(t_j\\),\nthat the values of \\(\\boldsymbol{x}\\) for these subjects are \\(\\boldsymbol{x_1}, \\boldsymbol{x_2}, \\cdots, \\boldsymbol{x_{n'j}}\\)\nand that the subject that dies is denoted, by the subscript 1\n\n\n\nThe set of \\(n'_j\\) subjects at risk is referred to as the risk set.\nThe risk of death at time \\(t_j\\) for each subject in the risk set is given by: \\[h(t) = h_0(t)\\textrm{exp}(\\boldsymbol{\\beta}^T\\boldsymbol{x})\\]\n\n\n\n\\(\\boldsymbol{\\beta}^T\\boldsymbol{x}\\) is the matrix representation of the regression function, \\(\\beta_1x_1 + \\beta_2x_2 + \\cdots + \\beta_px_p\\)\nand \\(h_0(t)\\) is baseline hazard function",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Regression with survival response</span>"
    ]
  },
  {
    "objectID": "regression.html#example-with-brain-cancer-data",
    "href": "regression.html#example-with-brain-cancer-data",
    "title": "2  Regression with survival response",
    "section": "2.2 Example with brain cancer data",
    "text": "2.2 Example with brain cancer data\nThe BrainCancer data set from the ISLR2 package contains survival times for patients with primary brain tumors undergoing treatment with radiation therapy. Variables included in the study are:\n\nsex: male or female\ndiagnosis: meningioma, LG glioma, HG glioma, or other\nloc: tumor location, infratentorial or supratentorial\ngtv: gross tumor volume \\(cm^3\\)\nki: Karnofsky index\nstereo: stereotatcic radiosurgery (SRS) or fractionated stereotactic (SRT) radiotherapy\n\n\n\nCode\n# preview data\ndata_brain &lt;- BrainCancer\n\ndata_brain %&gt;%\n  str()\n\n\n'data.frame':   88 obs. of  8 variables:\n $ sex      : Factor w/ 2 levels \"Female\",\"Male\": 1 2 1 1 2 1 2 2 1 2 ...\n $ diagnosis: Factor w/ 4 levels \"Meningioma\",\"LG glioma\",..: 1 3 1 2 3 1 1 2 1 3 ...\n $ loc      : Factor w/ 2 levels \"Infratentorial\",..: 1 2 1 2 2 2 2 2 2 2 ...\n $ ki       : int  90 90 70 80 90 80 80 80 70 100 ...\n $ gtv      : num  6.11 19.35 7.95 7.61 5.06 ...\n $ stereo   : Factor w/ 2 levels \"SRS\",\"SRT\": 1 2 1 2 2 1 2 2 2 2 ...\n $ status   : int  0 1 0 1 1 0 0 0 0 0 ...\n $ time     : num  57.64 8.98 26.46 47.8 6.3 ...\n\n\nCode\n# Cox model with multiple predictors\nfit.cox_multi &lt;- coxph(Surv(time, status) ~ sex + diagnosis + ki, data = data_brain)\nsummary(fit.cox_multi)\n\n\nCall:\ncoxph(formula = Surv(time, status) ~ sex + diagnosis + ki, data = data_brain)\n\n  n= 87, number of events= 35 \n   (1 observation deleted due to missingness)\n\n                       coef exp(coef) se(coef)      z Pr(&gt;|z|)    \nsexMale             0.11149   1.11795  0.35670  0.313 0.754608    \ndiagnosisLG glioma  1.01441   2.75774  0.62159  1.632 0.102687    \ndiagnosisHG glioma  2.22962   9.29629  0.44520  5.008  5.5e-07 ***\ndiagnosisOther      0.82773   2.28813  0.57751  1.433 0.151774    \nki                 -0.06624   0.93591  0.01753 -3.778 0.000158 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                   exp(coef) exp(-coef) lower .95 upper .95\nsexMale               1.1179     0.8945    0.5556    2.2493\ndiagnosisLG glioma    2.7577     0.3626    0.8156    9.3251\ndiagnosisHG glioma    9.2963     0.1076    3.8847   22.2467\ndiagnosisOther        2.2881     0.4370    0.7377    7.0967\nki                    0.9359     1.0685    0.9043    0.9686\n\nConcordance= 0.782  (se = 0.038 )\nLikelihood ratio test= 36.59  on 5 df,   p=7e-07\nWald test            = 34.11  on 5 df,   p=2e-06\nScore (logrank) test = 40.79  on 5 df,   p=1e-07\n\n\n\n2.2.1 Coefficient interpration\nAbove, we fitted Cox model using sex and diagnosis as predictors. The results, indicate, for instance that:\n\nThe estimated hazard ratio (HR) for a male patient is \\(e^{0.11} = 1.11\\). This means that men have 1.11 times the hazard of dying than women while keeping other variables constant (sometimes referred to as adjusted hazard ration, AHR).\nHowever the associated Z value is small, resulting in large p-value of 0.75, which indicates that this difference is not statistically significant.\nWe can also see that one-unit increase in the Karnofsky index is corresponds to a multiplier of \\(e^{-0.06} = 0.94\\) in the chance of dying. The higher the Karnofsky index score, the lower the chance of dying at any given point in time, with this effect being highly significant \\(p\\)-value of 0.000158.\nNote that if you want to find HR associated with more than 1-unit dffererence, e.g. for patients with 10 units higher Karnofsky index, we would calculate HR as \\(e^{-0.06 \\times 10} = 0.54\\). This means that patients with 10 units higher Karnofsky index have 0.54 times the hazard of dying compared to those with lower Karnofsky index.\n\nSometimes, in addition to reporting the numeric results of a Cox regression, forest plots are used to visualize HRs and their 95% confidence intervals.\n\n\nCode\n# make forest plot with ggforest()\nggforest(fit.cox_multi, data = data_brain)\n\n\n\n\n\n\n\n\n\n\n\n2.2.2 Global statistical signficance\nThe output of the Cox regression contains also three methods for an overall test of whether the predictors in the model have a significant effect on the hazard (or risk) of the event occurring. Essentially, these check whether the model as a whole provides a better fit than a null model (a model without any covariates).\nLikelihood Ratio Test (LRT) compares the log-likelihoods of two models:\n\nThe null model, which includes only the baseline hazard (i.e., no covariates).\nThe full model, which includes the covariates of interest.\n\nThe test statistic is computed as: \\[\n2 \\times (\\text{log-likelihood of the full model} - \\text{log-likelihood of the null model})\n\\] This statistic follows a chi-squared distribution, and the associated p-value indicates whether the full model (with covariates) is significantly better at explaining the data than the null model.\nWald Test\nThe Wald test checks whether the estimated regression coefficients are significantly different from zero. For each predictor, the test examines whether its coefficient, \\(\\beta_i\\), is significantly different from 0, implying that the predictor has a significant effect on the hazard. The Wald test can also be used as a global test of significance.\nScore Test (Log-Rank Test)\nThe Score test (also called the log-rank test in this context) evaluates the contribution of each predictor to the model’s fit, considering the expected number of events. Like the likelihood ratio test, the Score test also compares the null and full models and uses a chi-squared distribution to compute significance.\n\n\n2.2.3 Concordance\nIn the context of a Cox proportional hazards model, concordance (also known as the C-index or concordance index) is a measure of how well the model predicts the order of events. Specifically, it assesses the ability of the Cox model to correctly predict which of two individuals will experience an event first, based on their risk scores.\nThe concordance index (C-index) ranges between 0.5 and 1:\n\nA C-index of 0.5 indicates that the model’s predictions are no better than random chance. This means the model cannot distinguish between individuals who experience the event earlier and those who experience it later.\nA C-index of 1 means perfect prediction, indicating that the model always correctly predicts the order of events.\n\nThe C-index is similar to the area under the ROC curve (AUC) used in binary classification models, but it is adapted to survival analysis where the goal is to rank individuals by their risk of experiencing the event.\nIn our example, a concordance of 0.782 means that the Cox model can correctly predict the ordering of survival times 78.2% of the time. In other words, if you randomly select two individuals and compare their predicted risk scores, the model will correctly predict which individual experiences the event earlier in 78.2% of cases. The standard error is 0.038 which provides a measure of uncertainty around the concordance estimate. A smaller standard error indicates more confidence in the estimate.\n\n\n2.2.4 Predictions\nIn Cox regression, we can estimate:\n\nthe survival probability at a specific time, \\(S(t|X=x)\\)\nand the hazard ratio for an individual relative to a reference individual, $h(t|X=x) / \\(S(t|X=x_{ref})\\), where \\(X_{ref}\\) is a reference individual with known covariate values.\n\nFor predicted survival, the choice of time matters. A predicted HR will not depend on time due to proportional hazards assumption.\n\n2.2.4.1 Survival\nLet’s predict the probability of survival at 40 days, for a new patient (man, with LG glioma, Karnofsky index of 80).\n\n# new patient data\nnew_pat &lt;- data.frame(time = 40, \n                      sex = \"Male\", \n                      diagnosis = \"LG glioma\",\n                      ki = 80, \n                      status = 0)\n\npredict(fit.cox_multi, newdata = new_pat, type = \"survival\", se.fit = T)\n\n$fit\n[1] 0.4824421\n\n$se.fit\n[1] 0.1834607\n\n\nThe probability of surviving through 40 days is 0.48. To get confidence interval we could use:\n\nunlist(summary(survfit(fit.cox_multi,\n                       newdata = new_pat,\n                       se.fit =T, conf.int = 0.95),\n        times=40)[c(\"surv\", \"std.err\", \"lower\", \"upper\")])\n\n     surv   std.err     lower     upper \n0.4824421 0.1834607 0.2289573 1.0000000 \n\n\nSo the probability of surviving through 40 days is 0.48 with 95% CI [0.23, 1].\n\n\n2.2.4.2 HR\nTo predict the adjusted hazard ratio for a new patient, we use again the predict() function, this type with type = \"risk\". We also need to specify the reference individual. Some options include:\n\nreference = \"zero\": the reference individual has continuous predictor values set to 0 and categorical predictors each at their reference level. This is not a good choice if a value of 0 is not plausible for continuous variables in the model, e.g. age.\nreference = \"sample\": the reference individual has continuous predictors each their respective sample mean and categorical predictors at their reference level.\nreference = \"strata\": this leads to the same results as in reference = \"sample\" unless the model includes astrata()`, in which case continuous variables will be set their within-stratum means.\n\n\n# predict HR for our new patient\npredict(fit.cox_multi, \n        newdata = new_pat, \n        type = \"risk\", \n        reference = \"strata\", \n        se.fit = T)\n\n$fit\n       1 \n3.276632 \n\n$se.fit\n       1 \n1.201369 \n\n\nOur new patient 3.27 times the hazard of dying compared to a reference individual with level of each categorical predictor and the mean of each continuous predictor, which in our case are (Female for gender, Meningioma for diagnosis, and mean Karnofsky index of 81.02).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Regression with survival response</span>"
    ]
  },
  {
    "objectID": "regression.html#time-dependent-covariates",
    "href": "regression.html#time-dependent-covariates",
    "title": "2  Regression with survival response",
    "section": "2.3 Time-dependent covariates",
    "text": "2.3 Time-dependent covariates\nIn all above example the predictors did not vary over time. Each individual had only one value for each predictor. Since survival data is the result of follow-up over time, it is possible to have predictors that do vary over time. For example, in a study of time to heart attack, researchers could record various other conditions’ occurrence over time, such as hypertension or angina. In a study of juvenile recidivism, researchers could record how education or employment status change over time. Cox regression is able to handle such time-varying predictors (also known as “time dependent covariates”).\nFor time-varying covariates, the hazard function is extended to account for changes in the covariates over time: \\[h(t | \\boldsymbol{x}(t)) = h_0(t) \\cdot \\exp\\left(\\boldsymbol{\\beta}^T \\boldsymbol{x}(t)\\right)\\]\nwhere:\n\n\\(h(t | \\boldsymbol{x}(t))\\) is the hazard at time \\(t\\), conditional on the covariate values at that time.\n\\(\\boldsymbol{x}(t)\\) represents the covariate vector at time \\(t\\). In this case, one or more covariates can change over time.\n\\(\\boldsymbol{\\beta}\\) is the vector of regression coefficients.\n\\(h_0(t)\\) is the baseline hazard function, which remains time-dependent but does not depend on the covariates.\n\nIn practice, time-varying covariates are handled by breaking the follow-up time into intervals where the covariate values are assumed to remain constant, and then updating the covariate values at each interval. Suppose a covariate (e.g., blood pressure, treatment status, or exposure) varies over time. For an individual, we divide their follow-up time into periods where the covariate value is constant, and then treat each period as a separate “observation” in the Cox model. The Cox model then uses these updated covariate values when estimating the hazard at each time point.\nThe partial likelihood function in the Cox model is modified to incorporate the updated covariate values \\(\\boldsymbol{x}(t)\\). For each event time \\(t_j\\), the likelihood is based on the covariate values that are valid at that specific time.\nThe partial likelihood becomes:\n\\[PL(\\boldsymbol{\\beta}) = \\prod_{j=1}^{k} \\frac{\\exp\\left(\\boldsymbol{\\beta}^T \\boldsymbol{x}_1(t_j)\\right)}{\\sum_{i \\in \\text{risk set at } t_j} \\exp\\left(\\boldsymbol{\\beta}^T \\boldsymbol{x}_i(t_j)\\right)}\\]\nwhere:\n\n\\(\\boldsymbol{x}_1(t_j)\\) is the covariate vector for the subject who experienced the event at time \\(t_j\\),\nand \\(\\boldsymbol{x}_i(t_j)\\) is the covariate vector for each subject in the risk set at time \\(t_j\\).\n\nA dataset with time-varying predictors will have multiple rows per individual, with different rows having different values for the time-varying predictors, reflecting how they change over time. Additionally, rather than having a single event time variable, each row will have two time variables indicating the beginning and end of the time interval represented by that row of data.\nFor instance, in the study of heroin usage, we can see a male participant who started using non-prescribed pharmaceutical opioids (NPPOs) at age 19 (time independent covariates). He did not meet the criteria for lifetime opioid dependence at baseline (wave 1), but did at the next interview (wave2), and he first reported using heroin at his 6th interview (both time varying variables).\n\n\nCode\ndata_opioid &lt;- readRDS(\"data/data-opioid.rds\")\n\ndata_opioid %&gt;% \n  filter(RANDID == 10) %&gt;%\n  select(RANDID, wave, START, STOP, heroin, age_at_init, sex, dep_lifetime)\n\n\n  RANDID wave START STOP heroin age_at_init  sex dep_lifetime\n1     10    1  3.78 4.26      0          19 Male            0\n2     10    2  4.26 4.78      0          19 Male            1\n3     10    3  4.78 5.29      0          19 Male            1\n4     10    4  5.29 5.84      0          19 Male            1\n5     10    5  5.84 6.27      0          19 Male            1\n6     10    6  6.27 6.79      1          19 Male            1",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Regression with survival response</span>"
    ]
  },
  {
    "objectID": "regression.html#multiple-events-competing-risks",
    "href": "regression.html#multiple-events-competing-risks",
    "title": "2  Regression with survival response",
    "section": "2.4 Multiple events: competing risks",
    "text": "2.4 Multiple events: competing risks\nIn survival analysis, competing risks occur when an individual is at risk of more than one mutually exclusive event, and the occurrence of one event precludes the occurrence of the others. Traditional survival models, such as the Cox proportional hazards model, typically focus on a single type of event (e.g., death or failure), but in many real-world scenarios, individuals may face different types of events that compete with each other.\nA competing risk refers to events that prevent the event of primary interest from happening. For example: - In a study of heart disease, death due to cancer is a competing risk if the primary event of interest is death due to heart disease. - In a study of cancer treatment, death from any cause is a competing risk if the event of interest is relapse.\nIn these situations, standard survival analysis methods may overestimate the probability of the primary event because they do not account for the possibility of competing events.\nThe Cumulative Incidence Function (CIF) is commonly used in competing risks analysis. It represents the probability of experiencing a specific event (e.g., death from heart disease) by a certain time, accounting for the presence of competing risks (e.g., death from cancer).\nCIF is a product of two estimates.\n\nThe estimate of hazard at ordered failure time \\(t_j\\) for the event of interest: \\[\\hat{h_c(t_j)}=\\frac{d_{cj}}{n_j}\\] where:\n\n\n\\(m_{cj}\\) denotes the number of events for risk \\(c\\) at time \\(t_j\\)\nand \\(n_j\\) is the number of subjects at risk at time \\(t_j\\)\n\n\nThe estimate of overall probability of surviving previous time: \\[\\hat{S}(t_{j-1})\\] We consider the overall survival as a subject must have survived all other competing events in order to fail from event type \\(c\\) at time \\(t_j\\).\n\nThe estimated incidence probability of failing from even type \\(c\\) at time \\(t_j\\) is then: \\[\\hat{I_c}(t_j) = \\hat{S}(t_{j-1}) \\times \\hat{h_c(t_j)}\\] The probability of failing form even type \\(c\\) at time \\(t_j\\) is a product of surviving the previous time periods and the cause specific hazard at time \\(t_j\\).\nThe CIF for event type \\(c\\) at time \\(t_j\\) is then the cumulative sum up to time \\(t_j\\), i.e. from \\(f' = 1\\) to \\(f'=f\\), of these incidence probabilities over all event type \\(c\\) failure times, which is expressed: \\[CIF_c(t_j) = \\sum_{f'=1}^{f}\\hat{I_c}(t_j) = \\sum_{f'=1}^{f}\\hat{S}(t_{f'-1})\\times\\hat{h_c}(t_{f'})\\]\nIn 1999 Gray (1998) proposed a non-parametric test to compare two or more CIFs. The test is analogous to the log-rank test comparing KM curves, using a modified Chi-squared test statistic. This test does not require the independent censoring assumption.\nIn Fine and Gray Fine and Gray (1999) proposed a proportional hazards model aims at modeling the CIF with covariates, by treating the CIF curve as a subdistribution function. The subdistribution function is analogous to the Cox proportional hazard model, except that it models a hazard function (as known as subdistribution hazard) derived from a CIF.\n\n\n\n\nFine, Jason P., and Robert J. Gray. 1999. “A Proportional Hazards Model for the Subdistribution of a Competing Risk.” Journal of the American Statistical Association 94. https://doi.org/10.1080/01621459.1999.10474144.\n\n\nGray, Robert J. 1998. “A Class of k-Sample Tests for Comparing the Cumulative Incidence of a Competing Risk.” The Annals of Statistics 16. https://doi.org/10.1214/aos/1176350951.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Regression with survival response</span>"
    ]
  },
  {
    "objectID": "lab.html",
    "href": "lab.html",
    "title": "3  R examples",
    "section": "",
    "text": "3.1 KM, log-rank, Cox proportional hazards model\nrm(list=ls())\n\n# load libraries\nlibrary(tidyverse)\nlibrary(skimr)\nlibrary(survival)\n\n# load data\ndata_brain &lt;- readRDS(\"data/data_cancer_brain.rds\")\n\n# preview data\nskim(data_brain)\n\n\nData summary\n\n\nName\ndata_brain\n\n\nNumber of rows\n88\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n4\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nsex\n0\n1.00\nFALSE\n2\nFem: 45, Mal: 43\n\n\ndiagnosis\n1\n0.99\nFALSE\n4\nMen: 42, HG : 22, Oth: 14, LG : 9\n\n\nloc\n0\n1.00\nFALSE\n2\nSup: 69, Inf: 19\n\n\nstereo\n0\n1.00\nFALSE\n2\nSRT: 65, SRS: 23\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nki\n0\n1\n81.02\n10.51\n40.00\n80.00\n80.00\n90.0\n100.00\n▁▁▃▇▇\n\n\ngtv\n0\n1\n8.66\n8.66\n0.01\n2.50\n6.51\n12.1\n34.64\n▇▃▁▁▁\n\n\nstatus\n0\n1\n0.40\n0.49\n0.00\n0.00\n0.00\n1.0\n1.00\n▇▁▁▁▅\n\n\ntime\n0\n1\n27.46\n20.12\n0.07\n10.39\n24.03\n41.6\n82.56\n▇▅▅▂▁\n\n\n\n\n# status = 0, indicates a censored observation \n# status = 1, indicates an uncensored observation\n\n# Kaplan-Meier survival curve\nfit.surv &lt;- survfit(Surv(time, status) ~ 1, data = data_brain)\nplot(fit.surv, xlab = \"Months\", ylab = \"Estiamted Probabiliy of Survival\")\n\n\n\n\n\n\n\n\n# KM stratify by sex\nfit.surv &lt;- survfit(Surv(time, status) ~ sex, data = data_brain)\nplot(fit.surv, mark.time = TRUE, col = c(2, 4), xlab = \"Months\", ylab = \"Estiamted Probabiliy of Survival\")\n\n\n\n\n\n\n\n\n# Log-rank test to compare survival of men and women\nlogrank_test &lt;- survdiff(Surv(time, status) ~ sex, data = data_brain)\nprint(logrank_test)\n## Call:\n## survdiff(formula = Surv(time, status) ~ sex, data = data_brain)\n## \n##             N Observed Expected (O-E)^2/E (O-E)^2/V\n## sex=Female 45       15     18.5     0.676      1.44\n## sex=Male   43       20     16.5     0.761      1.44\n## \n##  Chisq= 1.4  on 1 degrees of freedom, p= 0.2\n\n# Fit Cox proportional hazards model\nfit.cox &lt;- coxph(Surv(time, status) ~ sex, data = data_brain)\nsummary(fit.cox)\n## Call:\n## coxph(formula = Surv(time, status) ~ sex, data = data_brain)\n## \n##   n= 88, number of events= 35 \n## \n##           coef exp(coef) se(coef)     z Pr(&gt;|z|)\n## sexMale 0.4077    1.5033   0.3420 1.192    0.233\n## \n##         exp(coef) exp(-coef) lower .95 upper .95\n## sexMale     1.503     0.6652     0.769     2.939\n## \n## Concordance= 0.565  (se = 0.045 )\n## Likelihood ratio test= 1.44  on 1 df,   p=0.2\n## Wald test            = 1.42  on 1 df,   p=0.2\n## Score (logrank) test = 1.44  on 1 df,   p=0.2\n\n# Test the proportional hazards assumption in the two gender groups\nph_test &lt;- cox.zph(fit.cox)\nprint(ph_test)\n##        chisq df    p\n## sex    0.588  1 0.44\n## GLOBAL 0.588  1 0.44\n\n# Fit Cox model with multiple predictors\nfit.cox_multi &lt;- coxph(Surv(time, status) ~ sex + diagnosis + loc + ki + gtv + stereo, data = data_brain)\nsummary(fit.cox_multi)\n## Call:\n## coxph(formula = Surv(time, status) ~ sex + diagnosis + loc + \n##     ki + gtv + stereo, data = data_brain)\n## \n##   n= 87, number of events= 35 \n##    (1 observation deleted due to missingness)\n## \n##                        coef exp(coef) se(coef)      z Pr(&gt;|z|)    \n## sexMale             0.18375   1.20171  0.36036  0.510  0.61012    \n## diagnosisLG glioma  0.91502   2.49683  0.63816  1.434  0.15161    \n## diagnosisHG glioma  2.15457   8.62414  0.45052  4.782 1.73e-06 ***\n## diagnosisOther      0.88570   2.42467  0.65787  1.346  0.17821    \n## locSupratentorial   0.44119   1.55456  0.70367  0.627  0.53066    \n## ki                 -0.05496   0.94653  0.01831 -3.001  0.00269 ** \n## gtv                 0.03429   1.03489  0.02233  1.536  0.12466    \n## stereoSRT           0.17778   1.19456  0.60158  0.296  0.76760    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n##                    exp(coef) exp(-coef) lower .95 upper .95\n## sexMale               1.2017     0.8321    0.5930    2.4352\n## diagnosisLG glioma    2.4968     0.4005    0.7148    8.7215\n## diagnosisHG glioma    8.6241     0.1160    3.5664   20.8546\n## diagnosisOther        2.4247     0.4124    0.6678    8.8031\n## locSupratentorial     1.5546     0.6433    0.3914    6.1741\n## ki                    0.9465     1.0565    0.9132    0.9811\n## gtv                   1.0349     0.9663    0.9906    1.0812\n## stereoSRT             1.1946     0.8371    0.3674    3.8839\n## \n## Concordance= 0.794  (se = 0.04 )\n## Likelihood ratio test= 41.37  on 8 df,   p=2e-06\n## Wald test            = 38.7  on 8 df,   p=6e-06\n## Score (logrank) test = 46.59  on 8 df,   p=2e-07\n\n# Plot survival curves for each diagnosis category, adjusting for other predictors\n# we set the values of the other predictors to the mean for quantitative predictors, \n# and to the modal value for factors\n\nmodeldata &lt;- data.frame(\n  diagnosis = levels(data_brain$diagnosis), \n  sex = rep(\"Female\", 4), \n  loc = rep(\"Supratentorial\", 4), \n  ki = rep(mean(data_brain$ki), 4),\n  gtv = rep(mean(data_brain$gtv), 4),\n  stereo = rep(\"SRT\", 4)\n)\n\nsurvplots &lt;- survfit(fit.cox_multi, newdata = modeldata)\nplot(survplots, mark.time = FALSE, xlab = \"Months\", ylab = \"Estiamted Probabiliy of Survival\", col = 2:5)\nlegend(\"bottomleft\", legend = levels(data_brain$diagnosis), col = 2:5, lty = 1)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R examples</span>"
    ]
  },
  {
    "objectID": "lab.html#time-varying-predictors",
    "href": "lab.html#time-varying-predictors",
    "title": "3  R examples",
    "section": "3.2 Time-varying predictors",
    "text": "3.2 Time-varying predictors\nadpoted from https://www.bookdown.org/rwnahhas/RMPH/\nA dataset with time-varying predictors will have multiple rows per individual, with different rows having different values for the time-varying predictors, reflecting how they change over time. Additionally, rather than having a single event time variable, each row will have two time variables indicating the beginning and end of the time interval represented by that row of data.\n\ndata_opioid &lt;- readRDS(\"data/data-opioid.rds\")\n\ndata_opioid %&gt;% \n  filter(RANDID == 10) %&gt;%\n  select(RANDID, wave, START, STOP, heroin, age_at_init, sex, dep_lifetime)\n##   RANDID wave START STOP heroin age_at_init  sex dep_lifetime\n## 1     10    1  3.78 4.26      0          19 Male            0\n## 2     10    2  4.26 4.78      0          19 Male            1\n## 3     10    3  4.78 5.29      0          19 Male            1\n## 4     10    4  5.29 5.84      0          19 Male            1\n## 5     10    5  5.84 6.27      0          19 Male            1\n## 6     10    6  6.27 6.79      1          19 Male            1\n\nHere, we see a preview of the data_opioid dataset containing longitudinal information for 362 individuals, who at baseline had used non-prescribed pharmaceutical opioids (NPPO, “pain pills”), but were not dependent on NPPOs and had never used heroin.\n\nEach row contains the time variables START and STOP which define the time interval (years from initiation of NPPO use) associated with that row.\nTime-invariant variables in the dataset are constant over all rows for the same individual, while time-varying variables can change between rows.\nEach (START, STOP] interval defines a period of time during which no variables changed.\nTwo time-varying variables in the dataset are heroin use (heroin) (the event indicator variable) and lifetime opioid dependence (dep_lifetime)\n\nFor instance, for this particular individual, male, started using NPPOs at age 19 (time invariant variables). He did not meet the criteria for lifetime opioid dependence at baseline (wave = 0), but did at the next interview (wave = 1) and he first reported using heroin at his 6th interview.\n\nTo model the heroin usage using both time-invariant and time-varying predictors, we can use the coxph function:\n\ncox.timevar &lt;- coxph(Surv(START, STOP, heroin) ~\n                     age_at_init + sex + dep_lifetime,\n                   data = data_opioid)\n\nsummary(cox.timevar)\n## Call:\n## coxph(formula = Surv(START, STOP, heroin) ~ age_at_init + sex + \n##     dep_lifetime, data = data_opioid)\n## \n##   n= 1853, number of events= 27 \n## \n##                 coef exp(coef) se(coef)      z Pr(&gt;|z|)   \n## age_at_init  -0.3932    0.6749   0.1350 -2.911  0.00360 **\n## sexMale       0.1515    1.1635   0.3925  0.386  0.69956   \n## dep_lifetime  1.0580    2.8807   0.3991  2.651  0.00802 **\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n##              exp(coef) exp(-coef) lower .95 upper .95\n## age_at_init     0.6749     1.4817    0.5180    0.8794\n## sexMale         1.1635     0.8594    0.5391    2.5111\n## dep_lifetime    2.8807     0.3471    1.3176    6.2981\n## \n## Concordance= 0.716  (se = 0.042 )\n## Likelihood ratio test= 15.24  on 3 df,   p=0.002\n## Wald test            = 14.53  on 3 df,   p=0.002\n## Score (logrank) test = 15.45  on 3 df,   p=0.001\n\nWhether a predictor is time-varying or time-invariant, its HR can be interpreted as a comparison of the hazard between groups of individuals with different values of that predictor. Thus, in this example, we could conclude that after adjusting for age at NPPO initiation and sex, those with lifetime opioid dependence have 2.88 times the hazard of using heroin as those who do not (AHR = 2.88; 95% CI = 1.32, 6.30; p = 0.008). The HR for a time-varying predictor, however, can also be interpreted as the effect of within-individual change on the hazard. If an individual without opioid dependence transitions to dependence, their hazard of transitioning to heroin is multiplied by 2.88.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R examples</span>"
    ]
  },
  {
    "objectID": "lab.html#competing-risks",
    "href": "lab.html#competing-risks",
    "title": "3  R examples",
    "section": "3.3 Competing risks",
    "text": "3.3 Competing risks\n\n3.3.1 Comparing CIFs\nLet’s demonstrate how to analyze competing risks using the cmprsk package in R. This package includes functions for estimating the cumulative incidence function (CIF) in the presence of competing risks.\nBone marrow transplant (BMT) data from the cmprsk package includes information for 35 leukemia cancer patients who underwent bone marrow transplantation. The data includes the following variables:\n\ndis: disease; 0 = ALL; 1 = AML (ALL, Acute lymphoblastic leukemia; AML, Acute myeloid leukemia)\nftime: follow-up time\nstatus: 0 = censored (survival); 1 = Transplant-related mortality; 2 = relapse\n\n\nlibrary(cmprsk)\nlibrary(survminer)\n\n# preview data\ndata_bmt &lt;- readRDS(\"data/data-bmt.rds\")\nstr(data_bmt)\n## 'data.frame':    35 obs. of  3 variables:\n##  $ dis   : int  0 0 0 0 0 1 0 0 1 1 ...\n##  $ ftime : int  13 1 72 7 8 67 9 5 70 4 ...\n##  $ status: int  2 1 0 2 2 0 2 2 0 0 ...\n\n# label levels\ndata_bmt &lt;- data_bmt %&gt;%\n  mutate(dis = factor(dis, levels = c(0,1), labels = c(\"ALL\", \"AML\")), \n         status = factor(status, levels = c(0,1,2), labels = c(\"Censored\",\"Mortality\",\"Relapse\")))\n\nstr(data_bmt)\n## 'data.frame':    35 obs. of  3 variables:\n##  $ dis   : Factor w/ 2 levels \"ALL\",\"AML\": 1 1 1 1 1 2 1 1 2 2 ...\n##  $ ftime : int  13 1 72 7 8 67 9 5 70 4 ...\n##  $ status: Factor w/ 3 levels \"Censored\",\"Mortality\",..: 3 2 1 3 3 1 3 3 1 1 ...\n\n# Estimate the cumulative incidence functions for each event type\ncif &lt;- cuminc(ftime = data_bmt$ftime, # Failure time variable\n              fstatus = data_bmt$status) # Codes for different causes of failure\n\n# Print the CIF object\nprint(cif)\n## Estimates and Variances:\n## $est\n##                    20        40        60\n## 1 Censored  0.1142857 0.2000000 0.2000000\n## 1 Mortality 0.2571429 0.2571429 0.2571429\n## 1 Relapse   0.3714286 0.4285714 0.4285714\n## \n## $var\n##                      20          40          60\n## 1 Censored  0.002998057 0.004910750 0.004910750\n## 1 Mortality 0.005636800 0.005636800 0.005636800\n## 1 Relapse   0.006878377 0.007269181 0.007269181\n\n# Plot the CIFs for all even types\nplot(cif, lty = 1, col = c(\"green\", \"red\", \"blue\"), xlab = \"Time\", ylab = \"Cumulative Incidence\",\n     main = \"Cumulative Incidence Functions for Competing Risks\", curvlab = c(\"Censored\", \"Mortality\", \"Relapse\"))\n\n\n\n\n\n\n\n\n# Estimate the cumulative incidence functions fo each even type per group\ncif &lt;- cuminc(ftime = data_bmt$ftime, \n              fstatus = data_bmt$status, \n              group = data_bmt$dis) # Estimates will calculated within groups\n\n# Plot the CIFs for both event types using survminer package\nggcompetingrisks(cif, multiple_panels = FALSE, legend = \"right\")\n\n\n\n\n\n\n\n\n# Show Gray's test for equality of CIFs\nprint(cif$Tests)\n##                stat          pv df\n## Censored  5.9785107 0.014481226  1\n## Mortality 0.9133497 0.339227192  1\n## Relapse   9.4874094 0.002068867  1\n\nGray’s test for equality of CIFs across groups (ALL vs. AML) is split across different types of events, here (Censored, Mortality, and Relapse).\n\nFor Censored, the p-value is small and suggest that there isa statistically significant difference in the CIF for censored events between the groups.\nFor Mortality, the p-value is greater than 0.05, suggesting that there is no statistically significant difference in the CIF for mortality between the groups.\nFor Relapse, the p-value is less than 0.05, indicating a statistically significant difference in the CIF for relapse between the groups.\nThe above suggest that the groups are behaving differently in terms of the time to relapse and censored events, but not for mortality.\n\n\n\n3.3.2 Competing Risks Regression\nadopted from https://www.nature.com/articles/bmt2009359\nSuppose that the BMT study was extended to include more participants and additional covariates and now includes:\n\n177 observations\nSex: gender of the individual\nD: disease; 0 = ALL; 1 = AML\nPhase: phase at transplant (Relapse, CR1, CR2, CR3)\nAge: age at the beginning of follow-up\nStatus: 0 = censored; 1 = Transplant-related mortality; 2 = relapse\nSource: source of stem cells (BM+PB, PB)\nftime: failure time\n\nWe are interested in modeling time to relapse in the presence of transplant-related death (competing event). We want to sutdy the effect on relapse of sex, disease type, phase at transplant, source of stem cells and age.\n\n# load additional libraries\nlibrary(fastDummies)\n\n# load data\ndata_bmtcrr &lt;- readRDS(\"data/data-bmtcrr.rds\")\n\n# preview data\nstr(data_bmtcrr)\n## 'data.frame':    177 obs. of  7 variables:\n##  $ Sex   : Factor w/ 2 levels \"F\",\"M\": 2 1 2 1 1 2 2 1 2 1 ...\n##  $ D     : Factor w/ 2 levels \"ALL\",\"AML\": 1 2 1 1 1 1 1 1 1 1 ...\n##  $ Phase : Factor w/ 4 levels \"CR1\",\"CR2\",\"CR3\",..: 4 2 3 2 2 4 1 1 1 4 ...\n##  $ Age   : int  48 23 7 26 36 17 7 17 26 8 ...\n##  $ Status: int  2 1 0 2 2 2 0 2 0 1 ...\n##  $ Source: Factor w/ 2 levels \"BM+PB\",\"PB\": 1 1 1 1 1 1 1 1 1 1 ...\n##  $ ftime : num  0.67 9.5 131.77 24.03 1.47 ...\n\n# prepare matrix of covariates\n# factor variables need to be coded as dummy variables\nx_sex &lt;- dummy_cols(data_bmtcrr$Sex) %&gt;% dplyr::select(.data_F)\nx_phase &lt;- dummy_cols(data_bmtcrr$Phase) %&gt;% dplyr::select(.data_CR1, .data_CR2, .data_CR3)\nx_d &lt;- dummy_cols(data_bmtcrr$D) %&gt;% dplyr::select(.data_AML)\nx_source &lt;- dummy_cols(data_bmtcrr$Source) %&gt;% dplyr::select(.data_PB)\nx &lt;- data.frame(age = data_bmtcrr$Age, sex = x_sex, x_d, x_phase, x_source)\ncolnames(x) &lt;- c(\"age\", \"sex_F\", \"D_AML\", \"P:CR1\", \"P:CR2\", \"P:CR3\", \"source:PB\")\n\n# The first regression model for relapse can be produced by typing\nmod1 &lt;- crr(ftime = data_bmtcrr$ftime, \n            fstatus = data_bmtcrr$Status, \n            cov1 = x)\n\nsummary(mod1)\n## Competing Risks Regression\n## \n## Call:\n## crr(ftime = data_bmtcrr$ftime, fstatus = data_bmtcrr$Status, \n##     cov1 = x)\n## \n##              coef exp(coef) se(coef)      z p-value\n## age       -0.0185     0.982   0.0119 -1.554  0.1200\n## sex_F     -0.0352     0.965   0.2900 -0.122  0.9000\n## D_AML     -0.4723     0.624   0.3054 -1.547  0.1200\n## P:CR1     -1.1018     0.332   0.3764 -2.927  0.0034\n## P:CR2     -1.0200     0.361   0.3558 -2.867  0.0041\n## P:CR3     -0.7314     0.481   0.5766 -1.268  0.2000\n## source:PB  0.9211     2.512   0.5530  1.666  0.0960\n## \n##           exp(coef) exp(-coef)  2.5% 97.5%\n## age           0.982      1.019 0.959 1.005\n## sex_F         0.965      1.036 0.547 1.704\n## D_AML         0.624      1.604 0.343 1.134\n## P:CR1         0.332      3.009 0.159 0.695\n## P:CR2         0.361      2.773 0.180 0.724\n## P:CR3         0.481      2.078 0.155 1.490\n## source:PB     2.512      0.398 0.850 7.426\n## \n## Num. cases = 177\n## Pseudo Log-likelihood = -267 \n## Pseudo likelihood ratio test = 24.4  on 7 df,\n\nThe first part of the output shows for each term in the design matrix the estimated coefficient \\(\\hat{\\beta}_j\\), the relative risk \\(\\mathrm{exp}(\\hat{\\beta}_j)\\), the standard error, the z-value and the corresponding P-value for assessing significance.\nHere, Sex is not significant, followed by Age and D (disease type), whereas Source is only marginally significant. Phase is a factor with relapse as baseline, so each P-value provides a test for the difference of each level with respect to the baseline.\nAn overall P-value for Phase can be obtained through the Wald test via aod R package:\n\nlibrary(aod)\nwald.test(mod1$var, mod1$coef, Terms = 4:6)\n## Wald test:\n## ----------\n## \n## Chi-squared test:\n## X2 = 14.0, df = 3, P(&gt; X2) = 0.0029\n\nThe first argument to the function wald.test() is the estimated covariance matrix for the coefficients, followed by the vector of coefficients estimates, and the position of coefficients for which we want to assess significance. In our case, the P-value indicates that Phase is statistically significant.\nThe second part of the output for competing risks regression shows the relative risk for each term, and a 95% confidence interval. The relative risk or subdistribution hazard ratio for a categorical covariate is the ratio of subdistribution hazards for the actual group with respect to the baseline, with all other covariates being equal. If the covariate is continuous then the relative risk refers to the effect of a one unit increase in the covariate, with all other covariates being equal. In our data, exp(−0.0352)=0.965 is the relative risk of a woman with respect to a man, and exp(−0.0185)=0.982 is the relative risk for a 1 year increase in age.\nThe last part of the output shows the pseudo log-likelihood at maximum and the pseudo likelihood ratio test, that is, the difference in the objective function at the global null and at the final estimates. As this objective function is not a true likelihood, this test statistic is not asymptotically distributed as a χ2. As a consequence, model comparison based on likelihood ratio approach cannot be performed directly, but significance must be evaluated through simulations. However, a model selection criterion can be easily adopted as described in the following section.\nFor an example on model selection, model diagnostics or adding time-varying covariates in presence of competing events, please refer to the original tutorial article Scrucca, Santucci, and Aversa (2010) https://www.nature.com/articles/bmt2009359.\n\n\n\n\nScrucca, L, A Santucci, and F Aversa. 2010. “Regression Modeling of Competing Risk Using r: An in Depth Guide for Clinicians.” Bone Marrow Transplantation 45: 1388–95. https://doi.org/10.1038/bmt.2009.359.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R examples</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Fine, Jason P., and Robert J. Gray. 1999. “A Proportional Hazards\nModel for the Subdistribution of a Competing Risk.” Journal\nof the American Statistical Association 94. https://doi.org/10.1080/01621459.1999.10474144.\n\n\nGray, Robert J. 1998. “A Class of k-Sample Tests for Comparing the\nCumulative Incidence of a Competing Risk.” The Annals of\nStatistics 16. https://doi.org/10.1214/aos/1176350951.\n\n\nScrucca, L, A Santucci, and F Aversa. 2010. “Regression Modeling\nof Competing Risk Using r: An in Depth Guide for Clinicians.”\nBone Marrow Transplantation 45: 1388–95. https://doi.org/10.1038/bmt.2009.359.",
    "crumbs": [
      "References"
    ]
  }
]