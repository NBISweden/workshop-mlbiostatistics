---
title: "Descriptive statistics"
# author: Eva Freyhult, Olga Dethlefsen
format: 
  revealjs:
    slide-number: true
    view-distance: 10
    theme: [default, custom.scss]
    chalkboard: 
      buttons: true
  html:
    code-fold: false
editor_options: 
  
  chunk_output_type: console
---

```{r}
#| message: false
#| warning: false

# load libraries
library(tidyverse)
library(magrittr)
library(kableExtra)
library(ggplot2)
library(rmarkdown)
library(ggbeeswarm)
library(gridExtra)
library(ggmosaic)
library(scales)
```

## Introduction

*Two main types of statistics*

```{r}
#| echo: false
#| out-width: 100%
#| fig-align: center
knitr::include_graphics("images/stats-types.png")
```

-   **Descriptive statistics** describes and summarizes the data.
-   It can be contrasted with **inferential statistics** that uses a sample of data to make inferences about the population that the sample of data is drawn from.

## Introduction

*Descriptive statistics*

<br>

Descriptive statistics is a term describing simple analyses of data to help getting to know the data by:

::: incremental
-   describing the data
-   showing & visualizing the data
-   summarizing the data
:::

. . .

<br> Beyond getting to know the data descriptive statistics is used to:

. . .

::: incremental
-   uncover potential patterns in the data, incl. outliers
-   guide down-stream analysis
:::

## Data types

*numerical & categorical data types*

<br>

. . .

One of the first thing we tend to notice about the data is the data type. We differentiate between categorical (qualitative) and numerical (quantitative) data types.

<br> <br>

```{mermaid}
flowchart LR
  A(Data types) --> B(Categorical)
  A --> C(Numerical)
```

. . .

<br> <br>

**Depending on the data type we use different methods to describe, summarize and visualize the data. Beyond descriptive statistics, we even use different methods to analyse the data.**

## Data types

*Categorical data*

<br> **Categorical data** can be further divided into:

<br>

```{mermaid}
flowchart LR
  A(Data types) --> B(Categorical)
  A --> C(Numerical)
  B(Categorical) --> D(Nominal i.e. named)
  B --> E(Ordinal i.e. named and ordered)
```

<br>

. . .

-   Nominal: named, categories are mutually exclusive and unordered
    -   *e.g.dead/alive, healthy/sick, WT/mutant, A/B/AB/O, male/female, red/green/blue*

. . .

-   Ordinal: named and ordered, categories are mutually exclusive and ordered
    -   *e.g. pain (weak, moderate, severe), very young/young/middle age/old/very old, grade I, II, III, IV*

## Data types

*Numerical data*

<br> **Numerical data** can be further divided into: <br>

```{mermaid}
flowchart LR
  A(Data types) --> B(Categorical)
  A(Data types) --> C(Numerical)
  C(Numerical) --> D(Discrete i.e. finite or countable infinite values)
  C(Numerical) --> E(Continuous i.e. infinitely many uncountable values)
```

<br>

. . .

-   Discrete: finite or countable infinite values
    -   *days sick last year, number of cells, number of reads*

. . .

-   Continuous: infinitely many uncountable values
    -   *e.g. height, weight, concentration*

## Diabetes data set

*Example data set*

<br>

::: columns
::: {.column width="50%"}
-   403 participants were interviewed in a study to understand the prevalence of obesity, diabetes, and other cardiovascular risk factors in central Virginia
-   The data is available as part of `faraway` package.
:::

::: {.column width="50%"}
```{r}
#| echo: false
#| warning: false
#| message: false
#| include: true

library(tidyverse)
library(kableExtra)
library(faraway)

# Diabetes data from faraway() package
df <- diabetes

c1 <- colnames(df)
c2 <- c("Subject ID", "Total Cholesterol [mg/dL]", "Stabilize Glucose [mg/dL]", 
        "High Density Lipoprotein [mg/dL]", "Cholesterol / HDL Ratio", "Glycosolated Hemoglobin [%]", 
        "County: Buckingham or Louisa", "age [years]", "gender", 
        "height [in]", "weight [lb]", "frame: small, medium or large", 
        "First Systolic Blood Pressure", "First Diastolic Blood Pressure", 
        "Second Systolic Blood Pressure", "Second Diastolic Blood Pressure", 
        "waist [in]", "hip [in]", 
        "Postprandial Time [min] when labs were drawn")

tbl <- data.frame(Abbreviation = c1, Description = c2)

kbl_font_size <- 14

tbl %>% 
  kbl(align = "c") %>%
  kable_paper("hover", full_width = F) %>%
  kable_styling(font_size = kbl_font_size)

```
:::
:::

## Diabetes data set

*Example data set*

<br>

::: columns
::: {.column width="45%"}
-   Glycosolated hemoglobin $>7.0$ is usually taken as a positive diagnosis of diabetes, so we can add variable `diabetic` (yes/no) reflecting this information.
-   We can calculate BMI as $BMI = 703 \times (weight \; [lb] \; / (height \;[in])^2)$ and define obesity as $BMI \ge 30$ storing this information in `obese` variable (yes/no).
-   First few observations omitting samples with missing data (complete case analysis) are shown on the right.
:::

::: {.column width="5%"}
:::

::: {.column width="50%"}
```{r}

# add obesity and diabetes variables
inch2m <- 2.54/100
pound2kg <- 0.45
data_diabetes <- diabetes %>%
  mutate(height  = height * inch2m, height = round(height, 2)) %>% 
  mutate(waist = waist * inch2m) %>%  
  mutate(weight = weight * pound2kg, weight = round(weight, 2)) %>%
  mutate(BMI = weight / height^2, BMI = round(BMI, 2)) %>% 
  mutate(obese= cut(BMI, breaks = c(0, 29.9, 100), labels = c("No", "Yes"))) %>% 
  mutate(diabetic = ifelse(glyhb > 7, "Yes", "No"), diabetic = factor(diabetic, levels = c("No", "Yes"))) %>%
  na.omit()
  
# preview data
glimpse(head(data_diabetes))
```
:::
:::

## Categorical data

*Summarizing categorical data*

. . .

<br> <br>

```{mermaid}
%%| label: fig-cat-summary
%%| fig-align: center
%%| fig-cap: "Main method of summarizing categorical data types. Numerical summaries include frequency, summary and contingency tables together with listing proportions and percentages. Graphical summaries include bar charts, pie charts and mosaic plots."
flowchart TD
  A(Categorical data) --> B(Numerical summary)
  B(Numerical summary) --> D(Table of frequencies <br/> Proportions <br/> Percentages <br/> ...)
  A(Categorical data) --> C(Graphical summary)
  C(Graphical summary) --> E(Bar chart <br/> Pie chart <br/> Mosaic plot <br/> ...)
```

## Categorical data

*Summarizing categorical data*

<br>

Let's preview again first few measurements of diabetes data set focusing on `gender` and `obese` variables.

<br>

::: columns
::: {.column width="40%"}
```{r}
#| label: tbl-diabetes-preview
#| tbl-cap: "Diabetes data: first few observations of gender and obesity status."

data_diabetes %>%
  dplyr::select("id", "gender", "obese") %>%
  dplyr::slice(1:10) %>%
  as_tibble() %>%
  kbl(align = "c") %>%
  kable_paper("hover", full_width = T) %>%
  kable_styling(font_size = kbl_font_size)
  
```
:::

::: {.column width="10%"}
:::

::: {.column width="50%"}
-   Information about `gender` and `obese` status falls under categorical data type.
-   To summarize these variables we can ask questions such as:
    -   how many participants we have in each category?
    -   what are the percentages or proportions in each category?
-   We can also visualize these descriptive statistics in a bar chart of a pie chart.
:::
:::

## Categorical data

*Frequency table. Bar and pie charts.*

<br> Frequency table shows the number, percentages and proportions of study participants with BMI $\ge$ 30 and with BMI \< 30.

```{r}
# count frequencies, percentages and proportions
table.summary <- data_diabetes %>%
  group_by(obese) %>%
  tally() %>%
  mutate("percent (%)" = n/sum(n)*100) %>%
  mutate("proportion" = n/sum(n))

# show table
kable(table.summary, digits = 1) %>% 
  kable_styling(full_width = TRUE)
```

. . .

<br>

::: columns
::: {.column width="50%"}
Bar chart

```{r}
# set a custom ggplot theme
font.size <- 30
my.ggtheme <- theme(axis.title = element_text(size = font.size), 
        axis.text = element_text(size = font.size), 
        legend.text = element_text(size = font.size), 
        legend.title = element_blank(), 
        axis.title.y = element_text(angle = 0))

# use ggplot to draw a bar chart
data_diabetes %>%
  ggplot(aes(x = obese, fill = obese)) +
  geom_bar(width = 0.5) +
  scale_fill_brewer(palette = "Paired") + 
  theme_bw() +
  my.ggtheme

```
:::

::: {.column width="50%"}
Pie chart

```{r}

# draw pie chart
data_diabetes %>%
  ggplot(aes(x="", y = obese, fill = obese)) +
  geom_bar(width = 1, stat = "identity") +
  theme_bw() +
  coord_polar("y", start=0) +
  scale_fill_brewer(palette="Paired") +
  xlab("") +
  ylab("") + 
  my.ggtheme

```
:::
:::

## Categorical data

*Summary and contingency table: 2 categorical variables*

. . .

<br>

When we are interested in how one categorical variable is related to another categorical variable, we can use a **summary table**. For instance, we can look at the relationship between obesity (yes/no) and diabetes (yes/no). <br>

```{r}

data_diabetes %>%
  group_by(obese) %>%
  dplyr::summarize(Total=n(), `Diabetic` = sum(gender=="male")) %>% 
  mutate(`Diabetic (%)` = round(`Diabetic` * 100 / Total, 2)) %>%
  kable() %>%
  kable_styling(full_width = TRUE)

```

. . .

<br> <br>

**Contingency table**, sometimes called two-way frequency table, shows the multivariate frequency distribution of variables. <br>

```{r}
# use table() function to create contingency table
table.con <- table(data_diabetes$obese, data_diabetes$diabetic)
table.con <- addmargins(table.con)
rownames(table.con) <- c("Non-obese", "Obese", "Sum")
colnames(table.con) <- c("Non-diabetic", "Diabetic", "Sum")

table.con %>%
  kable(row.names = TRUE) %>%
  kable_styling(full_width = TRUE) %>%
  column_spec(4, bold = T) %>%
  row_spec(3, bold = T)

```

## Categorical data

*Bar charts: 2 categorical variables*

. . .

<br>

Bar charts can be used to visualize two and more categorical variables, e.g. by using **stacking**, **side-by-side bars** or **colors**.

<br>

```{r}
#| label: fig-cat2-barplot
#| fig-align: center
#| fig-cap: "Bar charts visualizing two caterogircal variables using stacking, side-by-side bars and colours."
#| out-height: 10cm


p1 <- data_diabetes %>% 
  ggplot(aes(x=obese, fill=diabetic)) + 
  geom_bar() + 
  theme_bw() + 
  xlab("obese") + 
  ylab("count (diabetic)") +
  ggtitle("Stacked bars") + 
  scale_fill_brewer(palette = "Paired") 

p2 <- data_diabetes %>% 
  ggplot(aes(x=obese, fill=diabetic)) + 
  geom_bar(position = "dodge") + 
  theme_bw() + 
  xlab("obese") + 
  ylab("count (diabetic)") +
  ggtitle("Side-by-side bars") + 
  scale_fill_brewer(palette = "Paired") 

p3 <- data_diabetes %>% 
  ggplot(aes(x=obese, fill=diabetic)) + 
  geom_bar(position = "fill") + 
  theme_bw() + 
  xlab("obese") + 
  ylab("fraction (diabetic)") +
  ggtitle("Fraction stacked") + 
  scale_fill_brewer(palette = "Paired") 


grid.arrange(p1, p2, p3, ncol = 3)

```

## Categorical data

*Mosaic plot*

<br>

<!-- Mosaic plots display contingency tables, here contingency table of obesity and diabetic status among study participants, also including gender. -->

```{r}
#| label: fig-cat2-mosaic
#| fig-align: center
#| fig-cap: "Mosaic plots display contigency tables, here of obesity and diabetic status among study pariticipants (left) and colour-coded by gender (right)."

p1 <- ggplot(data = data_diabetes) +
  geom_mosaic(aes(x = product(obese), fill=diabetic)) + 
  theme_bw() + 
  scale_fill_brewer(palette = "Paired")

p2 <-  ggplot(data = data_diabetes) +
  geom_mosaic(aes(x = product(obese, gender), fill=diabetic)) + 
  theme_bw() + 
   scale_fill_brewer(palette = "Set2") 

grid.arrange(p1, p2, ncol = 2)

 
```

## Numerical data

*Summarizing numerical data*

. . .

<br>

Numerical data can be visualized and summarized in many ways. Common plots include **histograms, density plots and scatter plots**. Summary statistics include **measures of location** such as mode and median and **measures of spread** such as variance or median absolute deviation. It is also common to visualize summary statistics, e.g. on box plot.

<br>

```{mermaid}
flowchart TD
  A(Numerical data) --> B(Numerical summary)
  A(Numerical data) --> C(Graphical summary)
  B(Numerical summary) --> D(Measures of location <br/> e.g. mode, average, median)
  B --> E(Measures of spread <br/> e.g. quartiles, variance, standard deviation)
  C(Graphical summary) --> F(Histogram <br/> Density plot <br/> Box plot <br/> ...)
```

## Numerical data

*Strip plot, Jittered strip plot & Beeswarm plot*

. . .

<br>

If it is technically feasible, it is recommended to visually assess all measurements on a plot.

<br>

```{r}
#| label: fig-num-1d
#| fig-align: center
#| fig-cap: "Strip plot, jittered strip plot and beeswarm plot showing all measurmentes of age variable (complete cases analysis)."
#| out-height: 10cm


# plot strip plot
p1 <- data_diabetes %>%
  ggplot(aes(x = "", y = age)) + 
  geom_point(size = 3, alpha = 0.8) + 
  theme_bw() + 
  ylab("age") + 
  xlab("") + 
  ggtitle("Strip plot")

p2 <- data_diabetes%>%
  ggplot(aes(x = "", y = age)) + 
  geom_jitter(height = 0, width = 0.2, size = 3, alpha = 0.8) + 
  theme_bw() + 
  ylab("age") + 
  xlab("") +
  ggtitle("Jittered plot")

p3 <- data_diabetes %>%
  ggplot(aes(x = "", y = age)) + 
  geom_beeswarm(cex = 2, size = 3, alpha = 0.8) + 
  theme_bw() + 
  ylab("age") + 
  xlab("") + 
  ggtitle("Beeswarm plot")

grid.arrange(p1, p2, p3, ncol = 3)
```

## Numerical data

*Histogram & density plot* <br>

. . .

A **histogram** bins the data and counts the number of observations that fall into each bin. A **density plot** is like a smoothed histogram where the total area under the curve is set to 1. A density plot is an approximation of a distribution.

```{r}
#| label: fig-hist-den
#| fig-align: center
#| fig-cap: "Histogram of the age measurmentes exluding missing data (left) and a corresponding density plot (right)."
#| out-width: 20cm
#| out-height: 10cm

# plot histogram
col.blue.light <- "#a6cee3"
col.blue.dark <- "#1f78b4"
p1 <- data_diabetes %>%
  ggplot(aes(x = age)) + 
  geom_histogram(binwidth = 5, center = 32.5, color = "white", fill = col.blue.dark) + 
  theme_bw() + 
  xlab("age") 

# plot density plot
p2 <- data_diabetes %>% ggplot(aes(x = age)) + 
  geom_density() + 
  theme_bw() + 
  xlab("age") 

grid.arrange(p1, p2, ncol = 2)

```

## Numerical data

*Scatter plot: 2 numerical variables*

<br>

. . .

Scatter plots are useful when studying a relationship (association) between two numerical variables.

. . .

```{r}
#| label: fig-scatter
#| out-height: 10cm
#| out-width: 20cm
#| fig-align: center
#| fig-cap: "Scatter plot showing relationship between weight and height (left) and including color-coding by gender (right)."

# plot scatter plot
p1 <- data_diabetes %>%
  mutate(group = "all") %>%
  ggplot(aes(x = weight, y = height, color = group)) + 
  geom_point(size = 3, alpha = 0.8) + 
  xlab("weight [kg]") + 
  ylab("height [m]") + 
  theme_bw() +
  theme(legend.position = "top") + 
  scale_color_manual(values = "black")

# plot scatter plot
p2 <- data_diabetes %>%
  ggplot(aes(x = weight, y = height, color = gender)) +
  geom_point(size = 3, alpha = 0.8) +
  xlab("weight [kg]") +
  ylab("height [m]") +
  theme_bw() +
  scale_color_brewer(palette = "Dark2") + 
  theme(legend.position = "top")

grid.arrange(p1, p2, ncol = 2)

```

## Numerical data

*Scatter plot: 2 numerical variables cont.* <br>

. . .

Sometimes, it is useful to connect the observations in the order in which they appear, e.g. when analyzing time series data. The diabetes data set does not contain any measurements over time but we can simulate some BMI values over time for demonstration purposes.

. . .

<br>

```{r}
#| label: fig-trend
#| out-width: 20cm
#| out-height: 10cm
#| fig-align: center
#| fig-cap: "Scatter plot for simulated over 12 weeks BMI values for 10 participants in a mock up study (left) and colour-coded by a study group."


# simulate BMI over time
# select participants with BMI >= 30
# assign half to control group and half to treatment to reduce weight 
# add simulated weight loss values to treatment group ca. 0.2 kg per week
# add simulated weight fluctuations, ca plus / minus 0.1 kg per week

data_diabetes_bmi30 <- data_diabetes %>% 
  filter(BMI >= 30) %>%
  select(id, weight, height, BMI) %>%
  mutate(group=sample(c("control", "treatment"), size=n(), replace=TRUE))

# add 52 weeks of simulated BMI values

no_weeks <- 12
weight_sim <- matrix(data = NA, 
                     nrow = nrow(data_diabetes_bmi30), 
                     ncol = no_weeks, 
                     dimnames = list(data_diabetes_bmi30$id, paste("week", 1: no_weeks, sep=""))) # initiate matrix to store simulated BMI values
weight_sim[, 1] <- data_diabetes_bmi30$weight # first column: baseline weight

for (n in 1:nrow(data_diabetes_bmi30)){
  
  for (p in 2:ncol(weight_sim)){
    
    # if control group: just fluctuate weight by random values between 0 and 0.2 kg
    # if treatment: decrease by random values between 0.1 and 0.5 kg from
    
    if (data_diabetes_bmi30$group[n] == "treatment"){
     
      loss <- runif(1, 0.1, 0.5) %>% round(1)
      weight_sim[n, p] <- weight_sim[n, p-1] - loss
      
    } else{
      
      fluctuation <- runif(1, -0.2, 0.2) %>% round(1)
      weight_sim[n, p] <- weight_sim[n, p-1] + fluctuation
      
    }
  
  }
}

# convert to tibble
weight_sim <- weight_sim %>%
  as_tibble(rownames = "id") %>%
  mutate(id = as.numeric(id))

# join data_diabetes_bmi30 with simulated
# keep 5 treatment and 5 control participants
data_diabets_sim <- data_diabetes_bmi30 %>%
  as_tibble() %>% 
  left_join(weight_sim, by = "id")

# plot BMI over time
data_plot <- data_diabets_sim %>%
  slice_sample(n = 10) %>%
  select(-weight, -BMI) %>% 
  pivot_longer(-c("id", "group", "height"), names_to = "week", values_to = "weight") %>% 
  mutate(BMI = weight / (height^2)) %>%
  mutate(week = gsub("week", "", week)) %>%
  mutate(week = as.numeric(week)) 

p1 <- data_plot %>%
  mutate(group = "id") %>%
  ggplot(aes(x = week, y = BMI, group = id, colour = group)) + 
  geom_point() +
  geom_line() + 
  xlab("week") +
  ylab("BMI") +
  theme_bw() +
  scale_color_manual(values = "black") + 
  scale_x_continuous(breaks= pretty_breaks()) + 
  theme(legend.position = "top")

data_plot <- data_diabets_sim %>%
  group_by(group) %>%
  slice_sample(n = 5) %>%
  select(-weight, -BMI) %>% 
  pivot_longer(-c("id", "group", "height"), names_to = "week", values_to = "weight") %>% 
  mutate(BMI = weight / (height^2)) %>%
  mutate(week = gsub("week", "", week)) %>%
  mutate(week = as.numeric(week)) 

p2 <- data_plot %>%
  ggplot(aes(x = week, y = BMI, group = id, colour = group)) + 
  geom_point() +
  geom_line() + 
  xlab("week") +
  ylab("BMI") +
  theme_bw() +
  scale_color_brewer(palette = "Dark2") +
  scale_x_continuous(breaks= pretty_breaks()) +
  theme(legend.position = "top")

grid.arrange(p1, p2, ncol = 2)

```

## Measures of location & spread

<br>

```{mermaid}
flowchart LR
  A(Representative value) --> C(Image of data)
  B(Spread) --> C(Image of data)
```

<br>

::: incremental
-   It is not always easy to get a "feeling" for a set of numerical measurements unless we summarize the data in a meaningful way.
-   We can further condense the information shown previously on diagrams by reporting what constitutes a **representative value**. If we also know **how widely scattered** the observations are around it, we can formulate an image of data.
-   The **average** is a general term for a measure of **location** and some common ways of calculating the average are mode, mean and median.
:::

## Measures of location

*Mode* <br>

-   Mode values is the value that most common occurs across the measurements. It can be found for **numerical and categorical** data types.

. . .

-   For instance, we can find `age` mode value by counting how many times we observe each age value among the study participants. The top three counts are below and the mode is thus 63.

```{r}
data_diabetes %>%
  group_by(age) %>%
  tally() %>%
  arrange(desc(n)) %>%
  slice(1:3) %>%
  kbl() %>%
  kable_paper("hover", full_width = T) %>%
  kable_styling(font_size = 14)
```

. . .

<br>

-   Analogously, we can find mode value for the categorical `diabetic status` by counting how many of the participants are diabetic and how many are not.

```{r}
data_diabetes %>%
  group_by(diabetic) %>%
  tally() %>%
  arrange(desc(n)) %>%
  slice(1:3) %>%
  kbl %>%
  kable_paper("hover", full_width = T) %>%
  kable_styling(font_size = 14)
```

## Measures of location

*Median* <br>

Median value divides the **ordered** data values into two equally sized groups so that 50% of the values are below and 50% are above the median value.

```{=tex}
\begin{equation}
    Median =
    \left\{
        \begin{array}{cc}
                \frac{(n+1)}{2}^{th} term & \mathrm{if\ } n \mathrm{\ is\ odd} \\
                \frac{1}{2}\times \left (\frac{n}{2}^{th} term + (\frac{n}{2}+1)^{th} term \right) & \mathrm{if\ } n \mathrm{\ is\ even}  \\
        \end{array}
    \right.
\end{equation}
```
. . .

For instance, the median value for `age` for the first 10 study participants:

```{r}
#| results: asis
#| tbl-cap: Age values for the first 10 study participants.
#| tbl-cap-location: margin
age_10 <- data_diabetes %>%
  slice(1:10)  # select first 10 participants

# show age for 10 first participants
age_10 %>%
  select(id, age) %>% 
  pivot_wider(names_from = id, values_from = age) %>%
  kbl() %>%
  kable_paper("hover", full_width = T) %>%
  kable_styling(font_size = 14) 

```

can be found by ordering observations:

```{r}
age_10_ordered <- data_diabetes %>%
  slice(1:10) %>% # select first 10 participants
  arrange(age) %>% # order by age
  pull(age) # extract ordered age observations

data_diabetes %>%
  slice(1:10) %>% # select first 10 participants
  arrange(age) %>%
  select(id, age) %>% 
  pivot_wider(names_from = id, values_from = age) %>%
  kbl() %>%
  kable_paper("hover", full_width = T) %>%
  kable_styling(font_size = 14) %>%
  column_spec(c(5), background = "gold") %>%
  column_spec(c(6), background = "gold")


```

and averaging $5^{th}$ and $6^{th}$ term in the ordered observations giving a median value of:

```{r}
#| code-fold: false
1/2*(age_10_ordered[5] + age_10_ordered[6])
```

## Measures of location

*Mean & weighted mean* <br>

**The arithmetic mean**, also commonly referred to as **mean**, is calculated by adding up all the values and diving the sum by the number of values in the data set.

Mathematically, for $n$ observations $x_1, x_2, \dots, x_n$, the arithmetic mean value is calculated as: $$\bar x = \frac{x_1+x_2+\dots+x_n}{n} = \frac{1}{n}\displaystyle\sum_{i=1}^n x_i$$ {#eq-mean}

. . .

**Weighted mean** allows to add weights to certain values of the variable of interest. We attach a weight, $w_i$ to each of the observed values, $x_i$, in our sample, to reflect this importance and define the weighted mean as: $$\bar{x} = \frac{w_1x_1 + w_2x_2 + \ldots + w_nx_n}{w_1 + w_2 + \ldots + w_n} = \frac{\displaystyle\sum_{i=1}^{n}w_ix_i}{\displaystyle\sum_{i=1}^{n}w_i}$$ {#eq-mean-weighted}

. . .

## Measures of location

*Mean & weighted mean* <br>

::: {#exm-wmean}
For instance, we may be interested in knowing an average `BMI` value, irrespective of `gender`. It happens that among our study participants women are over represented:

```{r}
data_diabetes %>%
  group_by(gender) %>%
  tally() %>%
  kbl() %>%
  kable_paper("hover", full_width = T) %>%
  kable_styling(font_size = 14)

```

Assuming BMI measurements for men and women should have equal influence (50/50) and knowing BMI average for men and women separately:

```{r}
data_diabetes %>%
  group_by(gender) %>%
  summarize(mean_BMI = mean(BMI)) %>%
  kbl(digits = 2) %>%
  kable_paper("hover", full_width = T) %>%
  kable_styling(font_size = 14)

```

What is the weighted BMI mean?
:::

## Measures of location

*Mean, median & outliers*

<br>

Median is usually preferred when data has outliers as it follows from median definition that is less sensitive to outliers. On the other hand, mean value can be distorted when outliers are present.

. . .

<br>

::: {#exm-outlier}

Let's add an outlying value of age (110) to the first 11 study participants, and re-calculate mean and median.

```{r}
# pull age values for the first 11 study participants
age_11 <- data_diabetes %>%
  slice(1:11) %>%
  select(id, age) %>%
  pull(age)
  
# add outlier value of 110
age_11_with_outlier <- c(age_11, 110)

# calculate mean and median, with and without outlier

# without outlier
age_mean_without <- mean(age_11) %>% round(2)
age_median_without <- median(age_11)

# with outlier
age_mean_with <- mean(age_11_with_outlier) %>% round(2)
age_median_with <- median(age_11_with_outlier)

res <- data.frame(mean = c(age_mean_without, age_mean_with), 
                  median = c(age_median_without, age_median_with), 
                  row.names = c("without outlier", "with outlier"))

res %>%
  kbl() %>%
  kable_paper("hover", full_width = T) %>%
  kable_styling(font_size = 14)

```

We can see that adding one outlying age value shifted mean age from `r age_mean_without` to `r age_mean_with` while median age value did not change that much with original median value being `r age_median_without` and `r age_median_with` after adding the outlying value.
:::

## Measures of location

*Mean, median & outliers*

<br>

In addition, it is good to remember that several very different distributions can still have the same mean value.



```{r mean35, warning=FALSE, message=FALSE, include=T, echo=F}
#| fig-cap: Examples of various distributions having the same mean value of 3.5
#| label: fig-mean-distr
#| fig-width: 20
#| fig-height: 10
#| fig-cap-location: margin

df <- data.frame(x=rnorm(200, 3.5, 2))
df$x <- df$x - mean(df$x) + 3.5
y <- exp(rnorm(200, 0, 1))
y <- y+3.5 - mean(y)
df$y=y

df$z <- rep(c(0,10), c(200*.65, 200*.35))

df$a <- rnorm(200, 3.5, 8)
df$a <- df$a - mean(df$a) + 3.5
b <- exp(rnorm(200, 2, 1))
df$b <- b+3.5 - mean(b)
c <- c(rnorm(150, 10, 3), rnorm(50,0,1))
c <- c + 3.5 - mean(c)
df$c <- c

data.plot <- df
colnames(data.plot) <- c("Distr1", "Distr2", "Distr3", "Distr4", "Distr5", "Distr6")
data.plot %>%
  rownames_to_column("x") %>%
  pivot_longer(-x, names_to = "Distr") %>%
  ggplot(aes(x = value)) +
  geom_histogram(color="white", bins=30) +
  facet_wrap(~Distr, scale = "free") +
  theme_bw() +
  xlab("") + 
  my.ggtheme

```

## Measures of spread
*Range, quartiles and IQR*
<br>

- The **range** is the difference between the largest and the smallest observations in the data set. 
- **Quartiles** are the **three values** that divide the data values into **four equally sized groups**.
- The **interquartile range**, IQR, is the difference between the 1st (Q1) and the 3rd (Q3) quartiles, i.e. between the 25th and 75th percentiles.

<br>


![](images/quartiles-anno.png){width = 80%}

```{r}
#| include: false
#| eval: false

age_10_ordered <- data_diabetes %>%
  slice(1:9) %>% # select first 10 participants
  arrange(age) %>% # order by age
  pull(age) # extract ordered age observations

data_diabetes %>%
  slice(1:9) %>% # select first 10 participants
  arrange(age) %>%
  select(id, age) %>% 
  pivot_wider(names_from = id, values_from = age) %>%
  kbl() %>%
  kable_paper("hover", full_width = T) %>%
  kable_styling(font_size = 14) %>%
  column_spec(c(5), background = "gold") 

```

## Measures of spread
*Variance and standard deviation*
<br>

The **variance** of a set of observations is their mean squared distance from the mean value:

$$\sigma^2 = \frac{1}{n} \sum_{i=1}^n (x_i - \bar x)^2$$ {#eq-sigma2}

```{r}
#| label: fig-var
#| fig-cap: First ten age measurements for the study participants. Grey lines show the distance to the mean age value.
#| fig-cap-location: margin

data.xy <- data_diabetes %>%
  slice(1:10) %>% 
  mutate(id = as.character(id)) %>%
  rename(y = age) %>%
  rename(x = id)

y.bar <- mean(data.xy$y)

data.xy %>%
ggplot(aes(x=x, y=y)) +
  geom_segment( aes(x=x, xend=x, y=y, yend=y.bar), color="grey") +
  geom_point(color=col.blue.dark, size=4) +
  geom_hline(yintercept=y.bar) +
  theme_bw() +
  theme(
    panel.grid.major.x = element_blank(),
    panel.border = element_blank(),
    axis.ticks = element_blank(),
    axis.text.y = element_blank()) +
  xlab("") +
  ylab("Age (year)") +
  coord_flip() 

```


## Measures of spread
*Variance and standard deviation*

<br>

**Standard deviation** is defined as the square root of the variance:

<br>
$$\sigma = \sqrt{\frac{1}{n} \sum_{i=1}^n (x_i - \bar x)^2}$$ {#eq-sigma}


## Measures of spread
*Sample variance and standard deviation*

<br>

Typically, we regard the collection of observations $x_1, \dots, x_n$ as a **sample** drawn from a large **population** of possible observations. It has been shown that we obtain a better sample estimate of the population variance and standard deviation if we divide by $(n-1)$. So the denominator $n$ is commonly replaced by $n-1$ and the **sample variance** is calculated instead as:

. . .

$$s^2 = {\frac{1}{n-1} \sum_{i=1}^n (x_i - \bar x)^2}.$$ {#eq-s2}


. . .

<br>
and the **sample standard deviation** is calculated as:

. . .

$$s = \sqrt{\frac{1}{n-1} \sum_{i=1}^n (x_i - \bar x)^2}.$$ {#eq-s}

## A box-and-whisker plot
*Boxplot*

. . .

<br>

:::: {.columns}

::: {.column width="60%"}
- A box-and-whisker plot is a **diagram summarizing numerical data through quartiles**. 
- It is shown as a vertical or horizontal rectangle **box**, with the ends of rectangle corresponding to the upper (Q3) and lower (Q1) quartiles of the data values. A line drawn through the rectangle corresponds to the median value (Q2). 
- There can be also lines called **whiskers** extending from the rectangle indicating variability outside the upper and lower quartiles. These can be defined in few ways^[Whiskers can indicate i) minimum and maximum values or ii) particular percentiles, e.g. 5th and 95th. On the box plot prepared with `R` function `boxplot()` or `geom_boxplot()` the upper whisker extends by default to the largest value no further than 1.5 * IQR from Q3 while the lower whiskers extends by default to the smallest value at most 1.5 * IQR from Q1.].
- Data beyond the end of the whiskers are called "outlying" points and are plotted individually.
:::

::: {.column width="40%"}
![](images/boxplot-annotated.png){}
:::

::::

## A box-and-whisker plot
*Boxplot*

<br>

:::: {.columns}

::: {.column width="60%"}
- We have recommended to visually assess all the observations. 
- We can overlay jitter plot on the box plot to get a complete picture of both the data and the quartiles summary statistics.
- On the right we see a box-and-whisker plot overlayed on the jitter plot for the BMI values based on the measurements for the 130 study participants
:::

::: {.column width="40%"}
```{r}
#| fig-height: 12

data_diabetes %>%
  ggplot(aes(x = "", y = BMI)) + 
  geom_boxplot(alpha = 1, col = "black", outlier.colour = "red", width = 0.5, outlier.size = 5) + 
  geom_jitter(width = 0.2, alpha = 0.5, size = 5) + 
  xlab("") + 
  theme_classic() + 
  my.ggtheme

```
:::

::::


## Lifecycle of data science
*Descriptive stats in context*

<br>

```{mermaid}
flowchart LR
  A(Define problem) --> B(Collect data)
  B --> C(Clean data)
  C --> D(Explore data)
  D --> E(Inferential statistics)
  D --> F(Predictive modelling)
  E --> G(Communicate results)
  F --> G(Communicate results)
  
```

<br>

- Descriptive statistics can be useful in most if not all phases of the project. 
- We rely the most on descriptive statistics during the exploring data phase. This phase, is often called **Exploratory Data Analysis** and abbreviated as **EDA**. 
- EDA was introduced in 1970s by John Tukey to encourage statisticians to explore the data, and formulate hypotheses that could lead to new data collection and experiments. 
- Prior the introduction of EDA, **initial data analysis**, **IDA** was used with a narrow focus on checking data quality and model assumptions required for statistical modeling and hypothesis testing. 

## Lifecycle of data science
*Descriptive stats in context*

<br>

```{mermaid}
flowchart LR
  A(Define problem) --> B(Collect data)
  B --> C(Clean data)
  C --> D(Explore data)
  D --> E(Inferential statistics)
  D --> F(Predictive modelling)
  E --> G(Communicate results)
  F --> G(Communicate results)
  G --> A
  G --> B
  G --> C
  G --> D
  E --> A
  E --> B
  E --> C
  E --> D
  F --> B
  F --> C
  F --> D
  
```

. . .

<br>

Data science projects rarely require only one pass through the project phases and often one returns to previous steps many times given the results from the down-stream steps. For instance, one may perform EDA, discover and handle missing data, and redo the EDA. Or one may try some hypothesis tests that would lead to new questions for which one would repeat both EDA and inferential data analysis parts. 

## Summary

<br>

::: incremental
-   Descriptive statistics is usually the first step of data analysis in which we try to familiarize ourselves with the data
-   Numerical summaries displaying data diagrammatically give us idea about data distributions. They can also uncover some errors or outliers as well as emerging patterns in the data.
-   Often, descriptive statistics together with data cleaning and processing, is the most time-consuming part of a bioinformatics project.
:::

. . .

**It is always a good idea to look at the raw measurements, printing them all for smaller data sets or printing randomly selected measurements from bigger data sets.**

. . .

<br> For many more options for plotting check out The R Graph Gallery <https://r-graph-gallery.com>

## Thank you

questions?
