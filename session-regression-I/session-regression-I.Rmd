---
title: 'Session regression I: simple linear regression'
output:
  html_document:
    df_print: paged
  pdf_document:
    fig_caption: yes
    keep_tex: yes
header-includes: \usepackage{float}
urlcolor: blue
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.path="session-regression-I-files/figures/")
knitr::opts_chunk$set(fig.pos = 'H')
```


## Learning outcomes
- understand simple linear regression model incl. terminology and mathematical notations
- estimate model parameters and their standar error
- use model for checking the association between _x_ and _y_
- use model for prediction
- assees model accuracy with RSE and R$^2$
- check model assumptions
- to be able to use `lm` function in R for model fitting, obtaining confidence interval and predictions

-------

## Introduction
- [Quiz](https://forms.gle/bHZr1MP454npysAFA): What do we already know about `simple linear regression`? 



#### Description
- Simple linear regression is a statistical method that allows us to summarize and study relationships between two continuous (quantitative, numerical) variables
  - one variable, denoted `x` is regarded as the *predictor*, *explanatory*, or *indepedent variable*, e.g. body weight (kg)
  - the other variable, denoted `y`, is regarded as the *response*, *outcome*, or *dependent variable*, e.g. plasma volume (l)
- It is used to estimate the best-fitting straight line to describe the association

#### Used for to answer questions such as: 
- is there a relationship between `x` exposure (e.g. body weight) and `y` outcome (e.g. plasma volume)?
- how strong is the relationship between the two variables?
- what will be a predicted value of the `y` outcome given a new set of exposure values?
- how accurately can we predict the outcome?

\newpage


```{r, det-vs-stat, echo=F, fig.height=5, fig.cap="**Determinisitc vs. statistical relationship**: a) deterministic: equation exactly describes the relationship between the two variables e.g. $Fahrenheit=9/5*Celcius+32$; b) statistical relationship between x and y is not perfect (increasing), c)  statistical relationship between x and y is not perfect (decreasing), d) random signal", fig.align="center"}

par(mfrow=c(2,2), mar=c(3,4,3,3))

# Deterministic relationship example
x_celcius <- seq(from=0, to=50, by=5)
y_fahr <- 9/5*x_celcius+32
plot(x_celcius, y_fahr, type="b", pch=19, xlab="Celcius", ylab="Fahrenheit", main="a)", cex.main=0.8)

# Statistical relationship (increasing)
x <- seq(from=0, to=100, by=5)
y_increasing <- 2*x + rnorm(length(x), mean=100, sd=25)
plot(x, y_increasing, pch=19, xlab="x", ylab="y", main="b)", cex.main=0.8)

# Statistical relationship (decreasing)
y_decreasing <- -2*x + rnorm(length(x), mean=100, sd=25)
plot(x, y_decreasing, pch=19, xlab="x", ylab="y", main="c)", cex.main=0.8)

# Statistical relationshp (random)
y_random <- - rnorm(length(x), mean=100, sd=25)
plot(x, y_random, pch=19, xlab="x", ylab="y", main="d)", cex.main=0.8)


```



### Example data

Example data contain the body weight and plasma volume for eight healthy men. 
```{r}

weight <- c(58, 70, 74, 63.5, 62.0, 70.5, 71.0, 66.0) # body weight (kg)
plasma <- c(2.75, 2.86, 3.37, 2.76, 2.62, 3.49, 3.05, 3.12) # plasma volume (liters)
```

Scatter plot of the data shows that high plasma volume tends to be associated with high weight and *vice verca*. Linear regrssion gives the equation of the straight line that best describes how the outcome changes (increase or decreases) with a change of exposure variable (in red)
```{r, fig-reg, echo=F, fig.align="center", fig.height=5, fig.width=5}

plot(weight, plasma, pch=19, las=1, xlab = "body weight [kg]", ylab="plasma volume [l]")
abline(lm(plasma~weight), col="red") # regression line

```

The equation of the regression line is: 

$$y=beta_0 + beta_1x$$



### Estimating the Coefficients
### Assessing the Accuracy of the Coefficient Estimates
### Asesssing the Accuracy of the Model


```{r reg, echo=F}

weight=c(58, 70, 74, 63.5, 62.0, 70.5, 71.0, 66.0) # body weight (kg)
plasma <- c(2.75, 2.86, 3.37, 2.76, 2.62, 3.49, 3.05, 3.12) # plasma volume (liters)

# correlation 
cor(weight, plasma)

# linear regression
x <- weight
y <- plasma
model <- lm(y~x)
summary(model)

# prediction
y.hat <- predict(model)

n=length(x)
RSS <- sum((y.hat-y)^2)
RSE <- sqrt(RSS/(n-2))

s <- sqrt((sum((y-mean(y))^2) - (model$coefficients[2])^2*sum((x-mean(x))^2))/(n-2))
se.1 <-s/sqrt(sum((x-mean(x))^2))
se.1

se.0 <- s*sqrt((1/n + mean(x)^2/(sum((x-mean(x))^2))))
se.0


#             Estimate Std. Error t value Pr(>|t|)  
# (Intercept)  0.08572    1.02400   0.084   0.9360  
# x            0.04362    0.01527   2.857   0.0289 *
```



## Multiple linear regression
### Estimating the Regression Coefficients
### Estimating coefficients
### Relationship between the response and predictors 
### Model fit 
### Predictions 
### Qualitative predictors 
### Interaction terms
### Non-linear transformation of the predictors 
### Potential problems: non-linearity, collinearity 
### Logistic regression
