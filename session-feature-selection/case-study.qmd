---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Demo: a predictive modelling case study

Let's use `tidymodels` framework to run small predictive case study trying to build a predictive model for BMI using our `diabetes` data set. We will use:

- `rsamples` for splitting data into test and non-test, as well as creating cross-validation folds

- `recipes` for feature engineering, e.g. changing from imperial to metric measurements, removing irrelevant and highly correlated features

- `parsnip` to specify Lasso regression model

- `tune` to optimize search space for lambda values

- `yardstick` to assess predictions

- `workflows` to put all the step together


## Data import & EDA
```{r}
#| label: load-data
#| eval: true
#| warning: false
#| message: false
#| code-fold: false
#| collapse: true
#| fig-show: hold
#| fig-cap-location: margin
#| fig-cap: 
#| - "Number of missing data per variable, shows that bp.2d and bp.2s have more than 50% missing entries"
#| - "Heatmap visualizing Pearson correlation coefficient between numerical variables"

# load libraries
library(tidyverse)
library(tidymodels)
library(ggcorrplot)
library(reshape2)
library(vip)

# import raw data
input_diabetes <- read_csv("data/data-diabetes.csv")

# create BMI variable
conv_factor <- 703 # conversion factor to calculate BMI from inches and pounds BMI = weight (lb) / [height (in)]2 x 703
data_diabetes <- input_diabetes %>%
  mutate(BMI = weight / height^2 * 703, BMI = round(BMI, 2)) %>%
  relocate(BMI, .after = id)

# preview data
glimpse(data_diabetes)

# run basic EDA
# note: we have seen descriptive statistics and plots during EDA session 
# note: so here we only look at missing data and correlation

# calculate number of missing data per variable
data_na <- data_diabetes %>% 
  summarise(across(everything(), ~ sum(is.na(.)))) 

# make a table with counts sorted from highest to lowest
data_na_long <- data_na %>%
  pivot_longer(-id, names_to = "variable", values_to = "count") %>%
  arrange(desc(count)) 

# make a column plot to visualize the counts
data_na_long %>%
  ggplot(aes(x = variable, y = count)) + 
  geom_col(fill = "blue4") + 
  xlab("") + 
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))

# calculate correlation between numeric variables
data_cor <- data_diabetes %>% 
  dplyr::select(-id) %>% 
  dplyr::select(where(is.numeric)) %>%
  cor(use = "pairwise.complete.obs")

# visualize correlation via heatmap
ggcorrplot(data_cor, hc.order = TRUE, lab = FALSE)

# bass on the number of missing data, let's delete bp.2s, bp.2d
# and use complete-cases analysis 
data_diabetes_narm <- data_diabetes %>%
  dplyr::select(-bp.2s, -bp.2d) %>%
  na.omit()

```

## Data splitting
```{r}
#| label: data-split
#| eval: true
#| warning: false
#| message: false
#| code-fold: false
#| collapse: true
#| fig-show: hold
#| fig-cap-location: margin
#| fig-cap: "Distribution of BMI values given all data and spits into non-test and test"

# use tidymodels framework to fit Lasso regression model for predicting BMI
# using repeated cross-validation to tune lambda value in L1 penalty term

# select random seed value
myseed <- 123

# split data into non-test (other) and test (80% s)
set.seed(myseed)
data_split <- initial_split(data_diabetes_narm, strata = BMI, prop = 0.8) # holds splitting info
data_other <- data_split %>% training() # creates non-test set (function is called training but it refers to non-test part)
data_test <- data_split %>% testing() # creates test set

# prepare repeated cross-validation splits with 5 folds repeated 3 times
set.seed(myseed)
data_folds <- vfold_cv(data_other,
                       v = 5, 
                       repeats = 3,
                       strata = BMI)

# check the split
dim(data_diabetes)
dim(data_other)
dim(data_test)

# check BMI distributions in data splits
par(mfrow=c(3,1))
hist(data_diabetes$BMI, xlab = "", main = "BMI: all", 50)
hist(data_other$BMI, xlab = "", main = "BMI: non-test", 50)
hist(data_test$BMI, xlab = "", main = "BMI: test", 50)


```

## Feature engineering
```{r}
#| label: data-recipe
#| eval: true
#| warning: false
#| message: false
#| code-fold: false
#| collapse: true
#| fig-show: hold

# create data recipe (feature engineering)

inch2m <- 2.54/100
pound2kg <- 0.45

data_recipe <- recipe(BMI ~ ., data = data_other) %>%
  update_role(id, new_role = "sampleID") %>%
  step_mutate(height = height * inch2m, height = round(height, 2)) %>% # convert height to meters
  step_mutate(weight = weight * pound2kg, weight = round(weight, 2)) %>% # convert weight to kg
  step_rename(glu = stab.glu) %>% # rename stab.glu to glu
  step_log(glu) %>%  #ln transform glucose
  step_zv(all_numeric()) %>% # removes variables that are highly sparse and unbalanced (if found)
  step_corr(all_numeric(), -all_outcomes(), -has_role("sampleID"), threshold = 0.8) %>% # removes variables with large absolute correlations with other variables (if found)
  step_dummy(location, gender, frame) %>% # convert categorical variables to dummy variables
  step_normalize(all_numeric(), -all_outcomes(), -has_role("sampleID"), skip = FALSE) 
  
  # you can implement more steps: see https://recipes.tidymodels.org/reference/index.html

# print recipe
data_recipe

# check if recipe is doing what it is supposed to do
# i.e. bake the data
data_other_prep <- data_recipe %>%
  prep() %>%
  bake(new_data = NULL)

## bake test data
data_test_prep <- data_recipe %>%
  prep() %>%
  bake(new_data = data_test)

# preview baked data
print(head(data_other_prep))

```

## Lasso regression
```{r}
#| eval: true
#| warning: false
#| message: false
#| code-fold: false
#| collapse: true
#| fig-show: hold
#| fig-width: 6
#| fig-height: 6
#| fig-cap-location: margin
#| fig-cap: 
#| - "Mean RMSE plus/minus standard error across repeated cross-validation folds as a function of lambda values"
#| - "Predicted BMI values against actual BMI values using final model for predicting test (unseen) data"
#| - "Top feature of importance, here measured as the features with highest absolute value of the Lasso regression coefficients from the final tuned model"

# define model
model <- linear_reg(penalty = tune(), mixture = 1) %>%
  set_engine("glmnet") %>%
  set_mode("regression")

# create workflow with data recipe and model 
wf <- workflow() %>%
  add_model(model) %>%
  add_recipe(data_recipe)

# define parameters range for tuning
grid_lambda <- grid_regular(penalty(), levels = 25)

# tune lambda
model_tune <- wf %>%
  tune_grid(resamples = data_folds, 
            grid = grid_lambda)

# show metrics average across folds
model_tune  %>%
  collect_metrics(summarize = TRUE)

# plot k-folds results across lambda range
model_tune %>%
  collect_metrics() %>% 
  dplyr::filter(.metric == "rmse") %>% 
  ggplot(aes(penalty, mean, color = .metric)) +
  geom_errorbar(aes( ymin = mean - std_err, ymax = mean + std_err), alpha = 0.5) +
  scale_x_log10() + 
  geom_line(linewidth = 1.5) +
  theme_bw() +
  theme(legend.position = "none") +
  scale_color_brewer(palette = "Set1")
  
# best lambda value (min. RMSE)
model_best <- model_tune %>%
  select_best("rmse")
print(model_best)

# finalize workflow with tuned model
wf_final <- wf %>%
  finalize_workflow(model_best)

# last fit 
fit_final <- wf_final %>%
  last_fit(split = data_split)

# final predictions
y_test_pred <- fit_final %>% collect_predictions() # predicted BMI

# final predictions: performance on test (unseen data)
fit_final %>% collect_metrics() 

# plot predictions vs. actual for test data
plot(data_test$BMI, y_test_pred$.pred, xlab="BMI (actual)", ylab = "BMI (predicted)", las = 1, pch = 19)

# correlation between predicted and actual BMI values for test data
cor(data_test$BMI, y_test_pred$.pred)

# re-fit model on all non-test data
model_final <- wf_final %>%
  fit(data_other) 

# show final model
tidy(model_final)

# plot variables ordered by importance (highest abs(coeff))
model_final %>%
  extract_fit_parsnip() %>%
  vip(geom = "point") + 
  theme_bw()

```

