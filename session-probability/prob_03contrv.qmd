---
editor: source
title: "Continuous random variable"
output: html_document
---

```{r}
#| label: setup
#| include: FALSE
library(ggplot2)
library(reshape2)
library(knitr)
library(kableExtra)
library(tidyverse)

knitr::opts_chunk$set(fig.width=3.5, fig.height=3.5, echo = FALSE, error=FALSE, warnings=FALSE, dpi=600, fig.path = "Rfigures/prob03_", cache=TRUE)
options(digits=2)
```

A continuous random number is not limited to discrete values, but any continuous number within one or several ranges is possible.

Examples: weight, height, speed, intensity, ...

A continuous random variable can be described by its **probability density function**, pdf.

```{r fig-pdfnewborn, fig.show="hold", fig.cap="Probability density function of the weight of a newborn baby.", fig.height=4, fig.width=7}
## ounce <- 0.0283495231
## pound <- 0.45359237
## ggplot(babies, aes(x=wt*ounce)) + theme_bw() + xlab("x") + ylab("f(x)") + geom_density() #+ ggtitle("Weight (kg) of a newborn baby"))
##plot(ggplot(fat, aes(x=weight*pound)) + theme_bw() + xlab("x") + ylab("f(x)") + geom_density() + ggtitle("Weight (kg) of a man"))
##Simulate weights
baby <- data.frame(smoke=sample(1000, x=0:2, prob=c(0.45,0.45,0.1), replace=TRUE)) %>% mutate(m=c(3.4, 3.0, 2.5)[smoke+1], wt=rnorm(n(), mean=m, sd=0.5))
ggplot(baby, aes(x=wt)) + theme_bw() + xlab("x") + ylab("f(x)") + geom_density() 
```

```{r fig-normpdf2, out.width="70%", fig.align="center", eval=FALSE}
x <- seq(-4,4,.01)
ggplot(data.frame(x=x, fx=dnorm(x)), aes(x,fx)) + geom_line() + theme_bw() + ylab("f(x)")
```

The probability density function, $f(x)$, is defined such that the total area under the curve is 1.

$$
\int_{-\infty}^{\infty} f(x) dx = 1
$$

```{r fig-wtbabiesdens3, fig.cap= "The probability $P(a \\leq X \\leq b)$ can be computed by computing the area under the probability density function between $a$ and $b$."}
#ggplot(baby, aes(x=wt)) + theme_bw() + xlab("x") + ylab("f(x)") + geom_density() 
#plot(ggplot(data.frame(w=wt), aes(x=w)) + theme_bw() + xlab("x") + ylab("f(x)") + geom_density())

df.wt <- density(baby$wt)
df.wt <- data.frame(x=df.wt$x, y=df.wt$y)
plot(ggplot(baby, aes(x=wt)) + theme_bw() + xlab("x") + ylab("f(x)") + geom_density() + geom_area(data=df.wt %>% filter(x<3.75, x>2.33), aes(x=x, y=y)) + scale_x_continuous(breaks=c(2,2.33,3,3.75,4,5), labels=c('2','a','3','b','4','5')) + geom_hline(yintercept=0) + theme(panel.grid.minor = element_blank(), panel.grid.major.x = element_line(color = c("grey92", NA, "grey92", NA, "grey92", "grey92"))))
#plot(ggplot(data.frame(w=wt), aes(x=w)) + theme_bw() + xlab("x") + ylab("f(x)") + geom_density() + geom_area(data=df.wt %>% filter(x<3.75, x>2.33), aes(x=x, y=y)) + scale_x_continuous(breaks=c(2,2.33,3,3.75,4,5), labels=c('2','a','3','b','4','5')) + geom_hline(yintercept=0) + theme(panel.grid=element_blank()))
```

```{r pdfwtnorm, out.width="100%", eval=TRUE}
w<-seq(1.5,5.5,.01)
df.nwt <- data.frame(w=w, f=dnorm(w, 3.5, 0.5))
#ggplot(df.nwt, aes(x=w, y=f)) + geom_line() + theme_bw() + xlab("Weight (kg)") + ylab("f(x)")
```

```{r pdfab, eval=FALSE}
ggplot(df.nwt, aes(x=w, y=f)) + geom_line() + theme_bw() + xlab("Weight (kg)") + ylab("f(x)") + geom_area(data=df.nwt %>% filter(w<3.75, w>2.33)) + scale_x_continuous(breaks=c(2,2.33,3,3.75,4,5), labels=c('2','a','3','b','4','5')) + geom_hline(yintercept=0) + theme(panel.grid.minor = element_blank(), panel.grid.major.x = element_line(color = c("grey92", NA, "grey92", NA, "grey92", "grey92")))
```

The area under the curve from $a$ to $b$ is the probability that the random variable $X$ takes a value between a and b.

$$P(a \leq X \leq b) = \int_a^b f(x) dx$$


The **cumulative distribution function**, cdf, sometimes called just the distribution function, $F(x)$, is defined as:

$$F(x) = P(X \leq x) = \int_{-\infty}^x f(t) dt$$

```{r}
#| label: fig-wtpdfcdf
#| fig-cap: "Probability density function (pdf) and cumulative distribution function (cdf)."
#| fig-subcap: 
#|   - "PDF"
#|   - "CDF"
#| layout-ncol: 2
plot(ggplot(df.nwt, aes(x=w, y=f)) + geom_line() + theme_bw() + xlab("x") + ylab("f(x)") + geom_area(data=df.nwt %>% filter(w<4.0)) + annotate("label",label=sprintf("P(X<4.0) = F(4.0) = %.2f", pnorm(4,3.5,0.5)), x=2.7, y=0.4, hjust=0))
df.nwt$F <- pnorm(df.nwt$w, 3.5, 0.5)
plot(ggplot(df.nwt, aes(x=w, y=F)) + geom_line() + xlab("x") + ylab("F(x)") + theme_bw() + geom_point(aes(x=4, y=pnorm(4,3.5,.5))) + annotate("label",label=sprintf("F(4.0)=%.2f", pnorm(4,3.5,.5)), x=4, y=.84, hjust=-0.2))##+ ggtitle("Cumulative distribution function") 
```

$$P(X \leq x) = F(x)$$

As we know that the total probability (over all x) is 1, we can conclude that

$$P(X > x) = 1 - F(x)$$ and thus

$$P(a < X \leq b) = F(b) - F(a)$$

## Parametric continuous distributions

Two important parameters of a distribution is the expected value, $\mu$, that describe the distributions location and the variance, $\sigma^2$, that describe the spread.

The expected value, or population mean, is defined as;

$$E[X] = \mu = \int_{-\infty}^\infty x f(x) dx$$ We will learn more about the expected value and how to estimate a population mean from a sample later in the course.

The population variance is defined as the expected value of the squared distance from the population mean;

$$\sigma^2 = E[(X-\mu)^2] = \int_{-\infty}^\infty (x-\mu)^2 f(x) dx$$

The square root of the variance is the standard deviation, $\sigma$.

## Normal distribution

The normal distribution (sometimes referred to as the Gaussian distribution) is a common bell-shaped probability distribution. Many continuous random variables can be described by the normal distribution or be approximated by the normal distribution.

The normal probability density function

$$f(x) = \frac{1}{\sqrt{2 \pi} \sigma} e^{-\frac{1}{2} \left(\frac{x-\mu}{\sigma}\right)^2}$$

describes the distribution of a normal random variable, $X$, with expected value $\mu$ and standard deviation $\sigma$, $e$ and $\pi$ are two common mathematical constants, $e \approx 2.71828$ and $\pi \approx 3.14159$.

<!-- In short we write $X \sim N(\mu, \sigma)$. -->

```{r fig-norm, out.width="75%", fig.show="hold", fig.align="center", eval=FALSE}
#| fig-cap: "The normal probability distribution function."
#ggplot(pop.FN, aes(x=Bodyweight)) + geom_histogram(binwidth=1, aes(y=stat(density)), color="white") + theme_bw() + geom_line(data=den.FN, aes(x=x, y=nfx), color="red")
x <- seq(-3.5, 3.5, .1)
dN <- data.frame(x=x, fx=dnorm(x))
plot(ggplot(dN, aes(x=x, y=fx)) + geom_line() + scale_x_continuous(breaks=-3:3, labels=c(expression(mu-3*sigma),expression(mu-2*sigma), expression(mu-1*sigma), expression(mu), expression(mu+sigma), expression(mu + 2*sigma),  expression(mu + 3*sigma))) + xlab("") + ylab("f(x)") + theme_bw())
```

The bell-shaped normal distributions is symmetric around $\mu$ and $f(x) \rightarrow 0$ as $x \rightarrow \infty$ and as $x \rightarrow -\infty$.

As $f(x)$ is well defined, values for the cumulative distribution function $F(x) = \int_{- \infty}^x f(x) dx$ can be computed.

```{r fig-pdfcdfnorm}
#| fig-cap: "Normal probability density function and cumulative distribution functions."
#| layout-ncol: 2
x <- seq(-3.5, 3.5, .1)
dN <- data.frame(x=x, fx=dnorm(x))
dN <- dN |> mutate(Fx = pnorm(x))
ggplot(dN, aes(x=x, y=fx)) + geom_line() + scale_x_continuous(breaks=-3:3, labels=c(expression(mu-3*sigma),expression(mu-2*sigma), expression(mu-1*sigma), expression(mu), expression(mu+sigma), expression(mu + 2*sigma),  expression(mu + 3*sigma))) + xlab("") + ylab("f(x)") + theme_bw() + ggtitle("Probability density function")
ggplot(dN, aes(x=x, y=Fx)) + geom_line() + scale_x_continuous(breaks=-3:3, labels=c(expression(mu-3*sigma),expression(mu-2*sigma), expression(mu-1*sigma), expression(mu), expression(mu+sigma), expression(mu + 2*sigma),  expression(mu + 3*sigma))) + xlab("") + ylab("F(x)") + theme_bw() + ggtitle("Cumulative distribution function")
```

If $X$ is normally distributed with expected value $\mu$ and standard deviation $\sigma$ we write:

$$X \sim N(\mu, \sigma)$$

Using transformation rules we can define $Z$, a random variable that is standard normal distributed (mean 0 and standard deviation 1).

$$Z = \frac{X-\mu}{\sigma}, \, Z \sim N(0,1)$$

Values for the cumulative standard normal distribution, $F(z)$, are tabulated and easy to compute in R using the function `pnorm`.

```{r fig-FZ, out.width="50%", fig.cap="The shaded area under the curve is the tabulated value $P(Z \\leq z) = F(z)$."}
w<-seq(-3.5,3.5,.01)
df.nwt <- data.frame(w=w, f=dnorm(w))
plot(ggplot(df.nwt, aes(x=w, y=f)) + geom_line() + theme_bw() + xlab("x") + ylab("f(x)") + geom_area(data=df.nwt %>% filter(w<0.7)) + annotate("label",label=sprintf("P(Z<z) = F(z)"), x=-1.0, y=0.1, hjust=0) + scale_x_continuous(breaks=c(-2,0,+.7,2), labels=c("-2","0","z","2")) + theme(panel.grid.minor = element_blank(), panel.grid.major.x = element_line(color = c("grey92", "grey92", NA, "grey92"))))
```

```{r}
#| label: tbl-FZtab
#| tbl-cap: "Cumulative distribution function for the standard normal distribution. The table gives F(z) = P(Z < z) for standard normal Z."
z <- sapply(seq(-3.4, -3.49, -0.01), function(x) seq(x,0,0.1))
z <- -z[nrow(z):1,]
z <- sapply(seq(0, 0.09, 0.01), function(x) seq(x,3.49,0.1))
zscore.df <- apply(pnorm(z), 2, function(x) sprintf("%.4f",x))
row.names(zscore.df) <- sprintf("%.1f", z[,1])
colnames(zscore.df) <- seq(0,0.09,0.01)
kable(zscore.df) %>% column_spec(1, bold=TRUE) |> kable_styling()
```

Some values of particular interest:

$$F(1.64) = 0.95$$
$$F(1.96) = 0.975$$

As the normal distribution is symmetric F(-z) = 1 - F(z)

$$F(-1.64) = 0.05$$
$$F(-1.96) = 0.025$$
$$P(-1.96 < Z < 1.96) = 0.95$$

<!-- Show table? -->

<!-- dnorm -->

<!-- pnorm -->

### Sum of two normal random variables

If $X \sim N(\mu_1, \sigma_1)$ and $Y \sim N(\mu_2, \sigma_2)$ are two independent normal random variables, then their sum is also a random variable:

$$X + Y \sim N(\mu_1 + \mu_2, \sqrt{\sigma_1^2 + \sigma_2^2})$$

and

$$X - Y \sim N(\mu_1 - \mu_2, \sqrt{\sigma_1^2 + \sigma_2^2})$$ This can be extended to the case with $n$ independent and identically distributed random variables $X_i$ ($i=1 \dots n$). If all $X_i$ are normally distributed with mean $\mu$ and standard deviation $\sigma$, $X_i \in N(\mu, \sigma)$, then the sum of all $n$ random variables will also be normally distributed with mean $n\mu$ and standard deviation $\sqrt{n} \sigma$.

## Central limit theorem


::: {#thm-CLT}
## CLT
The sum of $n$ independent and equally distributed random variables
is normally distributed, if $n$ is large enough.
:::

As a result of the central limit theorem, the distribution of fractions or mean values of a sample follow the normal distribution, at least if the sample is large enough (a rule of thumb is that the sample size $n>30$).

<!-- ```{example, "Mean BMI", eval=FALSE} -->

<!-- Percentage of body fat, age, weight, height, BMI and ten body circumference -->

<!-- measurements are recorded for 252 men. Consider these 252 as a population and compute the population mean ans standard deviation. -->

<!-- ``` -->

::: {#exm-skewed}
# A skewed distribution

A left skewed distribution has a heavier left tail than right tail. An example might be age at death of natural causes.

```{r}
#| label: fig-leftskewed
#| fig-cap: "A left skewed distribution. Can for example show the distribution of age of a mouse who died of natural causes."
#| fig.width: 5
miceage <- 2*(2-rgamma(10000, 3, 9))
data.frame(age=miceage) |> ggplot(aes(x=age)) + geom_density() + theme_bw()
```

Randomly sample 3, 5, 10, 15, 20, 30 values and compute the mean value, $m$. Repeat many times to get the distribution of mean values.

```{r}
#| label: fig-meanskew
#| fig-cap: "Distribution of sample means, where the means are computed based on random samples of sizes 3, 5, 10, 15, 20 and 30, respectively."
#| fig.width: 5
#| fig.height: 5
rs <- data.frame(n = c(3,5,10,15,20,30)) |> group_by(n) |> summarize(m=replicate(10000, mean(sample(miceage, n))), .groups="drop")
rs |> ggplot(aes(x=m, fill=factor(n))) + geom_histogram(bins=50) + theme_bw() + facet_wrap(~factor(n))+ theme(legend.position="none")
```

Note, mean is just the sum divided by the number of samples $n$.

:::

<!-- ::: {#exm-BMIdistr} -->
<!-- # Mean BMI -->

<!-- In a population of 252 men we can study the distribution of BMI. -->

<!-- ```{r fatdata} -->
<!-- fat <- read.table("http://jse.amstat.org/datasets/fat.dat.txt") -->
<!-- colnames(fat) <- c("case","body.fat","body.fat.siri","density","age","weight","height","BMI","ffweight","neck","chest","abdomen","hip","thigh","knee","ankle" ,"bicep","forearm","wrist" ) -->
<!-- ``` -->

<!-- ```{r BMIhist, out.width="60%"} -->
<!-- pl <- ggplot(fat, aes(x=BMI)) + geom_histogram(aes(y=stat(density)), binwidth=2, color="white") + theme_bw() -->
<!-- plot(pl) -->
<!-- ``` -->

<!-- ```{r BMI, echo=TRUE} -->
<!-- ##Population mean -->
<!-- (mu <- mean(fat$BMI)) -->
<!-- ##Population variance -->
<!-- (sigma2 <- var(fat$BMI)/nrow(fat)*(nrow(fat)-1)) -->
<!-- ##Population standard variance -->
<!-- (sigma <- sqrt(sigma2)) -->
<!-- ``` -->

<!-- Randomly sample 3, 5, 10, 15, 20, 30 men and compute the mean value, $m$. Repeat many times to get the distribution of mean values. -->

<!-- ```{r owexample, out.width="70%", fig.width=7, fig.show="hold"} -->
<!-- #hist(fat$BMI) -->
<!-- bmi <- fat$BMI -->
<!-- n <- c(3,5,10,15,20, 30) -->
<!-- rs <- sapply(n, function(k) replicate(10000, mean(sample(bmi, k)))) -->
<!-- colnames(rs) <- paste(sprintf("n=%i, m=%.4f", n, colMeans(rs))) -->
<!-- plot(ggplot(melt(rs, varnames=c("rep", "n")), aes(x=value, color=factor(n))) + geom_density() + theme_bw() + facet_wrap(~n) + theme(legend.position="none")) -->
<!-- ``` -->

<!-- Note, mean is just the sum divided by the number of samples $n$. -->

<!-- ::: -->

## $\chi^2$-distribution

The random variable $Y = \sum_{i=1}^n X_i^2$ is $\chi^2$ distributed with $n-1$ degrees of freedom, if $X_i$ are independent identically distributed random variables $X_i \in N(0,1)$.

In short $Y \in \chi^2(n-1)$.

```{r fig-Xdistr, fig.width=7, fig.height=7, fig.cap="The $\\chi^2$-distribution."}
x <- seq(-0,5, .01)
dX <- data.frame(x=x, n=rep(c(2, 3,4,5,7, 10), each=length(x))) %>%
  mutate(fx=dchisq(x, df=n-1))
#dT <- data.frame(x=x, fx=dt(x, df=n-1))
ggplot(dX, aes(x=x, y=fx, color=factor(paste0("n=",n), levels=paste0("n=",sort(unique(n)))))) + geom_line() + theme_bw() + scale_color_discrete("") + ylim(c(0,0.5))
```

::: {#exm-chisq}
The sample variance $S^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i-\bar X)^2$ is such that $\frac{(n-1)S^2}{\sigma^2}$ is $\chi^2$ distributed with $n-1$ degrees of freedom.
:::

<!-- Example. $\chi^2$-test for variance -->

## F-distribution

The ratio of two $\chi^2$-distributed variables divided by their degrees of freedom is F-distributed

```{r fig-Fdistr, fig.width=7, fig.height=7, fig.cap="The F-distribution"}
x <- seq(-0,5, .01)
dX <- data.frame(x=x, n1=rep(c(2,4,10), each=length(x)), n2=rep(c(2,4,10), each=length(x)*3)) %>%
  mutate(fx=df(x, df1=n1-1, df2=n2-1))
#dT <- data.frame(x=x, fx=dt(x, df=n-1))
ggplot(dX, aes(x=x, y=fx, color=factor(sprintf("n1=%i, n2=%i",n1, n2), levels=sprintf("n1=%i, n2=%i",rep(sort(unique(n1)), each=3), sort(unique(n2)))))) + geom_line() + theme_bw() + scale_color_discrete("") + ylim(c(0,0.8))
```

::: {#exm-Fdistr}
The ratio of two sample variances is F-distributed
:::

<!-- Example. F-test of equality of variances -->

## t-distribution

The ratio of a normally distributed variable and a $\chi^2$-distributed variable is t-distributed.

```{r fig-exampletdistr, fig.width=7, fig.height=7, fig.cap="The t-distribution."}
x <- seq(-3.5,3.5, .01)
dT <- data.frame(x=x, n=rep(c(2, 3,5,7, 10, 15, 20, 30), each=length(x))) %>%
  mutate(fx=dt(x, df=n-1))
#dT <- data.frame(x=x, fx=dt(x, df=n-1))
ggplot(dT, aes(x=x, y=fx, color=factor(paste0("n=",n), levels=paste0("n=",sort(unique(n)))))) + geom_line() + theme_bw() + scale_color_discrete("")
```

:::{#exm-tdistr}
  The ratio between sample mean and sample variance is t-distributed.
:::

## Distributions in R

Probability density functions for the normal, t, $\chi^2$ and F distributions can in R can be computed using functions `dnorm`, `dt`, `dchisq`, and `df`, respectively.

Cumulative distribution functions can be computed using `pnorm`, `pt`, `pchisq` and `pf`.

Also, functions for computing an $x$ such that $P(X<x) = q$, where $q$ is a probability of interest are available using `qnorm`, `qt`, `qchisq` and `qf`.
