{"headings":["we-will-learn","why-linear-models","statistical-vs.-deterministic-relationship","statistical-vs.-deterministic-relationship-1","statistical-vs.-deterministic-relationship-2","statistical-vs.-deterministic-relationship-3","what-linear-models-are-and-are-not","what-linear-models-are-and-are-not-1","what-linear-models-are-and-are-not-2","what-linear-models-are-and-are-not-3","terminology","simple-linear-regression","simple-linear-regression-1","weight-and-plasma-volume","simple-linear-regression-2","simple-linear-regression-3","simple-linear-regression-4","simple-linear-regression-5","least-squares","least-squares-1","least-squares-2","least-squares-estimates-for-a-simple-linear-regression","least-squares-3","least-squares-4","least-squares-5","slope","intercept","hypothesis-testing","hypothesis-testing-1","hypothesis-testing-2","hypothesis-testing-3","vector-matrix-notations","vector-matrix-notations-1","vector-matrix-form-of-the-linear-model","vector-matrix-notations-2","least-squares-in-vector-matrix-notation","vector-matrix-notations-3","vector-matrix-notation","vector-matrix-notations-4","assessing-model-fit","r2-summary-of-the-fitted-model","r2-summary-of-the-fitted-model-1","r2-summary-of-the-fitted-model-2","r2-summary-of-the-fitted-model-3","r2","r2-and-correlation-coefficient","r2-1","r2adj","r2adj-1","exercises","checking-model-assumptions","the-assumptions-of-a-linear-model","the-assumptions-of-a-linear-model-1","checking-assumptions","checking-assumptions-1","beyond-linear-models","why-generalized-linear-models","logistic-regression","logistic-regression-1","logistic-regression-2","logistic-regression-3","logistic-regression-4","logistic-regression-5","logistic-regression-6","common-glm-models","common-cases"],"entries":[{"key":"eq-lm","caption":"","order":{"section":[1,16,0,0,0,0,0],"number":2}},{"key":"thm-lss","caption":"Least squares estimates for a simple linear regression","order":{"section":[1,19,0,0,0,0,0],"number":1}},{"key":"fig-obesity","caption":"?(caption)","order":{"section":[5,2,0,0,0,0,0],"number":4}},{"key":"thm-r2adj","caption":"R^2(adj)","order":{"section":[2,6,0,0,0,0,0],"number":4}},{"key":"exm-vector-matrix-notation","caption":"vector-matrix-notation","order":{"section":[1,30,0,0,0,0,0],"number":4}},{"key":"def-vector-matrix-lm","caption":"vector matrix form of the linear model","order":{"section":[1,28,0,0,0,0,0],"number":1}},{"key":"thm-r2","caption":"R^2","order":{"section":[2,5,0,0,0,0,0],"number":3}},{"key":"exm-hypothesis-testing","caption":"Hypothesis testing","order":{"section":[1,26,0,0,0,0,0],"number":3}},{"key":"eq-lm-no-error","caption":"","order":{"section":[1,14,0,0,0,0,0],"number":1}},{"key":"fig-lm-example-reg","caption":"Scatter plot of the data shows that high plasma volume tends to be associated with high weight and vice verca. Linear regression gives the equation of the straight line (red) that best describes how the outcome changes (increase or decreases) with a change of exposure variable","order":{"section":[1,14,0,0,0,0,0],"number":2}},{"key":"fig-reg-errors","caption":"Scatter plot of the data shows that high plasma volume tends to be associated with high weight and vice versa. Linear regression gives the equation of the straight line (red) that best describes how the outcome changes with a change of exposure variable. Blue lines represent error terms, the vertical distances to the regression line","order":{"section":[1,18,0,0,0,0,0],"number":3}},{"key":"fig-lm-intro-example","caption":"Scatter plot of the data shows that high plasma volume tends to be associated with high weight and vice verca.","order":{"section":[1,12,0,0,0,0,0],"number":1}},{"key":"exm-lss","caption":"Least squares","order":{"section":[1,20,0,0,0,0,0],"number":2}},{"key":"thm-lss-vector-matrix","caption":"Least squares in vector-matrix notation","order":{"section":[1,29,0,0,0,0,0],"number":2}},{"key":"def-r2","caption":"R^2","order":{"section":[2,4,0,0,0,0,0],"number":2}},{"key":"exm-simple-lm","caption":"Weight and plasma volume","order":{"section":[1,12,0,0,0,0,0],"number":1}}]}