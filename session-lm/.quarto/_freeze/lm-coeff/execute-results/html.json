{
  "hash": "d37aedc9c7f6dc6496a3e05931b657d2",
  "result": {
    "markdown": "---\noutput: html_document\neditor_options: \n  chunk_output_type: console\n---\n\n# Common cases\n\nLet's go over some common cases of linear models to clarify their interpretation and usage. We will need to run this code to begin with:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nlibrary(tidyverse)\nlibrary(magrittr)\nlibrary(faraway)\nlibrary(ggiraphExtra)\n\nfont.size <- 12\nmy.ggtheme <- \n  theme_bw() + \n  theme(axis.title = element_text(size = font.size), \n        axis.text = element_text(size = font.size), \n        legend.text = element_text(size = font.size), \n        legend.title = element_blank(), \n        legend.position = \"top\")\n      \n\n# add obesity and diabetes status to diabetes faraway data\ninch2m <- 2.54/100\ninch2cm <- 2.54\npound2kg <- 0.45\ndata_diabetes <- diabetes %>%\n  mutate(height  = height * inch2m, height = round(height, 2)) %>% \n  mutate(waist = waist * inch2cm) %>%  \n  mutate(weight = weight * pound2kg, weight = round(weight, 2)) %>%\n  mutate(BMI = weight / height^2, BMI = round(BMI, 2)) %>% \n  mutate(obese= cut(BMI, breaks = c(0, 29.9, 100), labels = c(\"No\", \"Yes\"))) %>% \n  mutate(diabetic = ifelse(glyhb > 7, \"Yes\", \"No\"), diabetic = factor(diabetic, levels = c(\"No\", \"Yes\"))) %>%\n  na.omit()\n```\n:::\n\n\n## Example: simple linear regression\n\n::: {.cell .column-margin .fig-cap-location-margin fig.heigth='4'}\n\n```{.r .cell-code  code-fold=\"false\"}\nm1 <- lm(BMI ~ waist, data = data_diabetes)\nsummary(m1)\n## \n## Call:\n## lm(formula = BMI ~ waist, data = data_diabetes)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -13.2374  -2.7689  -0.4532   2.4065  19.3549 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept) -5.12445    2.73538  -1.873   0.0633 .  \n## waist        0.35298    0.02723  12.965   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 4.426 on 128 degrees of freedom\n## Multiple R-squared:  0.5677,\tAdjusted R-squared:  0.5643 \n## F-statistic: 168.1 on 1 and 128 DF,  p-value: < 2.2e-16\n\nggPredict(m1) + \n  my.ggtheme + \n  xlab(\"waist [cm]\")\n```\n\n::: {.cell-output-display}\n![Scatter plot showing BMI values given waist measurments with a fitted simple linear regression model.](lm-coeff_files/figure-html/fig-simple-1-1.png){#fig-simple-1 width=384}\n:::\n:::\n\n\n**Model (generic)** \n\n- $Y_i = \\alpha + \\beta \\cdot x_i + \\epsilon_i$ \n\n**Model (fitted)** \n\n- $BMI_i = -5.12 + 0.35 \\cdot waist_i + \\epsilon_i$ \n\n**Slope**\n\n- The value of slope tells us how and by much the outcome changes with a unit change in $x$\n- If the `waist` increases by 1 unit, here in cm, what would be our expected change in `BMI`^[If the waist increases by 1 cm we would expect our `BMI` to increase by $\\approx 0.35$ since $\\hat{\\beta} = 0.35298$]$? \n- And if the `waist` increases by 10 units what would be our expected change in `BMI`^[If the waist increases by 10 cm we would expect `BMI` to increase by $0.35298 \\cdot 10 \\approx  3.53$]$?\n\n**Intercept**\n\n- The **intercept**, often labeled the **constant**, is the value of Y when $x_i=0$.\n- In models where $x_i$ can be equal 0, the intercept is simply the expected mean value of response.\n- In models where $x_i$ cannot be equal 0, like in our `BMI` example where it is not possible to have `BMI` equal to zero, the intercept has no intrinsic meaning.\n- The intercept is thus quite often ignored in linear models, as it is the value of slope that dictates the association between exposure and outcome.\n\n**Hypothesis testing**\n\n- We've seen during the lecture that the check for association between exposure and outcome we check if the we have enough evidence to reject $H_0: \\beta=0$ in favor of the alternative $H_a: \\beta\\neq0$.\n- Here, for the $\\beta$ coefficient we have $t-statistics = 0.35298 / 0.02723 = 12.965$ and a corresponding $p-value = 12.96291$, as $t-statistics \\sim t(130-2) << 0.05$. Such large `t-statsitics` or small p-value means we have enough evidence to reject the null hypothesis and conclude that there is a significant association between waist and BMI. \n- We can double-check R output by calculating p-value ourselves using the Student t distribution:\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\n2*pt(12.96291, df=128, lower=F)\n## [1] 4.605102e-25\n```\n:::\n\n\n- Is there enough evidence to reject the null hypothesis of $H_0: \\alpha=0$ in favor of the alternative $H_a: \\alpha\\neq0$ assuming 5% significance level?^[No, as $p-value = 0.0633 \\nless 0.05$].\n- Is there enough evidence to reject the null hypothesis of $H_0: \\alpha=0$ in favor of the alternative $H_a: \\alpha\\neq0$ assuming 10% significance level?^[Yes, as $p-value = 0.0633 < 0.1$].\n\n**Predictions**\n\n- Using the model we can predict the `BMI` value for a new observation of `waist`.\n- For instance, we can find expected `BMI` value for someone who measures 100 cm in `waist` by: \n- $BMI = -5.12445 + 0.35298 \\cdot 100 = 30.17355$\n- In R can use `predict()` function:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\n# predict BMI for a new value of 100\nnew_data <- data.frame(waist = 100)\npredict(m1, newdata = new_data)\n##        1 \n## 30.17348\n```\n:::\n\n\n- What would be `BMI` for someone with `waist` measurements of 75?^[BMI = -5.12445 + 0.35298 \\cdot 75 = 21.349]\n- What would be `BMI` for someone with `waist` measurements of 200?^[BMI = -5.12445 + 0.35298 \\cdot 200 = 65.47141, however here we have to be careful in predicting outside the model range.]\n\n**Model fit**\n\n- In simple regression we can use $R^2$ to assess model fit, here $R^2 = 0.5677$.\n- Do you think that the model fits the data well?^[In simple linear regression $R^2$ is the same as $r^2$ and a value of 0.5677 indicates moderate fit, that agrees with the plot above. Since we have more variables in the data set we could try to improve the fit by including more variables.]\n\n**Model assumptions**\n\nWe should also not forget to look at the residual plots to check model assumptions:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\npar(mfrow = c(2,2))\nplot(m1)\n```\n\n::: {.cell-output-display}\n![](lm-coeff_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n- Given the diagnostic plots can we comment about the assumptions of linear models being met?^[The diagnostics do not indicate a serious violation of model assumptions, with no obvious trends of any kind in the residuals plots. Few samples deviate from diagonal line on the Normal Q-Q plot and these could be removed to ensure that the residuals follow normal distribution.]\n\n## Example: multiple regression\n\nLet's try to model BMI using more variables\n\n**Model (generic)**\n\n- $Y_i = \\beta_0 + \\beta_1 \\cdot  age_i + \\beta_2 \\cdot chol_i + \\beta_3 \\cdot hdl_i  + \\epsilon_i$\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\n# fit multiple linear regression and print model summary\nm2 <- lm(BMI ~ age + chol + hdl,  data = data_diabetes)\nsummary(m2)\n## \n## Call:\n## lm(formula = BMI ~ age + chol + hdl, data = data_diabetes)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -13.074  -4.833  -1.132   3.438  22.032 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(>|t|)    \n## (Intercept) 35.456968   3.149661  11.257  < 2e-16 ***\n## age         -0.027047   0.040304  -0.671  0.50340    \n## chol         0.002039   0.012701   0.161  0.87269    \n## hdl         -0.090023   0.032734  -2.750  0.00683 ** \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 6.552 on 126 degrees of freedom\n## Multiple R-squared:  0.06763,\tAdjusted R-squared:  0.04543 \n## F-statistic: 3.046 on 3 and 126 DF,  p-value: 0.03124\n```\n:::\n\n\n**Coefficient interpretations**\n\nUsing the model answer the questions:\n\n- what would happen to `BMI` if `hdl` levels increase by 10?^[decreases by $-0.090023 \\cdot 10 = 0.90023$]\n- what would happen to `BMI` if `age` increases by 1 year?^[decrease by 0.027047, however here we can see that the age coefficient is not significant and therefore we should be careful with our interpretations as there is no evidence that this coefficient is different than 0.]\n\n**Hypothesis testing**\n\n- overall, is there a relationship between the response $Y$ (BMI) and predictors?^[we have seen before that in the case of simple linear regression it was enough to test the null hypothesis of $H_0: \\beta=0$ versus $H_0: \\beta\\neq0$ to answers the question whether there is an overall relationship between response and predictor. In case of multiple regression, with many predictors, we need to test the null hypothesis of $$H_0: \\beta_1 = \\beta_2 = \\dots = \\beta_p = 0$$ versus the alternative $$H_a: at \\; least \\; one \\; \\beta_j \\; is \\; non-zero$$ This hypothesis test is performed by computing **F-statistics** reported in the model summary and calculated as $F = \\frac{(TSS - RSS)/p}{RSS/(n-p-1)}$ where $TSS = \\sum(y_i - \\bar{y})^2$ and $RSS = \\sum(y_i - \\hat{y_i})^2$. Here, the $F-statsitics = 3.046$ and the associated $p-value < 0.05$ so there is enough evidence to reject the null hypothesis in favor of the alternative and conclude that there is an overall significant relationship between response (BMI) and predictors.]\n\n<br />\n**Not so easy: alternative model**\n\nLet's consider another multiple regression model: \n\n- $Y_i = \\beta_0 + \\beta_1 \\cdot age_i + \\beta_2 \\cdot chol_i + \\beta_3 \\cdot hdl_i + \\beta_4 \\cdot  waist_i +  \\epsilon_i$\n\nWe fit the model in `R` and look at the model summary:\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nm2_alt <- lm(BMI ~ age + chol + hdl + waist, data = data_diabetes)\nsummary(m2_alt)\n## \n## Call:\n## lm(formula = BMI ~ age + chol + hdl + waist, data = data_diabetes)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -13.0337  -3.0416  -0.6777   2.2711  18.2894 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(>|t|)    \n## (Intercept) -0.921431   3.588473  -0.257   0.7978    \n## age         -0.050397   0.027016  -1.865   0.0645 .  \n## chol        -0.006250   0.008519  -0.734   0.4645    \n## hdl         -0.006199   0.022890  -0.271   0.7870    \n## waist        0.353256   0.028213  12.521   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 4.381 on 125 degrees of freedom\n## Multiple R-squared:  0.5864,\tAdjusted R-squared:  0.5732 \n## F-statistic:  44.3 on 4 and 125 DF,  p-value: < 2.2e-16\n```\n:::\n\n\n- What happens to `BMI` if `hdl` increases by 10?^[decreases by ca. 0.06]\n- What happens to `BMI` if `hdl` increases by 10 using the first model again?[decreases by ca. 0.9]\n- How do you explain the difference in `BMI` changes given these two models?\n\n**Specific interpretation**\n\n- Obviously there is difference between decrease of 0.9 BMI and decrease of 0.9 in BMI (alternative model). \n- Our interpretations need to be more specific and we say that **a unit increase in $x$ with other predictors held constant will produce a change equal to $\\hat{\\beta}$ in the response $y$**\n- Often it may be quite unrealistic to be able to control other variables and keep them constant and for our alternative model, a change in `hdl` would also imply a change in total cholesterol `chol`. \n- Further, our explanation contains **no notation of causation**.\n- We will learn later how to choose the best model by assessing its fit and including only relevant variable (feature selection), for now we focus on learning how to interpret the coefficients given a fitted model.\n\n\n## Example: categorical variable\n\n- We want to **compare the average BMI of men and women**.\n- We can do that using linear regression and including gender as **binary variable**\n\n\n::: {.cell .column-margin}\n\n```{.r .cell-code  code-fold=\"true\"}\nfont.size <- 20\ncol.blue.light <- \"#a6cee3\"\ncol.blue.dark <- \"#1f78b4\"\nmy.ggtheme <- \n  theme_bw() + \n  theme(axis.title = element_text(size = font.size), \n        axis.text = element_text(size = font.size), \n        legend.text = element_text(size = font.size), \n        legend.title = element_blank(), \n        legend.position = \"top\")\n      \n\n# visualize the data with box plot\ndata_diabetes %>%\n  ggplot(aes(x = gender, y = BMI, fill = gender)) + \n  geom_boxplot() + \n  scale_fill_brewer(palette = \"Set2\") + \n  my.ggtheme\n```\n\n::: {.cell-output-display}\n![](lm-coeff_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n**Model**\n\n$$Y_i = \\alpha + \\beta I_{x_i} + \\epsilon_i$$\nwhere\n\\begin{equation}\n    I_{x_i} =\n    \\left\\{\n        \\begin{array}{cc}\n                1 & \\mathrm{if\\ } x_i=1 \\\\\n                0 & \\mathrm{if\\ } x_i=0 \\\\\n        \\end{array}\n    \\right.\n\\end{equation}\nfor some coding, e.g. we choose to set \"Female=1\" and \"Male=0\" or vice versa.\n\nIn `R` we write:\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\n# Note: check that Gender is indeed non-numeric\nprint(class(data_diabetes$gender))\n## [1] \"factor\"\n\n# fit linear regression and print model summary\nm3 <- lm(BMI ~ gender, data = data_diabetes)\nprint(summary(m3))\n## \n## Call:\n## lm(formula = BMI ~ gender, data = data_diabetes)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -14.167  -4.117  -0.327   3.160  19.273 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)   27.7674     0.8527  32.566  < 2e-16 ***\n## genderfemale   3.9396     1.1379   3.462 0.000729 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 6.437 on 128 degrees of freedom\n## Multiple R-squared:  0.08563,\tAdjusted R-squared:  0.07849 \n## F-statistic: 11.99 on 1 and 128 DF,  p-value: 0.0007286\n```\n:::\n\n\n**Estimates**\n$$\\hat{\\alpha} = 27.7674$$\n$$\\hat{\\beta} = 3.9396$$\n\n- The `lm()` function chooses automatically one of the category as baseline, here `females`.\n- Model summary prints the output of the model with the baseline category **\"hidden\"**.\n- Notice that the only label we have is \"genderfemale\".\n- Meaning that we ended-up having a model coded as below:\n\\begin{equation}\n    I_{x_i} =\n    \\left\\{\n        \\begin{array}{cc}\n                1 & \\mathrm{if\\ } \\quad person_i\\;is\\;female \\\\\n                0 & \\mathrm{if\\ } \\quad person_i\\;is\\;male \\\\\n        \\end{array}\n    \\right.\n\\end{equation}\n- Consequently, if observation $i$ is female then the expected value of `BMI` is:\n$$E(BMI_i|female) = 27.7674 + 3.9396 = 31.707$$\n- and if observation $i$ is male then the expected value of `BMI` is:\n$$E(BMI_i|male) = 27.7674$$\nWe can plot the model in R:\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nggPredict(m3) + \n  my.ggtheme \n```\n\n::: {.cell-output-display}\n![](lm-coeff_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\n## Example: categorical & numerical variables\n\n- Above we observed a signficant difference in average `BMI` between men and women among the study participants.\n- Can we also observe a significant relationship between `BMI` and `height`?\n- And if so, does this relationship depend on `gender`?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#|label: fig-htwtgen-plot\n#|fig-cap: Scatter plot showing BMI measurments given height stratified by gender.\n#|fig-cap-location: margin\n#|collapse: true\n#|code-fold: false\n#|fig-width: 5\n#|fig-heigth: 5\n\n# plot the data separately for Male and Female\ndata_diabetes %>%\n  ggplot(aes(x = height, y=BMI, col = gender)) +\n  geom_point(alpha = 0.8, size = 3) +\n  scale_color_brewer(palette = \"Set2\") + \n  my.ggtheme\n```\n\n::: {.cell-output-display}\n![](lm-coeff_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n- From the plot we can see that `BMI` decreases slightly with `height`.\n- On average, men are taller than women.\n- On average, women have higher BMI than men.\n- The relationship between `height` and `BMI` appears to be the same for males and females, i.e. `BMI` decreases with `height` for both men and women.\n\nTo assess the relationship we use a model containing `height` and `gender`.\n\n**Model**\n\n$$Y_i = \\alpha + \\beta I_{x_i} + \\gamma x_{2,i} + \\epsilon_i$$\nwhere\n\\begin{equation}\n    I_{x_i} =\n    \\left\\{\n        \\begin{array}{cc}\n                1 & \\mathrm{if\\ } \\quad person_i\\;is\\;female \\\\\n                0 & \\mathrm{if\\ } \\quad person_i\\;is\\;male \\\\\n        \\end{array}\n    \\right.\n\\end{equation}\n\nand $x_{2,i}$ is the `heigth` of person $i$.\n\nIn `R` we write:\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\n# fit linear model and print model summary\nm4 <- lm(BMI ~ gender + height, data = data_diabetes)\nprint(summary(m4))\n## \n## Call:\n## lm(formula = BMI ~ gender + height, data = data_diabetes)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -13.7580  -4.2617  -0.3863   3.1646  19.2244 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(>|t|)   \n## (Intercept)    37.743     13.294   2.839  0.00527 **\n## genderfemale    3.163      1.538   2.057  0.04172 * \n## height         -5.719      7.606  -0.752  0.45350   \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 6.448 on 127 degrees of freedom\n## Multiple R-squared:  0.08969,\tAdjusted R-squared:  0.07535 \n## F-statistic: 6.256 on 2 and 127 DF,  p-value: 0.002562\n```\n:::\n\n\n**Model together with estimates**\n\n$$Y_i = \\alpha + \\beta I_{x_i} + \\gamma x_{2,i} + \\epsilon_i$$\nwhere\n\\begin{equation}\n    I_{x_i} =\n    \\left\\{\n        \\begin{array}{cc}\n                1 & \\mathrm{if\\ } \\quad person_i\\;is\\;male \\\\\n                0 & \\mathrm{if\\ } \\quad person_i\\;is\\;female \\\\\n        \\end{array}\n    \\right.\n\\end{equation}\n\nand $x_{2,i}$ is the weight of person $i$\n\n\n**Estimates**\n\n$$\\hat{\\alpha} = 37.743 $$\n$$\\hat{\\beta} = 3.163$$\n$$\\hat{\\gamma} = -5.719$$\n\n\n- For instance, using our estimates, for a female who happens to 1.7 m tall we would predict `BMI` of:\n$$E(BMI_i|female, height = 1.7) = 37.743 + 3.163 + (-5.719 \\cdot 1.7) = 31.1837$$\n- and for a male of height 1.7 m tall we would predict `BMI` of\n$$E(BMI_i|male, height = 1.7) = 37.743 + (-5.719 \\cdot 1.7)  = 28.0207$$\n\nIn `R` we can plot our data and the fitted model to verify our calculations:\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\n# plot the data separately for men and women\n# using ggplot() and geom_smooth()\nggPredict(m4) + \n  scale_color_brewer(palette = \"Set2\") + \n  my.ggtheme\n```\n\n::: {.cell-output-display}\n![](lm-coeff_files/figure-html/unnamed-chunk-13-1.png){width=768}\n:::\n:::\n\n\n<br />\n\n## Example: interactions\n\n\n- The fitted lines in the above example are **parallel**, the **slope is modeled to be the same for men and women**, and the intercept denotes the group differences.\n- It is also possible to allow for **both intercept and slope being fitted separately for each group**.\n- This is done when we except that the relationships are different in different groups, e.g. increasing in one group and decreasing in the other.\n- And we then talk about including **interaction effect** since the two lines may interact (cross).\n\n**Model**\n\n$$Y_{i,j} = \\alpha_i + \\beta_ix_{ij} + \\epsilon_{i,j}$$\nwhere:\n\n- $Y_{i,j}$ is the BMI of person $j$ of gender $i$\n- $x_{ij}$ is the height of person $j$ of gender $i$\n- $i=1$ corresponds to women in our example (keeping the same coding as above)\n- $i=2$ corresponds to men\n\nIn `R` we define the interaction term with `*`:\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\n# fit linear model with interaction\nm5 <- lm(BMI ~ gender * height, data = data_diabetes)\nprint(summary(m5))\n## \n## Call:\n## lm(formula = BMI ~ gender * height, data = data_diabetes)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -13.5564  -4.1137  -0.3072   3.1057  19.2005 \n## \n## Coefficients:\n##                     Estimate Std. Error t value Pr(>|t|)\n## (Intercept)           31.222     20.318   1.537    0.127\n## genderfemale          14.219     26.032   0.546    0.586\n## height                -1.981     11.638  -0.170    0.865\n## genderfemale:height   -6.558     15.414  -0.425    0.671\n## \n## Residual standard error: 6.469 on 126 degrees of freedom\n## Multiple R-squared:  0.09099,\tAdjusted R-squared:  0.06935 \n## F-statistic: 4.204 on 3 and 126 DF,  p-value: 0.007155\n```\n:::\n\n\nNow, based on the regression output we would expect:\n\n- for a woman of height $x$, a BMI value of:\n$$E(BMI|female\\; and \\; height=x)=31.222 + 14.219 - 1.981 \\cdot x - 6.558 \\cdot x = 45.441 -8.539 \\cdot x$$\n- for a man of height $x$, a BMI value of $$E(BMI|male\\; and \\; height=x)=31.222-1.981 \\cdot x$$\n\n**Estimates**\n$$\\hat{\\alpha_1} = 45.441$$\n$$\\hat{\\beta_1} = 31.222$$\n\n$$\\hat{\\alpha_2} = 47.34778$$\n$$\\hat{\\beta_2} = -1.981$$\n\n- We can see from the regression output that there is no evidence to reject the null hypothesis that the interaction term \"Genderfemale:height\" is equal to zero.\n- Or therefore conclude that the relationship between `BMI` and `height` is different for men and women.\n- We can plot the fitted model and see that the lines are no longer parallel.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nggPredict(m5) +\n  guides(color=guide_legend(override.aes=list(fill=NA))) + \n  scale_color_brewer(palette = \"Set2\") + \n  my.ggtheme\n```\n\n::: {.cell-output-display}\n![](lm-coeff_files/figure-html/unnamed-chunk-15-1.png){width=768}\n:::\n:::\n\n\n\n## Example: logistic regression with categorical variable\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\n# recode diabetic status to 1 and 0\ndata_diabetes <- data_diabetes %>%\n  mutate(obese = ifelse(obese == \"Yes\", 1, 0))\n\n# fit logistic regression using age and gender\nm6 <- glm(obese ~  hdl + gender, family = binomial(link=\"logit\"), data = data_diabetes)\nsummary(m6)\n## \n## Call:\n## glm(formula = obese ~ hdl + gender, family = binomial(link = \"logit\"), \n##     data = data_diabetes)\n## \n## Deviance Residuals: \n##     Min       1Q   Median       3Q      Max  \n## -1.5968  -0.9830  -0.6736   1.0641   1.9679  \n## \n## Coefficients:\n##              Estimate Std. Error z value Pr(>|z|)   \n## (Intercept)   0.55047    0.58718   0.937   0.3485   \n## hdl          -0.02997    0.01197  -2.504   0.0123 * \n## genderfemale  1.26586    0.40120   3.155   0.0016 **\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for binomial family taken to be 1)\n## \n##     Null deviance: 178.71  on 129  degrees of freedom\n## Residual deviance: 164.39  on 127  degrees of freedom\n## AIC: 170.39\n## \n## Number of Fisher Scoring iterations: 4\n```\n:::\n\n\n- By how much change odds of suffering from obesity when `hdl` increases by 1?^[the odds increase by e^{-0.02997} = 0.97]\n- What are the odds of suffering from obesity and being a women vs. suffering from obesity and being a man?^[The odds of suffering from obesity as a woman are e^{1.26586} = 3.55 times of that suffering from obesity and being a man.]\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nggPredict(m6) + \n  scale_color_brewer(palette = \"Set2\") + \n  my.ggtheme\n```\n\n::: {.cell-output-display}\n![](lm-coeff_files/figure-html/unnamed-chunk-17-1.png){width=768}\n:::\n:::\n\n\nWe can predict `obesity status` in R for a man with `hdl` values of 50:\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\n# define new observation\ndf <- data.frame(hdl = 50, gender = as.factor(\"male\"))\n\n# predict probability of suffering from obesity\nprob_obese <- predict(m6, newdata = df, type = \"response\")\nprint(prob_obese)\n##         1 \n## 0.2792396\n```\n:::\n",
    "supporting": [
      "lm-coeff_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}