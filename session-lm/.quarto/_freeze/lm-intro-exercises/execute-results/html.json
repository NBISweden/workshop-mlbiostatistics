{
  "hash": "d0cac8cab433759ae4b58758f5259ca4",
  "result": {
    "markdown": "---\noutput: html_document\neditor_options: \n  chunk_output_type: console\n---\n\n# Exercises (introduction to linear models) {.unnumbered}\n\n\n::: {.cell}\n\n:::\n\n\n:::{#exr-lm-fit}\n\n## Fitting linear model\n\nGoing back to the diabetes data, fit linear regression models using vector-matrix notations to model BMI based on age [years] and waist [m] measurements. In particular, define design matrix $\\mathbf{X}$, vector of observations $\\mathbf{Y}$ and vector of parameters $\\boldsymbol\\beta$ and use $$\\hat{\\mathbf{\\beta}}= (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y}$$ to find beta values estimates. \n\nCheck your calculations by fitting the model using `lm()` function.\n\nThe below code can get you started.\n\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\ninch2m <- 2.54/100\npound2kg <- 0.45\ndata_diabetes <- diabetes %>%\n  mutate(height  = height * inch2m, height = round(height, 2)) %>% \n  mutate(waist = waist * inch2m) %>%  \n  mutate(weight = weight * pound2kg, weight = round(weight, 2)) %>%\n  mutate(BMI = weight / height^2, BMI = round(BMI, 2)) %>% \n  mutate(obese= cut(BMI, breaks = c(0, 29.9, 100), labels = c(\"No\", \"Yes\"))) %>% \n  mutate(diabetic = ifelse(glyhb > 7, \"Yes\", \"No\"), diabetic = factor(diabetic, levels = c(\"No\", \"Yes\"))) %>%\n  na.omit()\n```\n:::\n\n\n\n:::{#exr-lm-hypothesis}\n\n## Hypothesis testing\n\nYour colleague Anna is interested in association between BMI and cholesterol, both total cholesterol (chol) and high density lipoprotein fraction (hdl). She has correctly fitted linear model using lm() function but her computer broke and she only has the below output: \n\n:::\n\n```{.r}\n# Coefficients:\n#               Estimate Std. Error t value Pr(>|t|)\n# (Intercept)  3.471e+01  2.940e+00  11.808  < 2e-16 ***\n# chol         1.965e-05  1.231e-02\n# hdl         -9.371e-02  3.220e-02\n```\n\n\nCan you help Anna finding out whether `chol` and `hdl` are significantly associated with `BMI`? What are the t-value statistics and the corresponding p-values? Calculate these values without fitting the model and then fit the model to double check your calculations.\n\n\n:::{#exr-lm-assess-fit}\n\n## Evaluate model fit\n\nAfter helping Anna you got interested in whether your initial model containing `age` and `waist` is a better fit to the data than Anna's model containing `chol` and `hdl`. Evaluate model fit by calculating $R^2(adj)$ based on the equation:\n\n$$R^2(adj) = 1-\\frac{\\frac{RSS}{n-p-1}}{\\frac{TSS}{n-1}}$$ where\n\n- $p$ is the number of independent predictors, i.e. the number of variables in the model, excluding the constant and $n$ is the number of observations. \n\nCheck your calculations using `lm()` function.\n\nHint: If `reg` holds a fitted linear regression model,  you can assess the estimated BMI values by accessing `reg$fitted.values` and residuals via `reg$residuals`. \n\n:::\n\n\n::: {.solution}\n\n@exr-lm-fit\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\ninch2m <- 2.54/100\npound2kg <- 0.45\ndata_diabetes <- diabetes %>%\n  mutate(height  = height * inch2m, height = round(height, 2)) %>% \n  mutate(waist = waist * inch2m) %>%  \n  mutate(weight = weight * pound2kg, weight = round(weight, 2)) %>%\n  mutate(BMI = weight / height^2, BMI = round(BMI, 2)) %>% \n  mutate(obese= cut(BMI, breaks = c(0, 29.9, 100), labels = c(\"No\", \"Yes\"))) %>% \n  mutate(diabetic = ifelse(glyhb > 7, \"Yes\", \"No\"), diabetic = factor(diabetic, levels = c(\"No\", \"Yes\"))) %>%\n  na.omit()\n\n# define Y\nY <- data_diabetes %>% select(\"BMI\") %>% as.matrix()\n\n# define X\nX <- cbind(rep(1, nrow(data_diabetes)), data_diabetes$age, data_diabetes$waist)\nX <- as.matrix(X)\n\n# alternatively we case use model.matrix() to define X\nX <- model.matrix(~ age + waist, data = data_diabetes)\n\n# least square estimate\nbeta.hat <- solve(t(X)%*%X)%*%t(X)%*%Y\nprint(beta.hat)\n##                     BMI\n## (Intercept) -2.39192911\n## age         -0.05716479\n## waist       35.46856117\n\n# check calculations using lm() function\nreg_1 <- lm(BMI ~ age + waist, data = data_diabetes)\nsummary(reg_1)\n## \n## Call:\n## lm(formula = BMI ~ age + waist, data = data_diabetes)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -12.6952  -2.8803  -0.5864   2.2229  18.7443 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept) -2.39193    2.95646  -0.809   0.4200    \n## age         -0.05716    0.02551  -2.241   0.0267 *  \n## waist       35.46856    2.68192  13.225   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 4.358 on 127 degrees of freedom\n## Multiple R-squared:  0.5841,\tAdjusted R-squared:  0.5776 \n## F-statistic: 89.19 on 2 and 127 DF,  p-value: < 2.2e-16\n```\n:::\n\n\n\n::: \n\n::: {.solution}\n\n@exr-lm-hypothesis\n\nUnder the null hypothesis $H_0: \\beta = 0$\n![](figures/linear-models/lm-tstatistics.png)\n\n- $n$ is number of observations\n- $p$ is number of model parameters\n- $\\frac{\\hat{\\beta}-\\beta}{e.s.e(\\hat{\\beta})}$ is the ratio of the departure of the estimated value of a parameter, $\\hat\\beta$, from its hypothesized value, $\\beta$, to its standard error, called `t-statistics`\n- the `t-statistics` follows Student's t distribution with $n-p$ degrees of freedom\n\nThis means that to check if the there is an association between `chol` and `BMI` we check if there is enough evidence to reject the null hypothesis of $H_0: \\beta = 0$. Here, t-statistics equals to $\\frac{\\hat{\\beta}-\\beta}{e.s.e(\\hat{\\beta})} = \\frac{1.965\\times 10^{05} - 0}{1.231\\times 10^{05}} = 0.001596263$ and a corresponding p-values can be found: \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\n2*pt(0.001596263, df=130 - 3, lower.tail = F)\n## [1] 0.9987289\n```\n:::\n\n\nAssuming 5% significance level, we do not have enough evidence to reject the null hypothesis in favor of the alternative as p-value is large $p = 0.99873 > 0.05$. This means we do not observe association between `chol` and `BMI.`\n\nAnalogously, for `age` we have t-statistics equal to $\\frac{\\hat{\\beta}-\\beta}{e.s.e(\\hat{\\beta})} = \\frac{-9.371\\times 10^{02} - 0}{3.220\\times 10^{02}} = -2.910248$ and a corresponding p-value equals to:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\n2*pt(-2.910248, df=130 - 3, lower.tail = T)\n## [1] 0.004265831\n```\n:::\n\n\nHere, p-value is small and we can thus reject the null hypothesis in favour of the alternative and conclude that there is an association between `hdl` and `BMI`.\n\nTo check our calculations we can re-fit the linear model and print the entire summary.\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nreg_2 <- lm(BMI ~ chol + hdl, data = data_diabetes)\nsummary(reg_2)\n## \n## Call:\n## lm(formula = BMI ~ chol + hdl, data = data_diabetes)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -12.8952  -4.8988  -0.9225   3.0629  21.7951 \n## \n## Coefficients:\n##               Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  3.471e+01  2.940e+00  11.808  < 2e-16 ***\n## chol         1.965e-05  1.231e-02   0.002  0.99873    \n## hdl         -9.371e-02  3.220e-02  -2.910  0.00426 ** \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 6.538 on 127 degrees of freedom\n## Multiple R-squared:  0.0643,\tAdjusted R-squared:  0.04956 \n## F-statistic: 4.363 on 2 and 127 DF,  p-value: 0.0147\n```\n:::\n\n\n::: \n\n::: {.solution}\n\n@exr-lm-assess-fit\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nn <- nrow(data_diabetes)\np <- 2 # beta for age and beta for waist (model 1)\np <- 2 # beta for chol and beta for hdl (model 2)\n\n# calculate TSS\nTSS <- sum((data_diabetes$BMI - mean(data_diabetes$BMI))^2)\n\n# calculate RSS and R2_adj (model 1)\n# model BMI ~ age + waist \nreg_1 <- lm(BMI ~ age + waist, data = data_diabetes)\nreg <- reg_1\nRSS <- sum((reg$residuals)^2)\nR2_adj <- 1 - (RSS/(n-p-1))/(TSS/(n-1))\nprint(R2_adj)\n## [1] 0.5775851\n\n# calculate RSS and R2_adj (model 2)\n# model BMI ~ chol + hdl\nreg_2 <- lm(BMI ~ chol + hdl, data = data_diabetes)\nreg <- reg_2\nRSS <- sum((reg$residuals)^2)\nR2_adj <- 1 - (RSS/(n-p-1))/(TSS/(n-1))\nprint(R2_adj)\n## [1] 0.04956166\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\n# check calculations\nsummary(reg_1)\n## \n## Call:\n## lm(formula = BMI ~ age + waist, data = data_diabetes)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -12.6952  -2.8803  -0.5864   2.2229  18.7443 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept) -2.39193    2.95646  -0.809   0.4200    \n## age         -0.05716    0.02551  -2.241   0.0267 *  \n## waist       35.46856    2.68192  13.225   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 4.358 on 127 degrees of freedom\n## Multiple R-squared:  0.5841,\tAdjusted R-squared:  0.5776 \n## F-statistic: 89.19 on 2 and 127 DF,  p-value: < 2.2e-16\nsummary(reg_2)\n## \n## Call:\n## lm(formula = BMI ~ chol + hdl, data = data_diabetes)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -12.8952  -4.8988  -0.9225   3.0629  21.7951 \n## \n## Coefficients:\n##               Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  3.471e+01  2.940e+00  11.808  < 2e-16 ***\n## chol         1.965e-05  1.231e-02   0.002  0.99873    \n## hdl         -9.371e-02  3.220e-02  -2.910  0.00426 ** \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 6.538 on 127 degrees of freedom\n## Multiple R-squared:  0.0643,\tAdjusted R-squared:  0.04956 \n## F-statistic: 4.363 on 2 and 127 DF,  p-value: 0.0147\n```\n:::\n\n\n::: \n\n\n\n\n\n<!-- **Data for exercises** are on Canvas under Files -> data_exercises --> \n<!-- linear-models --> -->\n\n<!-- ::: {#exr-protein} -->\n\n<!-- ## Protein levels in pregnancy -->\n\n<!-- The researchers were interested whether protein levels in expectant mothers are changing throughout the pregnancy. Observations have been taken on 19 healthy women and each woman was at different stage of pregnancy (gestation). -->\n\n<!-- Assuming linear model: -->\n\n<!-- - $Y_i = \\alpha + \\beta x_i + \\epsilon_i$, where $Y_i$ corresponds to protein levels in i-th observation -->\n\n<!-- and taking summary statistics: -->\n\n<!-- - $\\sum_{i=1}^{n}x_i = 456$ -->\n<!-- - $\\sum_{i=1}^{n}x_i^2 = 12164$ -->\n<!-- - $\\sum_{i=1}^{n}x_iy_i = 369.87$ -->\n<!-- - $\\sum_{i=1}^{n}y_i = 14.25$ -->\n<!-- - $\\sum_{i=1}^{n}y_i^2 = 11.55$ -->\n\n\n<!-- a) find the least square estimates of $\\hat{\\alpha}$ and $\\hat{\\beta}$ -->\n<!-- b) knowing that e.s.e($\\hat{\\beta}) = 0.003295$ -->\n\n<!-- can we: -->\n\n<!-- - i) reject the null hypothesis that the is no relationship between protein level and gestation, i.e. perform a hypothesis test to test $H_0:\\beta = 0$; -->\n<!-- - ii) can we reject the null hypothesis that $\\beta = 0.02$, i.e.  perform a hypothesis test to test $H_0:\\beta = 0.02$ -->\n<!-- c) write down the linear model in the vector-matrix notation and identify response, parameter, design and error matrices -->\n<!-- d) read in \"protein.csv\" data into R, set Y as protein (response) and calculate using matrix functions the least squares estimates of model coefficients -->\n<!-- e) use `lm()` function in R to check your calculations -->\n<!-- f) use the fitted model in R to predict the value of protein levels at week 20. Try plotting the data, fitted linear model and the predicted value to assess whether your prediction is to be expected. -->\n\n<!-- ::: -->\n\n\n<!-- ::: {#exr-potato} -->\n\n<!-- ## Glucose levels in potatoes -->\n\n<!-- The glucose level in potatoes depends on their storage time and the relationship is somehow curvilinear as shown below. -->\n<!-- As we believe that the quadratic function might describe the relationship, assume linear model in form -->\n<!-- $Y_i = \\alpha + \\beta x_i + \\gamma x_i^2 + \\epsilon_i \\quad i=1,\\dots,n$ where $n=14$ and -->\n\n<!-- a) write down the model in vector-matrix notation -->\n<!-- b) load data from \"potatoes.csv\" and use least squares estimates to obtain estimates of model coefficients -->\n<!-- c) use `lm()` function to verify your calculations -->\n<!-- d) perform a hypothesis test to test $H_0:\\gamma=0$; and comment whether there is a significant quadratic relationship -->\n<!-- e) predict glucose concentration at storage time 4 and 16 weeks. Plot the data, the fitted model and the predicted values -->\n\n<!-- ::: -->\n\n\n<!-- ```{r} -->\n<!-- #| label: fig-potatoes -->\n<!-- #| fig-cap: \"Sugar in potatoes: relationship between storage time and glucose content\" -->\n<!-- #| fig-width: 5 -->\n<!-- #| fig-heigth: 5 -->\n\n<!-- data.potatoes <- read.csv(\"data/lm/potatoes.csv\") -->\n<!-- plot(data.potatoes$Weeks, data.potatoes$Glucose, pch=19, xlab=\"Storage time [weeks]\", ylab=\"Glucose [g/kg]\") -->\n\n<!-- ``` -->\n\n<!-- ::: {#exr-recognize} -->\n\n<!-- ## Linear models form -->\n\n<!-- Which of the following models are linear models and why? -->\n\n<!-- a) $Y_i=\\alpha + \\beta x_i + \\epsilon_i$ -->\n<!-- b) $Y_i=\\beta_0 + \\beta_1 x_{i,1} + \\beta_2 x_{i,2} + \\epsilon_i$ -->\n<!-- c) $Y_i=\\alpha + \\beta x_i + \\gamma x_i^2 + \\epsilon_i$ -->\n<!-- d) $Y_i=\\alpha + \\gamma x_i^\\beta + \\epsilon_i$ -->\n\n<!-- :::  -->\n\n<!-- ------------ -->\n\n\n\n<!-- ## Answers to selected exercises  -->\n\n<!-- ::: {.solution} -->\n\n<!-- @exr-protein -->\n\n<!-- :::  -->\n\n<!-- a) -->\n\n<!-- - $S_{xx} = \\sum_{i=1}^{n}x_i^2-\\frac{(\\sum_{i=1}^{n}x_i)^2}{n} = 12164 - \\frac{456^2}{19} = 1220$ -->\n<!-- - $S_{xy} = \\sum_{i=1}^nx_iy_i-\\frac{\\sum_{i=1}^{n}x_i\\sum_{i=1}^{n}y_i}{n} = 369.87 - \\frac{(456 \\cdot 14.25)}{19} = 27.87$ -->\n<!-- - $\\hat{\\beta} = \\frac{S_{xy}}{S_{xx}} = 27.87 / 1220 = 0.02284$ -->\n<!-- - $\\hat{\\alpha} = \\bar{y}-\\frac{S_{xy}}{S_{xx}}\\cdot \\bar{x} = \\frac{14.25}{19}-\\frac{27.87}{1220}\\cdot \\frac{456}{19} = 0.20174$ -->\n\n<!-- b) i. -->\n\n<!-- We can calculate test statistics following: -->\n\n<!-- - $\\frac{\\hat{\\beta} - \\beta}{e.s.e(\\hat{\\beta})} \\sim t(n-p) = \\frac{0.02284 - 0}{0.003295} = 6.934$ where the value follows Student's t distribution with $n-p = 19 - 2 = 17$ degrees of freedom. We can now estimate the a p-value using Student’s t distribution table or use R function -->\n<!-- ```{r} -->\n<!-- #| code-fold: false -->\n<!-- 2*pt(6.934, df=17, lower=F) -->\n<!-- ``` -->\n<!-- As p-value << 0.001 there is sufficient evidence to reject $H_0$ in favor of $H_1$, thus we can conclude that there is a significant relationship between protein levels and gestation -->\n\n<!-- b) ii. -->\n\n<!-- Similarly, we can test $H_0:\\beta = 0.02$, i.e. $\\frac{\\hat{\\beta} - \\beta}{e.s.e(\\hat{\\beta})} \\sim t(n-p) = \\frac{0.02284 - 0.02}{0.20174} = 0.01407753$. Now the test statistics is small -->\n<!-- ```{r} -->\n<!-- #| code-fold: false -->\n<!-- 2*pt(0.01407753, df=17, lower=F) -->\n<!-- ``` -->\n<!-- p-value is large and hence there is no sufficient evidence to reject $H_0$ and we can conclude that $\\beta = 0.02$ -->\n\n<!-- c) We can rewrite the linear model in vector-matrix formation as $\\mathbf{Y}= \\mathbf{\\beta}\\mathbf{X} + \\mathbf{\\epsilon}$ where: -->\n\n<!-- response $\\mathbf{Y}=\\begin{bmatrix} -->\n<!--   y_1  \\\\ -->\n<!--   y_2    \\\\ -->\n<!--   \\vdots \\\\ -->\n<!--   y_{19} -->\n<!-- \\end{bmatrix}$ -->\n\n<!-- parameters $\\boldsymbol\\beta=\\begin{bmatrix} -->\n<!--   \\alpha \\\\ -->\n<!--   \\beta -->\n<!-- \\end{bmatrix}$ -->\n\n<!-- design matrix $\\mathbf{X}=\\begin{bmatrix} -->\n<!--   1 & x_1  \\\\ -->\n<!--   1 & x_2  \\\\ -->\n<!--   \\vdots & \\vdots \\\\ -->\n<!--   1 & x_{19} -->\n<!-- \\end{bmatrix}$ -->\n\n<!-- errors $\\boldsymbol\\epsilon=\\begin{bmatrix} -->\n<!--   \\epsilon_1  \\\\ -->\n<!--   \\epsilon_2    \\\\ -->\n<!--   \\vdots \\\\ -->\n<!--   \\epsilon_{19} -->\n<!-- \\end{bmatrix}$ -->\n\n<!-- d) The least squares estimates in vector-matrix notation is $\\hat{\\boldsymbol\\beta}= (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y}$ and we can calculate this in R -->\n\n<!-- ```{r protein} -->\n<!-- #| code-fold: false -->\n<!-- # read in data -->\n<!-- data.protein <- read.csv(\"data/lm/protein.csv\") -->\n\n<!-- # print out top observations -->\n<!-- head(data.protein) -->\n\n<!-- # define Y and X matrices given the data -->\n<!-- n <- nrow(data.protein) # nu. of observations -->\n<!-- Y <-  as.matrix(data.protein$Protein, ncol=1) # response -->\n<!-- X <-  as.matrix(cbind(rep(1, length=n), data.protein$Gestation)) # design matrix -->\n<!-- head(X) # double check that the design matrix looks like it should -->\n\n<!-- # least squares estimate -->\n<!-- beta.hat <- solve(t(X)%*%X)%*%t(X)%*%Y # beta.hat is a matrix that contains our alpha and beta in the model -->\n<!-- print(beta.hat) -->\n\n<!-- ``` -->\n\n<!-- e) We use `lm()` function to check our calculations -->\n<!-- ```{r} -->\n<!-- #| code-fold: false -->\n\n<!-- # fit linear regression model and print model summary -->\n<!-- protein <- data.protein$Protein # our Y -->\n<!-- gestation <- data.protein$Gestation # our X -->\n\n<!-- model <- lm(protein ~ gestation) -->\n<!-- print(summary(model)) -->\n\n<!-- ``` -->\n\n<!-- f) -->\n<!-- ```{r} -->\n<!-- #| code-fold: false -->\n\n\n<!-- new.obs <- data.frame(gestation = 20) -->\n<!-- y.pred <- predict(model, newdata = new.obs) -->\n\n<!-- # we can visualize the data, fitted linear model (red), and the predicted value (blue) -->\n<!-- plot(gestation, protein, pch=19, xlab=\"gestation [weeks]\", ylab=\"protein levels [mgml-1]\") -->\n<!-- lines(gestation, model$fitted.values, col=\"red\") -->\n<!-- points(new.obs, y.pred, col=\"blue\", pch=19, cex = 1) -->\n\n<!-- ``` -->\n\n\n\n\n<!-- ::: {.solution} -->\n\n<!-- @exr-potato -->\n\n<!-- ::: -->\n\n\n<!-- a) We can rewrite the linear model in vector-matrix formation as $$\\mathbf{Y} = \\mathbf{X}\\boldsymbol\\beta + \\boldsymbol\\epsilon$$ -->\n\n<!-- where: -->\n<!-- response $\\mathbf{Y}=\\begin{bmatrix} -->\n<!--   y_1  \\\\ -->\n<!--   y_2    \\\\ -->\n<!--   \\vdots \\\\ -->\n<!--   y_{14} -->\n<!-- \\end{bmatrix}$ -->\n\n<!-- parameters $\\boldsymbol\\beta=\\begin{bmatrix} -->\n<!--   \\alpha \\\\ -->\n<!--   \\beta \\\\ -->\n<!--   \\gamma -->\n<!-- \\end{bmatrix}$ -->\n\n<!-- design matrix $\\mathbf{X}=\\begin{bmatrix} -->\n<!--   1 & x_1  & x_1^2\\\\ -->\n<!--   1 & x_2  & x_2^2\\\\ -->\n<!--   \\vdots & \\vdots & \\vdots \\\\ -->\n<!--   1 & x_{14} & x_{14}^2 -->\n<!-- \\end{bmatrix}$ -->\n\n<!-- errors $\\boldsymbol\\epsilon=\\begin{bmatrix} -->\n<!--   \\epsilon_1  \\\\ -->\n<!--   \\epsilon_2    \\\\ -->\n<!--   \\vdots \\\\ -->\n<!--   \\epsilon_{14} -->\n<!-- \\end{bmatrix}$ -->\n\n\n<!-- b) load data to from \"potatoes.csv\" and use least squares estimates for obtain estimates of model coefficients -->\n<!-- ```{r} -->\n<!-- #| code-fold: false -->\n\n<!-- data.potatoes <- read.csv(\"data/lm/potatoes.csv\") -->\n\n<!-- # define matrices -->\n<!-- n <- nrow(data.potatoes) -->\n<!-- Y <-  data.potatoes$Glucose -->\n<!-- X1 <- data.potatoes$Weeks -->\n<!-- X2 <- (data.potatoes$Weeks)^2 -->\n<!-- X <- cbind(rep(1, length(n)), X1, X2) -->\n<!-- X <- as.matrix(X) -->\n\n<!-- # least squares estimate -->\n<!-- # beta here refers to the matrix of model coefficients incl. alpha, beta and gamma -->\n<!-- beta.hat <- solve(t(X)%*%X)%*%t(X)%*%Y -->\n<!-- print(beta.hat) -->\n<!-- ``` -->\n\n<!-- c) we use `lm()` function to verify our calculations: -->\n<!-- ```{r} -->\n<!-- #| code-fold: false -->\n<!-- model <- lm(Y ~ X1 + X2) -->\n<!-- print(summary(model)) -->\n<!-- ``` -->\n\n<!-- d) perform a hypothesis test to test $H_0:\\gamma=0$; and comment whether we there is a significant quadratic term -->\n<!-- - $\\frac{\\hat{\\gamma} - \\gamma}{e.s.e(\\hat{\\gamma})} \\sim t(n-p) = \\frac{1.030423 - 0}{0.1406} = 7.328755$ where the value follows Student's t distribution with $n-p = 19 - 2 = 17$ degrees of freedom. We can now estimate the a p-value using Student’s t distribution table or use a function in R -->\n\n<!-- ```{r} -->\n<!-- #| code-fold: false -->\n<!-- 2*pt(7.328755, df=14-3, lower=F) -->\n<!-- ``` -->\n<!-- As p-value << 0.001 there is sufficient evidence to reject $H_0$ in favor of $H_1$, thus we can conclude that there is a significant quadratic relationship between glucose and storage time -->\n\n<!-- e) predict glucose concentration at storage time 4 and 16 weeks -->\n\n<!-- ```{r} -->\n<!-- #| code-fold: false -->\n<!-- new.obs <- data.frame(X1 = c(4, 16), X2 = c(4^2, 16^2)) -->\n<!-- pred.y <- predict(model, newdata = new.obs) -->\n\n<!-- plot(data.potatoes$Weeks, data.potatoes$Glucose, xlab=\"Storage time [weeks]\", ylab=\"Glucose [g/kg]\", pch=19) -->\n<!-- lines(data.potatoes$Weeks, model$fitted.values, col=\"red\") -->\n<!-- points(new.obs[,1], pred.y, pch=19, col=\"blue\") -->\n\n<!-- ``` -->\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}