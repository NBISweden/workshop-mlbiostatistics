{"title":"Linear models in the ML context","markdown":{"yaml":{"output":"html_document","editor_options":{"chunk_output_type":"console"}},"headingText":"Linear models in the ML context","containsRefs":false,"markdown":"\n\n\n- It is often the case that some or many of the variables used in a multiple regression model are in fact not associated with the response. \n- Including such **irrelevant** variables leads to unnecessary complexity in the resulting model, and worse prediction results. \n- There are few approaches to perform **feature selection** or **variable selection**, that is for excluding irrelevant variables from a multiple regression model. The main classes include **Subset Selection**, **Shrinkage methods** and **Dimension Reduction**.\n- Here, we can also think of linear models in machine learning context. By using data splitting strategies, we can find best linear models for prediction tasks. \n- Similar to evaluation classification results, we need some metrics to evaluate regression results. In terms of assessing model fit, we have already seen one metric i.e. adjusted $R^2$. Other metrics than can also be expressed in terms of RSS include **Akaike information criterion (AIC)** and **Bayesian information criterion (BIC)**. \n- In addition, validation set and cross-validation methods can be used to directly evaluate the prediction error. Here, we use metrics such as **Mean Squared Error (MSE)** or **Mean Absolute Error (MAE)**.\n\n\n## Evaluating regression\n\n### model fit\n\n**Adjusted R-squared** (as seen before)\n$$\nR_{adj}^2=1-\\frac{RSS}{TSS}\\frac{n-1}{n-p-1} = 1 - \\frac{\\sum_{i=1}^{n}(y_i - \\hat{y_i})^2}{\\sum_{i=1}^{n}(y_i - \\bar{y})^2}\\frac{n-1}{n-p-1}\n$$\n\n**AIC** and **BIC**\n\nAIC is grounded in information theory and BIC is derived from a Bayesian point of view. Both are formally defined in likelihood functions. For regression models they can be expressed in terms of RSS because the likelihood of a model in the context of normal errors is directly related to the RSS. \n \n$$\\text{AIC} = n \\ln(\\text{RSS}/n) + 2p$$\n\nwhere:\n\n- $n$ is the number of observations.\n- $\\text{RSS}$ is the residual sum of squares.\n- $p$ is the number of parameters in the model (including the intercept).\n\n\n$$\\text{BIC} = n \\ln(\\text{RSS}/n) + p \\ln(n)$$\n\nwhere:\n\n- $n$ is the number of observations.\n- $\\text{RSS}$ is the residual sum of squares.\n- $p$ is the number of parameters in the model.\n\n\nBoth criteria, AIC and BIC, introduce penalties for the number of parameters to avoid overfitting. BIC introduces a stronger penalty based on the sample size, making it more conservative than AIC. When comparing models using AIC or BIC that incorporate RSS, the objective remains the same: select the model that provides the best balance between goodness of fit and model simplicity. The model with the lower AIC or BIC value is generally preferred, as it indicates either a more parsimonious model or a model that better fits the data (or both). \n\n### predictions\n\n- **Mean Squared Error (MSE)**: average squared difference between the predicted values and the actual values.\n$$MSE = \\frac{1}{N}\\sum_{i=1}^{N}({y_i}-\\hat{y}_i)^2$$\n- **Root Mean Squared Error (RMSE)**: square root of the MSE\n$$RMSE = \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}({y_i}-\\hat{y}_i)^2}$$\n- **MAE**: average absolute difference between the predicted values and the actual values $$MAE = \\frac{1}{N}\\sum_{i=1}^{N}|{y_i}-\\hat{y}_i|$$\n- **Mean Absolute Percentage Error (MAPE)**: average percentage difference between the predicted values and the actual values.\n\nThe smaller the difference between the predicted values vs. the validation or cross-validation predicted values, the better the model. \n\n## Feature selection\n\n\n","srcMarkdownNoYaml":"\n\n## Linear models in the ML context\n\n- It is often the case that some or many of the variables used in a multiple regression model are in fact not associated with the response. \n- Including such **irrelevant** variables leads to unnecessary complexity in the resulting model, and worse prediction results. \n- There are few approaches to perform **feature selection** or **variable selection**, that is for excluding irrelevant variables from a multiple regression model. The main classes include **Subset Selection**, **Shrinkage methods** and **Dimension Reduction**.\n- Here, we can also think of linear models in machine learning context. By using data splitting strategies, we can find best linear models for prediction tasks. \n- Similar to evaluation classification results, we need some metrics to evaluate regression results. In terms of assessing model fit, we have already seen one metric i.e. adjusted $R^2$. Other metrics than can also be expressed in terms of RSS include **Akaike information criterion (AIC)** and **Bayesian information criterion (BIC)**. \n- In addition, validation set and cross-validation methods can be used to directly evaluate the prediction error. Here, we use metrics such as **Mean Squared Error (MSE)** or **Mean Absolute Error (MAE)**.\n\n\n## Evaluating regression\n\n### model fit\n\n**Adjusted R-squared** (as seen before)\n$$\nR_{adj}^2=1-\\frac{RSS}{TSS}\\frac{n-1}{n-p-1} = 1 - \\frac{\\sum_{i=1}^{n}(y_i - \\hat{y_i})^2}{\\sum_{i=1}^{n}(y_i - \\bar{y})^2}\\frac{n-1}{n-p-1}\n$$\n\n**AIC** and **BIC**\n\nAIC is grounded in information theory and BIC is derived from a Bayesian point of view. Both are formally defined in likelihood functions. For regression models they can be expressed in terms of RSS because the likelihood of a model in the context of normal errors is directly related to the RSS. \n \n$$\\text{AIC} = n \\ln(\\text{RSS}/n) + 2p$$\n\nwhere:\n\n- $n$ is the number of observations.\n- $\\text{RSS}$ is the residual sum of squares.\n- $p$ is the number of parameters in the model (including the intercept).\n\n\n$$\\text{BIC} = n \\ln(\\text{RSS}/n) + p \\ln(n)$$\n\nwhere:\n\n- $n$ is the number of observations.\n- $\\text{RSS}$ is the residual sum of squares.\n- $p$ is the number of parameters in the model.\n\n\nBoth criteria, AIC and BIC, introduce penalties for the number of parameters to avoid overfitting. BIC introduces a stronger penalty based on the sample size, making it more conservative than AIC. When comparing models using AIC or BIC that incorporate RSS, the objective remains the same: select the model that provides the best balance between goodness of fit and model simplicity. The model with the lower AIC or BIC value is generally preferred, as it indicates either a more parsimonious model or a model that better fits the data (or both). \n\n### predictions\n\n- **Mean Squared Error (MSE)**: average squared difference between the predicted values and the actual values.\n$$MSE = \\frac{1}{N}\\sum_{i=1}^{N}({y_i}-\\hat{y}_i)^2$$\n- **Root Mean Squared Error (RMSE)**: square root of the MSE\n$$RMSE = \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}({y_i}-\\hat{y}_i)^2}$$\n- **MAE**: average absolute difference between the predicted values and the actual values $$MAE = \\frac{1}{N}\\sum_{i=1}^{N}|{y_i}-\\hat{y}_i|$$\n- **Mean Absolute Percentage Error (MAPE)**: average percentage difference between the predicted values and the actual values.\n\nThe smaller the difference between the predicted values vs. the validation or cross-validation predicted values, the better the model. \n\n## Feature selection\n\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":"html_document","warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"lm-ml.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","bibliography":["references.bib"],"theme":"cosmo","editor_options":{"chunk_output_type":"console"}},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}