[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Descriptive statistics",
    "section": "",
    "text": "Preface\nDescriptive statistics is a term describing simple analyses of data that help getting to know the data by describing the data, showing the data and summarizing the data. Descriptive statistics is used to guide down-stream data analysis and often helps to uncover patterns in the data.\nLearning outcomes\n\nunderstand why we are doing descriptive statistics\nunderstand the difference between data types and be able to select and use appropriate data summaries and plots for each data type\ncompute measures of location, including mean and median\ncompute measures of spread, including quantiles, variance and standard deviation\ncompute population and sample mean and variance and be able to explain the difference between them\n\nDo you see a mistake or a typo? We would be grateful if you let us know via edu.ml-biostats@nbis.se\nThis repository contains teaching and learning materials prepared and used during “Introduction to biostatistics and machine learning” course, organized by NBIS, National Bioinformatics Infrastructure Sweden. The course is open for PhD students, postdoctoral researcher and other employees within Swedish universities. The materials are geared towards life scientists wanting to be able to understand and use basic statistical and machine learning methods. More about the course https://nbisweden.github.io/workshop-mlbiostatistics/"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "Statistics is the discipline that concerns the collection, organization, analysis, interpretation, and presentation of data. Two main types of statistics are descriptive and inferential statistics. Descriptive statistics describes and summarizes the data (sample) whereas inferential statistics uses a sample of data to learn about the population that the sample of data is thought to represent.\n\n\n\n\n\nFigure 1.1: Illustration of two main types of statistics. Descriptive statistics describes and summarizes the data. Inferential statistics uses a sample of data to make inferences about the population that the sample of data is thought to represent.\n\n\n\n\nUsing descriptive statistics we can say for example that 40% of our research group members usually walk to work, 20% cycle, 20% take a bus and 20% drive. Assuming our research group is a representative sample of larger population of research groups, using statistical inference we can ask and answer questions such as what percentage of researches usually drive to work?\n\nDescriptive statistics\nIn other words, a descriptive statistic is a summary statistics that quantitatively describes features of collected information, e.g. percentage of our research group who walked to work on Monday. Descriptive statistics uses and analyses these statistics to help us to understand the data by:\n\ndescribing the data\nvisualizing the data\nsummarizing the data\n\nDescriptive statistics is also used to:\n\nuncover potential patterns in the data including outliers\nand guide down-stream analysis"
  },
  {
    "objectID": "data-types.html",
    "href": "data-types.html",
    "title": "2  Data types",
    "section": "",
    "text": "Depending on the data type we use different methods to describe, summarize and visualize the data. Especially, we differentiate between categorical (qualitative) and numerical (quantitative) data types.\n\n\n\n\n\nflowchart TD\n  A(Data types) --&gt; B(Categorical)\n  A(Data types) --&gt; C(Numerical)\n  B --&gt; D(Nominal)\n  B --&gt; E(Ordinal)\n  C --&gt; F(Discrete)\n  C --&gt; G(Continuous)\n\n\nFigure 2.1: Main data types: categorical (qualitative) and numerical (quantitative)\n\n\n\n\n Categorical data types are further divided into:\n\nNominal: named, categories are mutually exclusive and unordered\n\ne.g.dead/alive, healthy/sick, WT/mutant, blood group (A/B/ABO/O), male/female, red/green/blue\n\nOrdinal: named and ordered, categories are mutually exclusive and ordered\n\ne.g. pain (weak, moderate, severe), AA/Aa/aa, very young/young/middle age/old/very old, grade I, II, III, IV\n\n\nNumerical data types are further divided into:\n\nDiscrete: finite or countable infinite values\n\ne.g. days sick last year, number of cells, number of reads\n\nContinuous: infinitely many uncountable values\n\ne.g. height, weight, concentration\n\n\n\n\n\n\n\n\nGood to remember\n\n\n\nDepending on the data type we use different methods to describe, summarize and visualize the data. Beyond descriptive statistics, we even use different methods to analyse the data."
  },
  {
    "objectID": "diabetes-example.html",
    "href": "diabetes-example.html",
    "title": "3  Diabetes data",
    "section": "",
    "text": "Before we continue with the descriptive statistics, let’s introduce an example data set. We will be looking at the data collected in a study to understand the prevalence of obesity, diabetes, and other cardiovascular risk factors in central Virginia, USA.\nThe data is available as part of faraway package. 403 African Americans were interviewed in a study to understand the prevalence of obesity, diabetes, and other cardiovascular risk factors in central Virginia. Available variables include:\n\n\n\n\n\nAbbreviation\nDescription\n\n\n\n\nid\nSubject ID\n\n\nchol\nTotal Cholesterol [mg/dL]\n\n\nstab.glu\nStabilize Glucose [mg/dL]\n\n\nhdl\nHigh Density Lipoprotein [mg/dL]\n\n\nratio\nCholesterol / HDL Ratio\n\n\nglyhb\nGlycosolated Hemoglobin [%]\n\n\nlocation\nCounty: Buckingham or Louisa\n\n\nage\nage [years]\n\n\ngender\ngender\n\n\nheight\nheight [in]\n\n\nweight\nweight [lb]\n\n\nframe\nframe: small, medium or large\n\n\nbp.1s\nFirst Systolic Blood Pressure\n\n\nbp.1d\nFirst Diastolic Blood Pressure\n\n\nbp.2s\nSecond Systolic Blood Pressure\n\n\nbp.2d\nSecond Diastolic Blood Pressure\n\n\nwaist\nwaist [in]\n\n\nhip\nhip [in]\n\n\ntime.ppn\nPostprandial Time [min] when labs were drawn\n\n\n\n\n\n\n\nAnd the first few observations are:\n\n\nCode\n#| echo: false\n#| warning: false\n#| message: false\n#| include: true\n\nlibrary(tidyverse)\nlibrary(kableExtra)\nlibrary(faraway)\n\n# preview\nglimpse(diabetes)\n\n\nRows: 403\nColumns: 19\n$ id       &lt;labelled&gt; 1000, 1001, 1002, 1003, 1005, 1008, 1011, 1015, 1016, 10…\n$ chol     &lt;labelled&gt; 203, 165, 228, 78, 249, 248, 195, 227, 177, 263, 242, 21…\n$ stab.glu &lt;labelled&gt; 82, 97, 92, 93, 90, 94, 92, 75, 87, 89, 82, 128, 75, 79,…\n$ hdl      &lt;labelled&gt; 56, 24, 37, 12, 28, 69, 41, 44, 49, 40, 54, 34, 36, 46, …\n$ ratio    &lt;labelled&gt; 3.6, 6.9, 6.2, 6.5, 8.9, 3.6, 4.8, 5.2, 3.6, 6.6, 4.5, 6…\n$ glyhb    &lt;labelled&gt; 4.31, 4.44, 4.64, 4.63, 7.72, 4.81, 4.84, 3.94, 4.84, 5.…\n$ location &lt;fct&gt; Buckingham, Buckingham, Buckingham, Buckingham, Buckingham, B…\n$ age      &lt;int&gt; 46, 29, 58, 67, 64, 34, 30, 37, 45, 55, 60, 38, 27, 40, 36, 3…\n$ gender   &lt;fct&gt; female, female, female, male, male, male, male, male, male, f…\n$ height   &lt;int&gt; 62, 64, 61, 67, 68, 71, 69, 59, 69, 63, 65, 58, 60, 59, 69, 6…\n$ weight   &lt;int&gt; 121, 218, 256, 119, 183, 190, 191, 170, 166, 202, 156, 195, 1…\n$ frame    &lt;fct&gt; medium, large, large, large, medium, large, medium, medium, l…\n$ bp.1s    &lt;labelled&gt; 118, 112, 190, 110, 138, 132, 161, NA, 160, 108, 130, 10…\n$ bp.1d    &lt;labelled&gt; 59, 68, 92, 50, 80, 86, 112, NA, 80, 72, 90, 68, 80, NA,…\n$ bp.2s    &lt;labelled&gt; NA, NA, 185, NA, NA, NA, 161, NA, 128, NA, 130, NA, NA, …\n$ bp.2d    &lt;labelled&gt; NA, NA, 92, NA, NA, NA, 112, NA, 86, NA, 90, NA, NA, NA,…\n$ waist    &lt;int&gt; 29, 46, 49, 33, 44, 36, 46, 34, 34, 45, 39, 42, 35, 37, 36, 3…\n$ hip      &lt;int&gt; 38, 48, 57, 38, 41, 42, 49, 39, 40, 50, 45, 50, 41, 43, 40, 4…\n$ time.ppn &lt;labelled&gt; 720, 360, 180, 480, 300, 195, 720, 1020, 300, 240, 300, …\n\n\nFurther:\n\nGlycosolated hemoglobin greater than 7.0 is usually taken as a positive diagnosis of diabetes.\nWe can calculate BMI as \\(BMI = 703 \\times (weight \\; [lb] \\; / (height \\;[in])^2)\\) and define obesity as \\(BMI \\ge 30\\).\nAlternatively, we can first convert pounds (lb) to kilograms (kg) by multiplying by 0.45 and inches (in) to meters (m) by multiplying by 0.0254 and then calculating BMI as \\(BMI = (weight \\; [kg] \\; / (height \\;[m])^2)\\)\n\nIn R we can add diabetes and obesity status (yes/no) and display first few measurements across all the variables as below:\n\n\nCode\n# add obesity and diabetes variables\ninch2m &lt;- 2.54/100\npound2kg &lt;- 0.45\ndata_diabetes &lt;- diabetes %&gt;%\n  mutate(height  = height * inch2m, height = round(height, 2)) %&gt;% \n  mutate(waist = waist * inch2m) %&gt;%  \n  mutate(weight = weight * pound2kg, weight = round(weight, 2)) %&gt;%\n  mutate(BMI = weight / height^2, BMI = round(BMI, 2)) %&gt;% \n  mutate(obese= cut(BMI, breaks = c(0, 29.9, 100), labels = c(\"No\", \"Yes\"))) %&gt;% \n  mutate(diabetic = ifelse(glyhb &gt; 7, \"Yes\", \"No\"), diabetic = factor(diabetic, levels = c(\"No\", \"Yes\")))\n  \n# preview data\nglimpse(data_diabetes)\n\n\nRows: 403\nColumns: 22\n$ id       &lt;labelled&gt; 1000, 1001, 1002, 1003, 1005, 1008, 1011, 1015, 1016, 10…\n$ chol     &lt;labelled&gt; 203, 165, 228, 78, 249, 248, 195, 227, 177, 263, 242, 21…\n$ stab.glu &lt;labelled&gt; 82, 97, 92, 93, 90, 94, 92, 75, 87, 89, 82, 128, 75, 79,…\n$ hdl      &lt;labelled&gt; 56, 24, 37, 12, 28, 69, 41, 44, 49, 40, 54, 34, 36, 46, …\n$ ratio    &lt;labelled&gt; 3.6, 6.9, 6.2, 6.5, 8.9, 3.6, 4.8, 5.2, 3.6, 6.6, 4.5, 6…\n$ glyhb    &lt;labelled&gt; 4.31, 4.44, 4.64, 4.63, 7.72, 4.81, 4.84, 3.94, 4.84, 5.…\n$ location &lt;fct&gt; Buckingham, Buckingham, Buckingham, Buckingham, Buckingham, B…\n$ age      &lt;int&gt; 46, 29, 58, 67, 64, 34, 30, 37, 45, 55, 60, 38, 27, 40, 36, 3…\n$ gender   &lt;fct&gt; female, female, female, male, male, male, male, male, male, f…\n$ height   &lt;dbl&gt; 1.57, 1.63, 1.55, 1.70, 1.73, 1.80, 1.75, 1.50, 1.75, 1.60, 1…\n$ weight   &lt;dbl&gt; 54.45, 98.10, 115.20, 53.55, 82.35, 85.50, 85.95, 76.50, 74.7…\n$ frame    &lt;fct&gt; medium, large, large, large, medium, large, medium, medium, l…\n$ bp.1s    &lt;labelled&gt; 118, 112, 190, 110, 138, 132, 161, NA, 160, 108, 130, 10…\n$ bp.1d    &lt;labelled&gt; 59, 68, 92, 50, 80, 86, 112, NA, 80, 72, 90, 68, 80, NA,…\n$ bp.2s    &lt;labelled&gt; NA, NA, 185, NA, NA, NA, 161, NA, 128, NA, 130, NA, NA, …\n$ bp.2d    &lt;labelled&gt; NA, NA, 92, NA, NA, NA, 112, NA, 86, NA, 90, NA, NA, NA,…\n$ waist    &lt;dbl&gt; 0.7366, 1.1684, 1.2446, 0.8382, 1.1176, 0.9144, 1.1684, 0.863…\n$ hip      &lt;int&gt; 38, 48, 57, 38, 41, 42, 49, 39, 40, 50, 45, 50, 41, 43, 40, 4…\n$ time.ppn &lt;labelled&gt; 720, 360, 180, 480, 300, 195, 720, 1020, 300, 240, 300, …\n$ BMI      &lt;dbl&gt; 22.09, 36.92, 47.95, 18.53, 27.52, 26.39, 28.07, 34.00, 24.39…\n$ obese    &lt;fct&gt; No, Yes, Yes, No, No, No, No, Yes, No, Yes, No, Yes, Yes, Yes…\n$ diabetic &lt;fct&gt; No, No, No, No, Yes, No, No, No, No, No, No, No, No, No, No, …\n\n\nWe can now use descriptive statistics to understand the diabetes data set more."
  },
  {
    "objectID": "data-categorical.html#frequency-table",
    "href": "data-categorical.html#frequency-table",
    "title": "4  Categorical data",
    "section": "4.1 Frequency table",
    "text": "4.1 Frequency table\nLet’s focus on 130 study participants for which no missing data was observed, i.e. complete case analysis. An example frequency table summarizing study participants by their BMI status is shown below.\n\n\nCode\n# count frequencies, percentages and proportions\ntable.summary &lt;- data_diabetes %&gt;%\n  group_by(obese) %&gt;%\n  tally() %&gt;%\n  mutate(\"percent (%)\" = n/sum(n)*100) %&gt;%\n  mutate(\"proportion\" = n/sum(n))\n\n# show table\nkable(table.summary, digits = 1) %&gt;% \n  kable_styling(full_width = TRUE)\n\n\n\n\n\n\n\nobese\nn\npercent (%)\nproportion\n\n\n\n\nNo\n72\n55.4\n0.6\n\n\nYes\n58\n44.6\n0.4\n\n\n\nTable 4.1: Frequency table showing the number, percentages and proportions of study participants with BMI \\(\\ge\\) 30 and with BMI &lt; 30"
  },
  {
    "objectID": "data-categorical.html#bar-chart-pie-chart",
    "href": "data-categorical.html#bar-chart-pie-chart",
    "title": "4  Categorical data",
    "section": "4.2 Bar chart & pie chart",
    "text": "4.2 Bar chart & pie chart\nTo visualize the frequencies (or percentages or proportions) we can use bar chart or a pie chart.\n\n\nCode\n# set a custom ggplot theme\nfont.size &lt;- 30\nmy.ggtheme &lt;- theme(axis.title = element_text(size = font.size), \n        axis.text = element_text(size = font.size), \n        legend.text = element_text(size = font.size), \n        legend.title = element_blank(), \n        axis.title.y = element_text(angle = 0))\n\n# use ggplot to draw a bar chart\ndata_diabetes %&gt;%\n  ggplot(aes(x = obese, fill = obese)) +\n  geom_bar(width = 0.5) +\n  scale_fill_brewer(palette = \"Paired\") + \n  theme_bw() +\n  my.ggtheme\n\n# draw pie chart\ndata_diabetes %&gt;%\n  ggplot(aes(x=\"\", y = obese, fill = obese)) +\n  geom_bar(width = 1, stat = \"identity\") +\n  theme_bw() +\n  coord_polar(\"y\", start=0) +\n  scale_fill_brewer(palette=\"Paired\") +\n  xlab(\"\") +\n  ylab(\"\") + \n  my.ggtheme\n\n\n\n\n\n\n\n\n(a) Bar chart\n\n\n\n\n\n\n\n(b) Pie chart\n\n\n\n\nFigure 4.2: Bar and pie chart showing graphical summaries of number and percentage of participants of study participants with BMI \\(\\ge\\) 30 and with BMI &lt; 30"
  },
  {
    "objectID": "data-categorical.html#summary-table-2-categorical-variables",
    "href": "data-categorical.html#summary-table-2-categorical-variables",
    "title": "4  Categorical data",
    "section": "4.3 Summary table: 2 categorical variables",
    "text": "4.3 Summary table: 2 categorical variables\nWhen we are interested in how one categorical variable is related to another categorical variable, we can use a summary table. For instance, we can look at the relationship between obesity (yes/no) and diabetes (yes/no).\n\n\nCode\ndata_diabetes %&gt;%\n  group_by(obese) %&gt;%\n  dplyr::summarize(Total=n(), `Diabetic` = sum(gender==\"male\")) %&gt;% \n  mutate(`Diabetic (%)` = round(`Diabetic` * 100 / Total, 2)) %&gt;%\n  kable() %&gt;%\n  kable_styling(full_width = TRUE)\n\n\n\n\n\n\n\nobese\nTotal\nDiabetic\nDiabetic (%)\n\n\n\n\nNo\n72\n39\n54.17\n\n\nYes\n58\n18\n31.03\n\n\n\nTable 4.2: Summary table showing relation between obesity and diabesis status among study participants"
  },
  {
    "objectID": "data-categorical.html#contingency-table-2-categorical-variables",
    "href": "data-categorical.html#contingency-table-2-categorical-variables",
    "title": "4  Categorical data",
    "section": "4.4 Contingency table: 2 categorical variables",
    "text": "4.4 Contingency table: 2 categorical variables\nShows the multivariate frequency distribution of variables\n\n\nCode\n# use table() function to create contingency table\ntable.con &lt;- table(data_diabetes$obese, data_diabetes$diabetic)\ntable.con &lt;- addmargins(table.con)\nrownames(table.con) &lt;- c(\"Non-obese\", \"Obese\", \"Sum\")\ncolnames(table.con) &lt;- c(\"Non-diabetic\", \"Diabetic\", \"Sum\")\n\ntable.con %&gt;%\n  kable(row.names = TRUE) %&gt;%\n  kable_styling(full_width = TRUE) %&gt;%\n  column_spec(4, bold = T) %&gt;%\n  row_spec(3, bold = T)\n\n\n\n\n\n\n\n\nNon-diabetic\nDiabetic\nSum\n\n\n\n\nNon-obese\n57\n15\n72\n\n\nObese\n43\n15\n58\n\n\nSum\n100\n30\n130\n\n\n\nTable 4.3: Contigency table (or cross table) showing multivariate frequency of obesity and diabesis status among study participants"
  },
  {
    "objectID": "data-categorical.html#bar-chart-2-categorical-variables",
    "href": "data-categorical.html#bar-chart-2-categorical-variables",
    "title": "4  Categorical data",
    "section": "4.5 Bar chart: 2 categorical variables",
    "text": "4.5 Bar chart: 2 categorical variables\nBar charts can be used to visualize two and more categorical variables, e.g. by using stacking, side-by-side bars or colors.\n\n\nCode\ndata_diabetes %&gt;% \n  ggplot(aes(x=obese, fill=diabetic)) + \n  geom_bar() + \n  theme_bw() + \n  xlab(\"obese\") + \n  ylab(\"count (diabetic)\") +\n  scale_fill_brewer(palette = \"Paired\") + \n  my.ggtheme\n  \n# another way of using bar charts: side by side bars\ndata_diabetes %&gt;% \n  ggplot(aes(x=obese, fill=diabetic)) + \n  geom_bar(position = \"dodge\") + \n  theme_bw() + \n  xlab(\"obese\") + \n  ylab(\"count (diabetic)\") +\n  scale_fill_brewer(palette = \"Paired\") + \n  my.ggtheme\n\n# another way of using bar charts: showing fractions instead of counts\ndata_diabetes %&gt;% \n  ggplot(aes(x=obese, fill=diabetic)) + \n  geom_bar(position = \"fill\") + \n  theme_bw() + \n  xlab(\"obese\") + \n  ylab(\"fraction (diabetic)\") +\n  scale_fill_brewer(palette = \"Paired\") + \n  my.ggtheme\n\n\n\n\n\n\n\n\n(a) stacked bars\n\n\n\n\n\n\n\n(b) side-by-side bars\n\n\n\n\n\n\n\n(c) bars showing fractions instead of counts\n\n\n\n\nFigure 4.3: Bar chart showing summary of diabetic status among study participants with BMI \\(\\ge\\) 30 and with BMI &lt; 30\n\n\n\n\n\nCode\n# calculate number of diabetic participants \n# by among participants with BMI &gt;=30 and stratified by gender\ndata_plot &lt;- data_diabetes %&gt;%\n  select(gender, obese, diabetic) %&gt;%\n  group_by(obese, diabetic, gender) %&gt;%\n  tally() %&gt;%\n  filter(diabetic == \"Yes\") #%&gt;%\n  #print()\n\n# bar plot (stacked)\ndata_plot %&gt;% \n  ggplot(aes(x=obese, y=n, fill = gender)) + \n  geom_bar(stat = \"identity\") + \n  theme_bw() + \n  xlab(\"obese\") +\n  ylab(\"count (diabetic)\") + \n  scale_fill_brewer(palette = \"Set2\") + \n  my.ggtheme\n\n# bar plot (side-by-side)\ndata_plot %&gt;% \n  ggplot(aes(x=obese, y=n, fill = gender)) + \n  geom_bar(stat = \"identity\", position = \"dodge\") + \n  theme_bw() + \n  xlab(\"obese\") +\n  ylab(\"count (diabetic)\") + \n  scale_fill_brewer(palette = \"Set2\") + \n  scale_y_continuous(breaks = pretty_breaks()) + \n  my.ggtheme\n\n\n\n\n\n\n\n\n(a) stacked bars\n\n\n\n\n\n\n\n(b) side-by-side bars\n\n\n\n\nFigure 4.4: Bar chart showing number of diabetic study participants among participants with BMI \\(\\ge\\) 30 and with BMI &lt; 30, stratified by gender"
  },
  {
    "objectID": "data-categorical.html#mosaic-plot",
    "href": "data-categorical.html#mosaic-plot",
    "title": "4  Categorical data",
    "section": "4.6 Mosaic plot",
    "text": "4.6 Mosaic plot\nMosaic plots display contingency tables\n\n\nCode\nlibrary(ggmosaic)\n ggplot(data = data_diabetes) +\n  geom_mosaic(aes(x = product(obese), fill=diabetic)) + \n  theme_bw() + \n  scale_fill_brewer(palette = \"Paired\")\n\n\n\n\n\nFigure 4.5: Mosaic plot showing contigency table of obesity and diabetic status among study participants\n\n\n\n\n\n\nCode\n ggplot(data = data_diabetes) +\n  geom_mosaic(aes(x = product(obese, gender), fill=diabetic)) + \n  theme_bw() + \n   scale_fill_brewer(palette = \"Set2\") \n\n\n\n\n\nFigure 4.6: Mosaic plot showing contigency table of obesity and diabetic status among study participants stratified by gender"
  },
  {
    "objectID": "data-numerical.html#strip-plot-jittered-strip-plot-beeswarm-plot",
    "href": "data-numerical.html#strip-plot-jittered-strip-plot-beeswarm-plot",
    "title": "5  Numerical data",
    "section": "5.1 Strip plot, Jittered strip plot & Beeswarm plot",
    "text": "5.1 Strip plot, Jittered strip plot & Beeswarm plot\nWhen the data set is not very big, i.e. does not contain millions of measurements for a given numerical variable of interest, it is recommended to visually assess all measurements on a plot. This can be done in a 1D scatter plot, called also a strip plot or a dot plot.\nFor instance the age values for the 130 participants in the diabetes study are:\n\n\nCode\nprint(data_diabetes$age)\n\n\n  [1] 58 30 45 60 33 70 47 66 24 40 42 61 61 70 36 55 65 20 74 51 71 76 40 40 76\n [26] 48 64 21 47 61 65 41 50 83 26 53 50 48 59 63 43 58 59 35 50 27 67 51 51 59\n [51] 58 66 43 65 34 37 61 45 68 63 55 66 63 78 68 61 63 54 50 51 45 38 63 50 44\n [76] 48 69 62 36 47 23 38 40 40 60 63 63 46 56 43 26 30 36 44 63 28 52 53 30 45\n[101] 35 50 27 52 42 39 28 53 55 84 80 60 80 63 37 20 54 58 52 33 37 32 60 42 52\n[126] 25 37 89 53 51\n\n\nLet’s visualize these age values using a strip plot.\n\n\nCode\n# plot strip plot\ndata_diabetes %&gt;%\n  ggplot(aes(x = \"\", y = age)) + \n  geom_point() + \n  theme_bw() + \n  ylab(\"age\") + \n  xlab(\"\") + \n  my.ggtheme\n\n\n\n\n\nFigure 5.2: A strip plot showing age values for the 130 study participants\n\n\n\n\nAs year was recorded in years and we have over 100 participants, it happens that some age values are repeated, e.g. we have 2 participants who were 20 years old and 3 that were 30 years old at the time of study. These repeated measurements are shown on top of each other and we cannot see them all. A jittered strip plot attempts to reduce such overlays by randomly moving data points by small amounts to the left and right.\n\n\nCode\n# plot jittered strip plot\ndata_diabetes%&gt;%\n  ggplot(aes(x = \"\", y = age)) + \n  geom_jitter(height = 0, width = 0.25) + \n  theme_bw() + \n  ylab(\"age\") + \n  xlab(\"\") + \n  my.ggtheme\n\n\n\n\n\nFigure 5.3: A jittered strip plot showing age values for the 130 study participants\n\n\n\n\nIn a jittered strip plot some overlays may still occur, as the data points are moved at random. Further, many data points are moved unnecessarily. In a beeswarm plot data points are moved only when necessary, and even then the data point is only moved by the minimum distance required to avoid overlays.\n\n\nCode\n# plot beeswarm\ndata_diabetes %&gt;%\n  ggplot(aes(x = \"\", y = age)) + \n  geom_beeswarm(cex = 2) + \n  theme_bw() + \n  ylab(\"age\") + \n  xlab(\"\") + \n  my.ggtheme\n\n\n\n\n\nFigure 5.4: A beeswarm showing age values for the 130 study participants"
  },
  {
    "objectID": "data-numerical.html#histogram-density-plot",
    "href": "data-numerical.html#histogram-density-plot",
    "title": "5  Numerical data",
    "section": "5.2 Histogram & density plot",
    "text": "5.2 Histogram & density plot\nA histogram bins the data and counts the number of observations that fall into each bin.\n\n\nCode\n# plot histogram\ndata_diabetes %&gt;%\n  ggplot(aes(x = age)) + \n  geom_histogram(binwidth = 5, center = 32.5, color = \"white\", fill = col.blue.dark) + \n  theme_bw() + \n  xlab(\"age\") + \n  my.ggtheme\n\n\n\n\n\nFigure 5.5: A histogram summarizing age values for the 130 study participants\n\n\n\n\nA density plot is like a smoothed histogram where the total area under the curve is set to 1. A density plot is an approximation of a distribution.\n\n\nCode\n# plot density plot\ndata_diabetes %&gt;% ggplot(aes(x = age)) + \n  geom_density() + \n  theme_bw() + \n  xlab(\"age\") + \n  my.ggtheme\n\n\n\n\n\nFigure 5.6: A density plot of age values for the 130 study participants"
  },
  {
    "objectID": "data-numerical.html#histogram-density-plot-stratified-by-group",
    "href": "data-numerical.html#histogram-density-plot-stratified-by-group",
    "title": "5  Numerical data",
    "section": "5.3 Histogram & density plot stratified by group",
    "text": "5.3 Histogram & density plot stratified by group\n\n\nCode\n# plot histogram\np.hist &lt;- data_diabetes %&gt;%\n  ggplot(aes(x=age, fill=gender)) + \n  geom_histogram(bins=15, color=\"white\", alpha = 0.6) + \n  xlab(\"age\") + \n  theme_bw() + \n  scale_fill_brewer(palette = \"Dark2\") + \n  my.ggtheme\n\np.density &lt;- data_diabetes %&gt;%\n  ggplot(aes(x=age, fill=gender)) + \n  geom_density(alpha = 0.6) + \n  xlab(\"age\") + \n  theme_bw() + \n  scale_fill_brewer(palette = \"Dark2\") + \n  my.ggtheme\n\ngrid.arrange(arrangeGrob(p.hist, p.density, ncol=2))\n\n\n\n\n\nFigure 5.7: Histogram and density plots summarizing age values stratified by gender"
  },
  {
    "objectID": "data-numerical.html#scatter-plot-2-numerical-variables",
    "href": "data-numerical.html#scatter-plot-2-numerical-variables",
    "title": "5  Numerical data",
    "section": "5.4 Scatter plot: 2 numerical variables",
    "text": "5.4 Scatter plot: 2 numerical variables\nScatter plots are useful when studying a relationship (association) between two numerical variables. Let’s look at the weight and height for our 130 study participants.\n\n\nCode\n# plot scatter plot\ndata_diabetes %&gt;%\n  ggplot(aes(x = weight, y = height)) + \n  geom_point() + \n  xlab(\"weight [kg]\") + \n  ylab(\"height [m]\") + \n  theme_bw() + \n  my.ggtheme\n\n\n\n\n\nFigure 5.8: Scatter plot showing a relationship between weight and height\n\n\n\n\n\n\nCode\n# plot scatter plot\ndata_diabetes %&gt;%\n  ggplot(aes(x = weight, y = height, color = gender)) +\n  geom_point() +\n  xlab(\"weight [kg]\") +\n  ylab(\"height [m]\") +\n  theme_bw() +\n  scale_color_brewer(palette = \"Dark2\") +\n  my.ggtheme\n\n\n\n\n\nFigure 5.9: Scatter plot showing a relationship between weight and height stratified by gender\n\n\n\n\nSometimes, it is useful to connect the observations in the order in which they appear, e.g. when analyzing time series data. The diabetes data set does not contain any measurements over time but we can simulate some BMI values over time for demonstration purposes.\n\n\nCode\n# simulate BMI over time\n# select participants with BMI &gt;= 30\n# assign half to control group and half to treatment to reduce weight \n# add simulated weight loss values to treatment group ca. 0.2 kg per week\n# add simulated weight fluctuations, ca plus / minus 0.1 kg per week\n\ndata_diabetes_bmi30 &lt;- data_diabetes %&gt;% \n  filter(BMI &gt;= 30) %&gt;%\n  select(id, weight, height, BMI) %&gt;%\n  mutate(group=sample(c(\"control\", \"treatment\"), size=n(), replace=TRUE))\n\n# add 52 weeks of simulated BMI values\n\nno_weeks &lt;- 12\nweight_sim &lt;- matrix(data = NA, \n                     nrow = nrow(data_diabetes_bmi30), \n                     ncol = no_weeks, \n                     dimnames = list(data_diabetes_bmi30$id, paste(\"week\", 1: no_weeks, sep=\"\"))) # initiate matrix to store simulated BMI values\nweight_sim[, 1] &lt;- data_diabetes_bmi30$weight # first column: baseline weight\n\nfor (n in 1:nrow(data_diabetes_bmi30)){\n  \n  for (p in 2:ncol(weight_sim)){\n    \n    # if control group: just fluctuate weight by random values between 0 and 0.2 kg\n    # if treatment: decrease by random values between 0.1 and 0.5 kg from\n    \n    if (data_diabetes_bmi30$group[n] == \"treatment\"){\n     \n      loss &lt;- runif(1, 0.1, 0.5) %&gt;% round(1)\n      weight_sim[n, p] &lt;- weight_sim[n, p-1] - loss\n      \n    } else{\n      \n      fluctuation &lt;- runif(1, -0.2, 0.2) %&gt;% round(1)\n      weight_sim[n, p] &lt;- weight_sim[n, p-1] + fluctuation\n      \n    }\n  \n  }\n}\n\n# convert to tibble\nweight_sim &lt;- weight_sim %&gt;%\n  as_tibble(rownames = \"id\") %&gt;%\n  mutate(id = as.numeric(id))\n\n# join data_diabetes_bmi30 with simulated\n# keep 5 treatment and 5 control participants\ndata_diabets_sim &lt;- data_diabetes_bmi30 %&gt;%\n  as_tibble() %&gt;% \n  left_join(weight_sim, by = \"id\")\n\n# plot BMI over time\ndata_plot &lt;- data_diabets_sim %&gt;%\n  slice_sample(n = 10) %&gt;%\n  select(-weight, -BMI) %&gt;% \n  pivot_longer(-c(\"id\", \"group\", \"height\"), names_to = \"week\", values_to = \"weight\") %&gt;% \n  mutate(BMI = weight / (height^2)) %&gt;%\n  mutate(week = gsub(\"week\", \"\", week)) %&gt;%\n  mutate(week = as.numeric(week)) \n\ndata_plot %&gt;%\n  ggplot(aes(x = week, y = BMI, group = id)) + \n  geom_point() +\n  geom_line() + \n  xlab(\"week\") +\n  ylab(\"BMI\") +\n  theme_bw() +\n  scale_color_brewer(palette = \"Dark2\") +\n  scale_x_continuous(breaks= pretty_breaks()) + \n  my.ggtheme\n\n\n\n\n\nFigure 5.10: A line plot for BMI simulated values over 12 weeks for 10 randomly selected study participants\n\n\n\n\n\n\nCode\ndata_plot &lt;- data_diabets_sim %&gt;%\n  group_by(group) %&gt;%\n  slice_sample(n = 5) %&gt;%\n  select(-weight, -BMI) %&gt;% \n  pivot_longer(-c(\"id\", \"group\", \"height\"), names_to = \"week\", values_to = \"weight\") %&gt;% \n  mutate(BMI = weight / (height^2)) %&gt;%\n  mutate(week = gsub(\"week\", \"\", week)) %&gt;%\n  mutate(week = as.numeric(week)) \n\ndata_plot %&gt;%\n  ggplot(aes(x = week, y = BMI, group = id, colour = group)) + \n  geom_point() +\n  geom_line() + \n  xlab(\"week\") +\n  ylab(\"BMI\") +\n  theme_bw() +\n  scale_color_brewer(palette = \"Dark2\") +\n  scale_x_continuous(breaks= pretty_breaks()) + \n  my.ggtheme\n\n\n\n\n\nFigure 5.11: A line plot for BMI simulated values over 12 weeks for 5 randomly selected study participants from control and treatment group"
  },
  {
    "objectID": "measures-of-location.html#mode",
    "href": "measures-of-location.html#mode",
    "title": "6  Measures of location",
    "section": "6.1 Mode",
    "text": "6.1 Mode\nMode values is the value that most common occurs across the measurements. It can be found for numerical and categorical data types.\nFor instance, we can find age mode value by counting how many times we observe each age value among the study participants. The mode values is the most commonly occurring one, here 63, with 9 participants being 63 at the time of the study.\n\n\nCode\ndata_diabetes %&gt;%\n  group_by(age) %&gt;%\n  tally() %&gt;%\n  arrange(desc(n)) %&gt;%\n  slice(1:3) %&gt;%\n  kbl() %&gt;%\n  kable_styling()\n\n\n\n\nTable 6.1: Top three most observed age values among the study participants.\n\n\nage\nn\n\n\n\n\n63\n9\n\n\n50\n6\n\n\n40\n5\n\n\n\n\n\n\n\n\nAnalogously, we can find mode value for the categorical diabetic status by counting how many of the participants are diabetic and how many are not. Here, the mode is No with 100 study participants having glycosolated hemoglobin level lower than 7.0 and 30 above.\n\n\nCode\ndata_diabetes %&gt;%\n  group_by(diabetic) %&gt;%\n  tally() %&gt;%\n  arrange(desc(n)) %&gt;%\n  slice(1:3) %&gt;%\n  kbl %&gt;%\n  kable_styling()\n\n\n\n\nTable 6.2: Number of times diabetic status of No and Yes is observed for the study participants.\n\n\ndiabetic\nn\n\n\n\n\nNo\n100\n\n\nYes\n30"
  },
  {
    "objectID": "measures-of-location.html#median",
    "href": "measures-of-location.html#median",
    "title": "6  Measures of location",
    "section": "6.2 Median",
    "text": "6.2 Median\nMedian value divides the ordered data values into two equally sized groups so that 50% of the values are below and 50% are above the median value. For the odd number of observations, the middle value is \\((n+1)/2\\)-th term of the ordered observations. For even number of observations, it is the average of the middle two terms of the ordered observations.\n\\[\\begin{equation}\n    Median =\n    \\left\\{\n        \\begin{array}{cc}\n                \\frac{(n+1)}{2}^{th} term & \\mathrm{if\\ } n \\mathrm{\\ is\\ odd} \\\\\n                \\frac{1}{2}\\times \\left (\\frac{n}{2}^{th} term + (\\frac{n}{2}+1)^{th} term \\right) & \\mathrm{if\\ } n \\mathrm{\\ is\\ even}  \\\\\n        \\end{array}\n    \\right.\n\\end{equation}\\]\nFor instance, the median value for age for the first 10 study participants:\n\n\nCode\nage_10 &lt;- data_diabetes %&gt;%\n  slice(1:10)  # select first 10 participants\n\n# show age for 10 first participants\nage_10 %&gt;%\n  select(id, age) %&gt;% \n  pivot_wider(names_from = id, values_from = age) %&gt;%\n  kbl() %&gt;%\n  kable_styling() \n\n\n\n\n\n\n1002\n1011\n1016\n1024\n1036\n1252\n1253\n1256\n1271\n1285\n\n\n\n\n58\n30\n45\n60\n33\n70\n47\n66\n24\n40\n\n\n\n\n\nAge values for the first 10 study participants. \n\ncan be found by ordering observations:\n\n\nCode\nage_10_ordered &lt;- data_diabetes %&gt;%\n  slice(1:10) %&gt;% # select first 10 participants\n  arrange(age) %&gt;% # order by age\n  pull(age) # extract ordered age observations\n\ndata_diabetes %&gt;%\n  slice(1:10) %&gt;% # select first 10 participants\n  arrange(age) %&gt;%\n  select(id, age) %&gt;% \n  pivot_wider(names_from = id, values_from = age) %&gt;%\n  kbl() %&gt;%\n  kable_styling() %&gt;%\n  column_spec(c(5), background = \"gold\") %&gt;%\n  column_spec(c(6), background = \"gold\")\n\n\n\n\n\n1271\n1011\n1036\n1285\n1016\n1253\n1002\n1024\n1256\n1252\n\n\n\n\n24\n30\n33\n40\n45\n47\n58\n60\n66\n70\n\n\n\n\n\n\n\nand averaging \\(5^{th}\\) and \\(6^{th}\\) term in the ordered observations giving a median value of:\n\n1/2*(age_10_ordered[5] + age_10_ordered[6])\n\n[1] 46\n\n\nThe median value for age for the first 11 study participants:\n\n\nCode\nage_11 &lt;- data_diabetes %&gt;%\n  slice(1:11)  # select first 11 participants\n\n# show age for 10 first participants\nage_11 %&gt;%\n  select(id, age) %&gt;% \n  pivot_wider(names_from = id, values_from = age) %&gt;%\n  kbl() %&gt;%\n  kable_styling() \n\n\n\n\n\n\n1002\n1011\n1016\n1024\n1036\n1252\n1253\n1256\n1271\n1285\n1301\n\n\n\n\n58\n30\n45\n60\n33\n70\n47\n66\n24\n40\n42\n\n\n\n\n\nAge values for the first 10 study participants. \n\ncan be found by taking \\(6^{th}\\) term from the ordered observations:\n\n\nCode\nage_11_ordered &lt;- data_diabetes %&gt;%\n  slice(1:11) %&gt;% # select first 11 participants\n  arrange(age) %&gt;% # order by age\n  pull(age) # extract ordered age observations\n\ndata_diabetes %&gt;%\n  slice(1:11) %&gt;% # select first 11 participants\n  arrange(age) %&gt;%\n  select(id, age) %&gt;% \n  pivot_wider(names_from = id, values_from = age) %&gt;%\n  kbl() %&gt;%\n  kable_styling() %&gt;%\n  column_spec(c(6), background = \"gold\")\n\n\n\n\n\n1271\n1011\n1036\n1285\n1301\n1016\n1253\n1002\n1024\n1256\n1252\n\n\n\n\n24\n30\n33\n40\n42\n45\n47\n58\n60\n66\n70\n\n\n\n\n\n\n\ngiving a median value of:\n\nage_11_ordered[6]\n\n[1] 45\n\n\nAlternatively, we can use median() function to check our calculations:\n\ndata_diabetes %&gt;%\n  dplyr::slice(1:10) %$%\n  median(age)\n## [1] 46\n\ndata_diabetes %&gt;%\n  dplyr::slice(1:11) %$%\n  median(age)\n## [1] 45"
  },
  {
    "objectID": "measures-of-location.html#arthimetic-mean",
    "href": "measures-of-location.html#arthimetic-mean",
    "title": "6  Measures of location",
    "section": "6.3 Arthimetic mean",
    "text": "6.3 Arthimetic mean\nThe arithmetic mean, also commonly referred to as mean, is calculated by adding up all the values and diving the sum by the number of values in the data set.\nMathematically, for \\(n\\) observations \\(x_1, x_2, \\dots, x_n\\), the arithmetic mean value is calculated as: \\[\\bar x = \\frac{x_1+x_2+\\dots+x_n}{n} = \\frac{1}{n}\\displaystyle\\sum_{i=1}^n x_i \\tag{6.1}\\]\nTo calculate the arithmetic mean for BMI given our 130 study participants we can follow Equation 6.1\n\n# calculate arithmetic mean following the equation\nx &lt;- data_diabetes %&gt;%\n  pull(BMI) # extract BMI observations\nn &lt;- length(x) # number of observations\nx.bar &lt;- sum(x) / n # calculate mean\nprint(x.bar)\n\n[1] 29.97962\n\nBMI_mean &lt;- round(x.bar, 2)\n\nor use basic mean() function in R:\n\ndata_diabetes %$%\n  mean(BMI) %&gt;%\n  print()\n\n[1] 29.97962"
  },
  {
    "objectID": "measures-of-location.html#weighted-mean",
    "href": "measures-of-location.html#weighted-mean",
    "title": "6  Measures of location",
    "section": "6.4 Weighted mean",
    "text": "6.4 Weighted mean\nAs all the values equally contribute to the calculations, the arithmetic mean value is easily affected by outliers and is distorted by skewed distributions. Sometimes, the weighted mean may be more useful, as it allows add weights to certain values of the variable of interest. We attach a weight, \\(w_i\\) to each of the observed values, \\(x_i\\), in our sample, to reflect this importance and define the weighted mean as: \\[\\bar{x} = \\frac{w_1x_1 + w_2x_2 + \\ldots + w_nx_n}{w_1 + w_2 + \\ldots + w_n} = \\frac{\\displaystyle\\sum_{i=1}^{n}w_ix_i}{\\displaystyle\\sum_{i=1}^{n}w_i} \\tag{6.2}\\]\nFor instance, we may be interested in knowing an average BMI value, irrespective of gender. It happens that among our study participants women are over represented:\n\n\nCode\ndata_diabetes %&gt;%\n  group_by(gender) %&gt;%\n  tally() %&gt;%\n  kbl() %&gt;%\n  kable_styling()\n\n\n\n\n\n\ngender\nn\n\n\n\n\nmale\n57\n\n\nfemale\n73\n\n\n\n\n\nNumber of male and female study participans. \n\nAssuming BMI measurements for men and women should have equal influence (50/50), we can calculate weighted BMI mean to account for group sizes. We assign weights to BMI observations for men and women so that they sum up to 100. Since we have 73 measurements for women, the corresponding weights are \\(w_f = 50 / 73 = 0.6849315\\) and \\(w_m = 50 / 57 = 0.877193\\) for measurements reported for men. The weighted mean can now be calculated following Equation 6.2 and is equal to:\n\n# number of women\nn_w &lt;- data_diabetes%&gt;%\n  filter(gender == \"female\") %&gt;%\n  nrow()\n\n# number of men\nn_m &lt;- data_diabetes%&gt;%\n  filter(gender == \"male\") %&gt;%\n  nrow()\n\n# add weights to observations\ndata_diabetes_addweights &lt;- data_diabetes %&gt;%\n  mutate(w = ifelse(gender == \"male\", 50/n_m, 50/n_w)) %&gt;% # assign weights\n  mutate(wx = BMI * w)  # multiply weight by their weights values\n  \nnumerator &lt;- data_diabetes_addweights %$%\n  sum(wx)\n\ndenominator &lt;- data_diabetes_addweights %$%\n  sum(w)\n\nBMI_weighted_mean &lt;- numerator / denominator\n  \nBMI_weighted_mean &lt;- BMI_weighted_mean %&gt;%\n  round(2) %&gt;%\n  print()\n\n[1] 29.74\n\n\nWe previously calculated BMI mean of 29.98 and mean BMI for men and women are:\n\n\nCode\ndata_diabetes %&gt;%\n  group_by(gender) %&gt;%\n  summarize(mean_BMI = mean(BMI)) %&gt;%\n  kbl(digits = 2) %&gt;%\n  kable_styling()\n\n\n\n\n\n\ngender\nmean_BMI\n\n\n\n\nmale\n27.77\n\n\nfemale\n31.71\n\n\n\n\n\nMean BMI values for men and women in the study. \n\nWe can note, as expected, that the weighted mean of BMI 29.74 is shifted slightly towards mean BMI for men since the BMI measurements for men have been assigned higher weights to account for women being overrepresented in the study."
  },
  {
    "objectID": "measures-of-location.html#mean-median-outliers",
    "href": "measures-of-location.html#mean-median-outliers",
    "title": "6  Measures of location",
    "section": "6.5 Mean, median & outliers",
    "text": "6.5 Mean, median & outliers\nMedian is usually preferred when data has outliers as it follows from median definition that is less sensitive to outliers. On the other hand, mean value can be distorted when outliers are present. Let’s add an outlying value of age (110) to the first 11 study participants, and re-calculate mean and median.\n\n\nCode\n# pull age values for the first 11 study participants\nage_11 &lt;- data_diabetes %&gt;%\n  slice(1:11) %&gt;%\n  select(id, age) %&gt;%\n  pull(age)\n  \n# add outlier value of 110\nage_11_with_outlier &lt;- c(age_11, 110)\n\n# calculate mean and median, with and without outlier\n\n# without outlier\nage_mean_without &lt;- mean(age_11) %&gt;% round(2)\nage_median_without &lt;- median(age_11)\n\n# with outlier\nage_mean_with &lt;- mean(age_11_with_outlier) %&gt;% round(2)\nage_median_with &lt;- median(age_11_with_outlier)\n\nres &lt;- data.frame(mean = c(age_mean_without, age_mean_with), \n                  median = c(age_median_without, age_median_with), \n                  row.names = c(\"without outlier\", \"with outlier\"))\n\nres %&gt;%\n  kbl() %&gt;%\n  kable_styling()\n\n\n\n\n\n\n\nmean\nmedian\n\n\n\n\nwithout outlier\n46.82\n45\n\n\nwith outlier\n52.08\n46\n\n\n\n\n\nComparision of mean and median age values before and after adding outlying age value of 110 to the first 11 study participants. \n\nWe can see that adding one outlying age value shifted mean age from 46.82 to 52.08 while median age value did not change that much with original median value being 45 and 46 after adding the outlying value.\nIn addition, it is good to remember that several very different distributions can still have the same mean value.\n\n\n\n\n\nFigure 6.1: Examples of various distributions having the same mean value of 3.5"
  },
  {
    "objectID": "measures-of-location.html#more-averages",
    "href": "measures-of-location.html#more-averages",
    "title": "6  Measures of location",
    "section": "6.6 More averages",
    "text": "6.6 More averages\nBeyond the common averages measure above, there is many more that one may encounter. The trimmed mean reduces the influence of outliers by removing a specified percentage of extreme values before calculating the mean, making it valuable in clinical trials where extreme results may skew data. The geometric mean is crucial in pharmacokinetics for calculating average rates of drug absorption or clearance, as it computes the nth root of the product of all data points. The moving average is commonly used in epidemiology to smooth out daily case reports of diseases, helping to visualize trends by averaging data points within a sliding window over time. The Hodges-Lehmann estimator, a robust statistic for central tendency, is less affected by outliers. It calculates the median of all possible averages of sample pairs, ideal for non-parametric analyses in studies where data may not be normally distributed, such as environmental exposure assessments\nTrimmed Mean\n\\[\\text{Trimmed Mean} = \\frac{\\sum_{i=p+1}^{n-p} x_{(i)}}{n - 2p}\\] Here, \\(x_{(i)}\\) are the ordered observations from smallest to largest, \\(n\\) is the total number of observations, and \\(p\\) is the number of extreme values removed from each end of the dataset.\nGeometric Mean \\[\\text{Geometric Mean (GM)} = \\left(\\prod_{i=1}^{n} x_i\\right)^{1/n}\\] The geometric mean is the nth root of the product of all \\(n\\) data points, \\(x_i\\).\nMoving Average \\[\\text{Moving Average} = \\frac{1}{k} \\sum_{i=j}^{j+k-1} x_i\\] This averages \\(k\\) consecutive data points in a series, starting from point \\(j\\).\nHodges-Lehmann Estimator \\[\\text{Hodges-Lehmann Estimator} = \\text{Median} \\left( \\frac{x_i + x_j}{2} \\right)\\] This estimator is calculated by taking all possible pairs \\((x_i, x_j)\\) of sample observations, computing their average, and then finding the median of these averages."
  },
  {
    "objectID": "measures-of-spread.html#range",
    "href": "measures-of-spread.html#range",
    "title": "7  Measures of spread",
    "section": "7.1 Range",
    "text": "7.1 Range\nThe range is the difference between the largest and the smallest observations in the data set. Similar to mean, it can be a misleading measure if there are outliers in the data.\nGiven our age values the range can be calculated:\n\nage_max &lt;- data_diabetes %$%\n  max(age)\n\nage_min &lt;- data_diabetes %$%\n  min(age)\n\nrange &lt;- age_max - age_min\nprint(range)\n\n[1] 69"
  },
  {
    "objectID": "measures-of-spread.html#quartiles",
    "href": "measures-of-spread.html#quartiles",
    "title": "7  Measures of spread",
    "section": "7.2 Quartiles",
    "text": "7.2 Quartiles\nIf we arrange the data in order of magnitude, starting with the smallest and ending with the largest value we can define percentiles. The value of \\(x\\) that has 1% of the observations in the ordered set lying below it (and 99% of the observations lying above it) is called the 1st percentile. The value of \\(x\\) that has 2% of the observations in the ordered set lying below it (and 98% of the observations lying above it) is called the 2nd percentile, and so on. The values of \\(x\\) that divide the ordered set into 10 equally sized groups, that is the 10th, 20th, 30th, …, 90th percentiles, are called deciles.\nQuartiles are the three values that divide the data values into four equally sized groups.\n\nQ1. Lower quartile. 25% of values are below Q1. Divides the values below the median into equally sized groups.\nQ2. Median. 50% of values are below Q2 and 50% are above Q2. Q2 is the median that we have seen before.\nQ3. Upper quartile. 75% of values are below Q3. Divides the values above the median into equally sized groups.\n\nGoing back to the diabetes data set, what are the three quartiles of participants age?\n\n# calculate quartiles\nquartiles &lt;- data_diabetes %&gt;%\n  reframe(x = quantile(age, c(0.25, 0.5, 0.75))) \n\nQ1 &lt;- quartiles %&gt;% slice(1) %&gt;% pull(x)\nQ2 &lt;- quartiles %&gt;% slice(2) %&gt;% pull(x)\nQ3 &lt;- quartiles %&gt;% slice(3) %&gt;% pull(x)\n\nprint(Q1)\n## [1] 40\nprint(Q2)\n## [1] 51\nprint(Q3)\n## [1] 61.75"
  },
  {
    "objectID": "measures-of-spread.html#iqr",
    "href": "measures-of-spread.html#iqr",
    "title": "7  Measures of spread",
    "section": "7.3 IQR",
    "text": "7.3 IQR\nThe interquartile range, IQR, is the difference between the 1st (Q1) and the 3rd (Q3) quartiles, i.e. between the 25th and 75th percentiles. It contains the central 50% of the observations in the ordered set.\n\\[IQR = Q3 - Q1\\]\nFor instance, the IQR range for age value for our study is:\n\niqr = Q3 - Q1\nprint(iqr)\n\n[1] 21.75"
  },
  {
    "objectID": "measures-of-spread.html#variance-and-standard-deviation",
    "href": "measures-of-spread.html#variance-and-standard-deviation",
    "title": "7  Measures of spread",
    "section": "7.4 Variance and standard deviation",
    "text": "7.4 Variance and standard deviation\nThe variance of a set of observations is their mean squared distance from the mean value:\n\\[\\sigma^2 = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar x)^2. \\tag{7.1}\\]\n\n\nCode\ndata.xy &lt;- data_diabetes %&gt;%\n  slice(1:10) %&gt;% \n  mutate(id = as.character(id)) %&gt;%\n  rename(y = age) %&gt;%\n  rename(x = id)\n\ny.bar &lt;- mean(data.xy$y)\n\ndata.xy %&gt;%\nggplot(aes(x=x, y=y)) +\n  geom_segment( aes(x=x, xend=x, y=y, yend=y.bar), color=\"grey\") +\n  geom_point(color=col.blue.dark, size=4) +\n  geom_hline(yintercept=y.bar) +\n  theme_bw() +\n  theme(\n    panel.grid.major.x = element_blank(),\n    panel.border = element_blank(),\n    axis.ticks = element_blank(),\n    axis.text.y = element_blank()) +\n  xlab(\"\") +\n  ylab(\"Age (year)\") +\n  coord_flip() +\n  my.ggtheme\n\n\n\n\n\nFigure 7.1: First ten age measurements for the study participants. Grey lines show the distance to the age mean value.\n\n\n\n\nThe variance is measured in the square of the unit in which \\(x\\) was measured. Another common measure using the same unit as \\(x\\) is standard deviation, defined as the square root of the variance:\n\\[\\sigma = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar x)^2} \\tag{7.2}\\]\nTypically, we regard the collection of observations \\(x_1, \\dots, x_n\\) as a sample drawn from a large population of possible observations. It has been shown theoretically that we obtain a better sample estimate of the population variance and standard deviation if we divide by \\((n-1)\\). So the denominator \\(n\\) is commonly replaced by \\(n-1\\) and the sample variance is calculated instead as\n\\[s^2 = {\\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar x)^2}. \\tag{7.3}\\]\nand the sample standard deviation is calculated as:\n\\[s = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar x)^2}. \\tag{7.4}\\]\nTo reiterate:\n\nwe calculate standard deviation, \\(\\sigma\\), when we consider our observations to be entire population (Equation 7.2)\nwe calculate sample standard deviation, \\(s\\), when we consider our observations a random sample from a larger population, as a better estimate of the standard deviation of the larger population (Equation 7.4)\n\nLet’s calculate variance, standard deviation and sample standard deviation for age.\n\n# extract age values\nage &lt;- data_diabetes %&gt;% pull(age)\n\n# number of observations\nn &lt;- length(age)\n\n# calculate mean (arithmetic)\nage_mean &lt;- mean(age)\n\n# calculate variance following variance equation\nsigma2 &lt;- (sum((age - age_mean)^2))/(n)\n\n# calculate standard deviation following standard deviation equation\nsigma &lt;- sqrt((sum((age - age_mean)^2))/(n))\n\n# calculate sample variance following sample variance equation\ns2 &lt;- (sum((age - age_mean)^2))/(n-1)\n\n# calculate sample standard deviation following sample standard deviation equation\ns &lt;- sqrt((sum((age - age_mean)^2))/(n-1))\n\n# collect results\nv.name &lt;- c(\"sigma2\", \"sigma\", \"s2\", \"s\")\nv.values &lt;- c(sigma2, sigma, s2, s)\nresults &lt;- data.frame(stats = v.name, value = v.values)\nprint(results)\n##    stats     value\n## 1 sigma2 224.80828\n## 2  sigma  14.99361\n## 3     s2 226.55098\n## 4      s  15.05161\n\nWe can check our calculations of sample variance and sample standard deviation using R functions var() and sd()\n\nprint(var(age))\n## [1] 226.551\nprint(sd(age))\n## [1] 15.05161"
  },
  {
    "objectID": "measures-of-spread.html#other-measures",
    "href": "measures-of-spread.html#other-measures",
    "title": "7  Measures of spread",
    "section": "7.5 Other measures",
    "text": "7.5 Other measures\nThere are naturally additional measure of spread and to assess the shape of data distribution. Some examples include the Coefficient of Variation (CV), calculated as the ratio of the standard deviation to the mean. CV is commonly used to compare the variability of measurements across different groups or conditions in biological experiments, regardless of their units. The Mean Absolute Deviation (MAD) measures average deviation from the mean, offering a robust alternative to the standard deviation, particularly useful in studies with outliers, such as enzyme kinetics where reaction rates can vary widely. Skewness measures the asymmetry of a distribution around its mean, important in clinical data to determine if results are biased toward high or low values, which might indicate non-normal behavior like skewed immune response. Kurtosis evaluates the ‘tailedness’ of the distribution; in pharmacological data, high kurtosis might suggest a concentration of data around a mean with extreme outliers, indicative of varying drug responses among patients.\nCoefficient of Variation (CV) \\[\\text{CV} = \\frac{\\sigma}{\\mu} \\times 100\\%\\] Here, \\(\\sigma\\) is the standard deviation and \\(\\mu\\) is the mean of the dataset. The CV is expressed as a percentage to indicate the ratio of the standard deviation to the mean.\nMean Absolute Deviation (MAD) \\[\\text{MAD} = \\frac{1}{n} \\sum_{i=1}^{n} |x_i - \\mu|\\] This represents the average of the absolute differences between each data point \\(x_i\\) and the mean \\(\\mu\\) of the dataset, where \\(n\\) is the number of observations.\nSkewness \\[\\text{Skewness} = \\frac{n}{(n-1)(n-2)} \\sum_{i=1}^{n} \\left(\\frac{x_i - \\mu}{\\sigma}\\right)^3\\] Skewness measures the asymmetry of the data around the mean. Positive skew indicates a tail on the right side of the distribution, and negative skew indicates a tail on the left.\nKurtosis \\[\\text{Kurtosis} = \\frac{n(n+1)}{(n-1)(n-2)(n-3)} \\sum_{i=1}^{n} \\left(\\frac{x_i - \\mu}{\\sigma}\\right)^4 - \\frac{3(n-1)^2}{(n-2)(n-3)}\\] Kurtosis assesses the tailedness of the distribution. A higher kurtosis than the normal distribution (which has a kurtosis of 3) indicates a distribution with more pronounced tails."
  },
  {
    "objectID": "boxplot.html",
    "href": "boxplot.html",
    "title": "8  Box-and-whisker plot",
    "section": "",
    "text": "Code\n# load libraries\nlibrary(tidyverse)\nlibrary(magrittr)\nlibrary(kableExtra)\nlibrary(faraway)\nlibrary(scales)\nlibrary(ggbeeswarm)\nlibrary(gridExtra)\n\n# define generic ggplot theme\nfont.size &lt;- 12\ncol.blue.light &lt;- \"#a6cee3\"\ncol.blue.dark &lt;- \"#1f78b4\"\nmy.ggtheme &lt;- theme(axis.title = element_text(size = font.size), \n        axis.text = element_text(size = font.size), \n        legend.text = element_text(size = font.size), \n        legend.title = element_blank(), \n        legend.position = \"top\", \n        axis.title.y = element_text(angle = 0)) \n\n# add obesity and diabetes status to diabetes faraway data\ninch2m &lt;- 2.54/100\npound2kg &lt;- 0.45\ndata_diabetes &lt;- diabetes %&gt;%\n  mutate(height  = height * inch2m, height = round(height, 2)) %&gt;% \n  mutate(waist = waist * inch2m) %&gt;%  \n  mutate(weight = weight * pound2kg, weight = round(weight, 2)) %&gt;%\n  mutate(BMI = weight / height^2, BMI = round(BMI, 2)) %&gt;% \n  mutate(obese= cut(BMI, breaks = c(0, 29.9, 100), labels = c(\"No\", \"Yes\"))) %&gt;% \n  mutate(diabetic = ifelse(glyhb &gt; 7, \"Yes\", \"No\"), diabetic = factor(diabetic, levels = c(\"No\", \"Yes\"))) %&gt;%\n  na.omit()\n\n\nA box-and-whisker plot, commonly referred to as box plot, is a diagram summarizing numerical data through quartiles. It is shown as a vertical or horizontal rectangle box, with the ends of rectangle corresponding to the upper (Q3) and lower (Q1) quartiles of the data values. A line drawn through the rectangle corresponds to the median value (Q2).\nIn addition to the box, there can be also lines called whiskers extending from the rectangle indicating variability outside the upper and lower quartiles. These can be defined in few ways, for instance they can indicate i) minimum and maximum values or ii) particular percentiles, e.g. 5th and 95th. On the box plot prepared with R function boxplot() or geom_boxplot() the upper whisker extends by default to the largest value no further than 1.5 * IQR from Q3 while the lower whiskers extends by default to the smallest value at most 1.5 * IQR from Q1.\nData beyond the end of the whiskers are called “outlying” points and are plotted individually.\nBelow, we can see annotated box plot based on the BMI values for the 130 study participants.\n\n\n\nFigure 8.1: Box plot\n\n\nThe code to generate the box plot in R is here:\n\ndata_diabetes %&gt;%\n  ggplot(aes(x = \"\", y = BMI)) + \n  geom_boxplot(alpha = 1, col = \"black\", outlier.colour = \"red\", width = 0.4) + \n  xlab(\"\") + \n  theme_classic() + \n  my.ggtheme\n\n\n\n\nFigure 8.2: A box-and-whisker plot for the BMI values based on the measurments for the 130 study participants.\n\n\n\n\nWe have previously mentioned that when we are dealing with a relatively small data set it is recommended to visually assess all the observations. We can overlay jitter plot on the box plot to get a complete picture of both the data and the quartiles summary statistics.\n\ndata_diabetes %&gt;%\n  ggplot(aes(x = \"\", y = BMI)) + \n  geom_boxplot(alpha = 1, col = \"black\", outlier.colour = \"red\", width = 0.4) + \n  geom_jitter(width = 0.2, alpha = 0.3) + \n  xlab(\"\") + \n  theme_classic() + \n  my.ggtheme\n\n\n\n\nFigure 8.3: A box-and-whisker plot overlayed on the jitter plot for the BMI values based on the measurments for the 130 study participants."
  },
  {
    "objectID": "beyond.html",
    "href": "beyond.html",
    "title": "9  Descriptive statistics & lifecycle of data science",
    "section": "",
    "text": "Common data science project phases include defining a problem, collecting and cleaning data, initial data exploration and depending on the nature of the question driving the study, analyses based on the sample of data to learn more about the larger population and/or building predictive models. Descriptive statistics can come handy in most if not all phases of the project. For instance when collecting data we can keep track of number of experiments to be run to ensure big enough sample size and when monitoring predictive models we can summarize model performance.\n\n\n\n\n\nflowchart LR\n  A(Define problem) --&gt; B(Collect data)\n  B --&gt; C(Clean data)\n  C --&gt; D(Explore data)\n  D --&gt; E(Inferential statistics)\n  D --&gt; F(Predictive modelling)\n  E --&gt; G(Communicate results)\n  F --&gt; G(Communicate results)\n  \n\n\nFigure 9.1: A schematic representation of the phases of the data science project.\n\n\n\n\nTypically though, we rely the most on the descriptive statistics during the exploring data phase. This phase, is often called Exploratory Data Analysis and abbreviated as EDA. EDA was introduced in 1970s by John Tukey, american mathematician and statistician, to encourage statisticians to explore the data, and formulate hypotheses that could lead to new data collection and experiments. Prior the introduction of EDA, initial data analysis, IDA was used with a narrow focus on checking data quality and model assumptions required for statistical modeling and hypothesis testing.\nData science projects rarely require only one pass through the project phases and often one returns to previous steps many times given the results from the down-stream steps. For instance, one may perform EDA, discover and handle missing data, and redo the EDA. Or one may try some hypothesis tests that would lead to new questions for which one would repeat both EDA and inferential data analysis parts.\n\n\n\n\n\nflowchart LR\n  A(Define problem) --&gt; B(Collect data)\n  B --&gt; C(Clean data)\n  C --&gt; D(Explore data)\n  D --&gt; E(Inferential statistics)\n  D --&gt; F(Predictive modelling)\n  E --&gt; G(Communicate results)\n  F --&gt; G(Communicate results)\n  G --&gt; A\n  G --&gt; B\n  G --&gt; C\n  G --&gt; D\n  E --&gt; A\n  E --&gt; B\n  E --&gt; C\n  E --&gt; D\n  F --&gt; B\n  F --&gt; C\n  F --&gt; D\n  \n\n\nFigure 9.2: A schematic representation of the phases of the data science project showing that one often returns to the earlier phases of the projects depending the outcome of the down-stream steps."
  },
  {
    "objectID": "exercises.html#solutions-descriptive-statistics",
    "href": "exercises.html#solutions-descriptive-statistics",
    "title": "10  Exercises",
    "section": "Solutions: Descriptive statistics",
    "text": "Solutions: Descriptive statistics\n\nSolution. Exercise 10.1\n\nAge is a numerical variable and we can calculate mean and sample standard deviation for example as below:\n\ndata_diabetes %&gt;%\n  select(age) %&gt;%\n  summarize(age_mean = mean(age, na.rm = T), \n            age_sd = sd(age, na.rm = T)) %&gt;%\n  print()\n\n  age_mean   age_sd\n1 46.85112 16.31233\n\n\nGender and obesity status are categorical variables and we can calculate counts and percentages per groups as below:\n\nsummary_gender &lt;- data_diabetes %&gt;%\n  select(gender) %&gt;%\n  group_by(gender) %&gt;%\n  summarize(n = n()) %&gt;%\n  mutate(percent = n * 100 / nrow(data_diabetes)) %&gt;%\n  print()\n\n# A tibble: 2 × 3\n  gender     n percent\n  &lt;fct&gt;  &lt;int&gt;   &lt;dbl&gt;\n1 male     169    41.9\n2 female   234    58.1\n\nsummary_obese &lt;- data_diabetes %&gt;%\n  select(obese) %&gt;%\n  group_by(obese) %&gt;%\n  summarize(n = n()) %&gt;%\n  mutate(percent = n * 100 / nrow(data_diabetes)) %&gt;%\n  print()\n\n# A tibble: 3 × 3\n  obese     n percent\n  &lt;fct&gt; &lt;int&gt;   &lt;dbl&gt;\n1 No      253   62.8 \n2 Yes     144   35.7 \n3 &lt;NA&gt;      6    1.49\n\n\nAlternatively, we can use one of the many R data summaries packages, for instance arsenal to summarize obesity status by age and gender.\n\nlibrary(arsenal)\n\ntab1 &lt;- tableby(obese ~ gender + age, data=data_diabetes)\nsummary(tab1)\n\n\n\n\n\n\n\n\n\n\n\nNo (N=253)\nYes (N=144)\nTotal (N=397)\np value\n\n\n\n\ngender\n\n\n\n&lt; 0.001\n\n\n   male\n128 (50.6%)\n40 (27.8%)\n168 (42.3%)\n\n\n\n   female\n125 (49.4%)\n104 (72.2%)\n229 (57.7%)\n\n\n\nage\n\n\n\n0.734\n\n\n   Mean (SD)\n47.103 (16.745)\n46.521 (15.831)\n46.892 (16.402)\n\n\n\n   Range\n19.000 - 91.000\n20.000 - 92.000\n19.000 - 92.000\n\n\n\n\n\nAnother popular package is gtsummary that calculates descriptive statistics for continuous, categorical, and dichotomous variables in R, and presents the results in customizable summary table ready for publication.\n\nlibrary(gtsummary)\n\ndata_diabetes %&gt;%\n  select(age, gender, obese) %&gt;%\n  tbl_summary(by = obese, \n              statistic = list(all_continuous() ~ \"{mean} ({sd})\"))\n\n\n\n\n\n  \n    \n      Characteristic\n      No, N = 2531\n      Yes, N = 1441\n    \n  \n  \n    age\n47 (17)\n47 (16)\n    gender\n\n\n        male\n128 (51%)\n40 (28%)\n        female\n125 (49%)\n104 (72%)\n  \n  \n  \n    \n      1 Mean (SD); n (%)\n    \n  \n\n\n\n\n\nSolution. Exercise 10.2\n\n\nfont.size &lt;- 12\ncol.blue.light &lt;- \"#a6cee3\"\ncol.blue.dark &lt;- \"#1f78b4\"\nmy.ggtheme &lt;- theme(axis.title = element_text(size = font.size), \n        axis.text = element_text(size = font.size), \n        legend.text = element_text(size = font.size), \n        legend.title = element_blank(), \n        legend.position = \"top\", \n        axis.title.y = element_text(angle = 0)) + theme_bw()\n  \nplt_hist &lt;- data_diabetes %&gt;%\n  ggplot(aes(x = BMI)) +\n  geom_histogram() + \n  my.ggtheme\n\nplt_density &lt;- data_diabetes %&gt;%\n  ggplot(aes(x = BMI)) +\n  geom_density() + \n  my.ggtheme\n\nplt_boxplot &lt;- data_diabetes %&gt;%\n  ggplot(aes(x = gender, y = BMI)) + \n  geom_boxplot() + \n  my.ggtheme\n  \n\nplt_hist\n\n\n\nplt_density\n\n\n\nplt_boxplot           \n\n\n\n\nIn addition, we could for instance try beeswarm plot and/or histogram stratified by gender. Or we can try also overlaying box plots over the jitter plot either for all BMI variables or separately for males and females. Sometimes, it may be also a good idea to plot summary statistics, e.g. a barplot at a height of means and error bars representing standard deviation, error bars or confidence intervals. See this post for inspiration if you’d like to try plotting the summary statistics instead http://www.cookbook-r.com/Graphs/Plotting_means_and_error_bars_(ggplot2)/"
  }
]